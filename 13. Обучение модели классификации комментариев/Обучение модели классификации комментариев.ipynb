{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Проект для «Викишоп»"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Интернет-магазин «Викишоп» запускает новый сервис. Теперь пользователи могут редактировать и дополнять описания товаров, как в вики-сообществах. То есть клиенты предлагают свои правки и комментируют изменения других. Магазину нужен инструмент, который будет искать токсичные комментарии и отправлять их на модерацию. \n",
    "\n",
    "Обучите модель классифицировать комментарии на позитивные и негативные. В вашем распоряжении набор данных с разметкой о токсичности правок.\n",
    "\n",
    "Постройте модель со значением метрики качества *F1* не меньше 0.75. \n",
    "\n",
    "**Инструкция по выполнению проекта**\n",
    "\n",
    "1. Загрузите и подготовьте данные.\n",
    "2. Обучите разные модели. \n",
    "3. Сделайте выводы.\n",
    "\n",
    "**Описание данных**\n",
    "\n",
    "Данные находятся в файле `toxic_comments.csv`. Столбец *text* в нём содержит текст комментария, а *toxic* — целевой признак."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\79174\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping taggers\\averaged_perceptron_tagger.zip.\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\79174\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\79174\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\79174\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\79174\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords, wordnet\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('omw-1.4')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('punkt')\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords as nltk_stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "import time\n",
    "\n",
    "pd.options.display.max_colwidth = 1000\n",
    "\n",
    "RANDOM_STATE = 12345"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Подготовка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Explanation\\nWhy the edits made under my username Hardcore Metallica Fan were reverted? They weren't vandalisms, just closure on some GAs after I voted at New York Dolls FAC. And please don't remove the template from the talk page since I'm retired now.89.205.38.27</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>D'aww! He matches this background colour I'm seemingly stuck with. Thanks.  (talk) 21:51, January 11, 2016 (UTC)</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It's just that this guy is constantly removing relevant information and talking to me through edits instead of my talk page. He seems to care more about the formatting than the actual info.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on improvement - I wondered if the section statistics should be later on, or a subsection of \"\"types of accidents\"\"  -I think the references may need tidying so that they are all in the exact same format ie date format etc. I can do that later on, if no-one else does first - if you have any preferences for formatting style on references or want to do it yourself please let me know.\\n\\nThere appears to be a backlog on articles for review so I guess there may be a delay until a reviewer turns up. It's listed in the relevant form eg Wikipedia:Good_article_nominations#Transport  \"</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember what page that's on?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159287</th>\n",
       "      <td>159446</td>\n",
       "      <td>\":::::And for the second time of asking, when your view completely contradicts the coverage in reliable sources, why should anyone care what you feel? You can't even give a consistent argument - is the opening only supposed to mention significant aspects, or the \"\"most significant\"\" ones?   \\n\\n\"</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159288</th>\n",
       "      <td>159447</td>\n",
       "      <td>You should be ashamed of yourself \\n\\nThat is a horrible thing you put on my talk page.  128.61.19.93</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159289</th>\n",
       "      <td>159448</td>\n",
       "      <td>Spitzer \\n\\nUmm, theres no actual article for prostitution ring.  - Crunch Captain.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159290</th>\n",
       "      <td>159449</td>\n",
       "      <td>And it looks like it was actually you who put on the speedy to have the first version deleted now that I look at it.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159291</th>\n",
       "      <td>159450</td>\n",
       "      <td>\"\\nAnd ... I really don't think you understand.  I came here and my idea was bad right away.  What kind of community goes \"\"you have bad ideas\"\" go away, instead of helping rewrite them.   \"</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>159292 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unnamed: 0  \\\n",
       "0                0   \n",
       "1                1   \n",
       "2                2   \n",
       "3                3   \n",
       "4                4   \n",
       "...            ...   \n",
       "159287      159446   \n",
       "159288      159447   \n",
       "159289      159448   \n",
       "159290      159449   \n",
       "159291      159450   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      text  \\\n",
       "0                                                                                                                                                                                                                                                                                                                                                                                Explanation\\nWhy the edits made under my username Hardcore Metallica Fan were reverted? They weren't vandalisms, just closure on some GAs after I voted at New York Dolls FAC. And please don't remove the template from the talk page since I'm retired now.89.205.38.27   \n",
       "1                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         D'aww! He matches this background colour I'm seemingly stuck with. Thanks.  (talk) 21:51, January 11, 2016 (UTC)   \n",
       "2                                                                                                                                                                                                                                                                                                                                                                                                                Hey man, I'm really not trying to edit war. It's just that this guy is constantly removing relevant information and talking to me through edits instead of my talk page. He seems to care more about the formatting than the actual info.   \n",
       "3       \"\\nMore\\nI can't make any real suggestions on improvement - I wondered if the section statistics should be later on, or a subsection of \"\"types of accidents\"\"  -I think the references may need tidying so that they are all in the exact same format ie date format etc. I can do that later on, if no-one else does first - if you have any preferences for formatting style on references or want to do it yourself please let me know.\\n\\nThere appears to be a backlog on articles for review so I guess there may be a delay until a reviewer turns up. It's listed in the relevant form eg Wikipedia:Good_article_nominations#Transport  \"   \n",
       "4                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      You, sir, are my hero. Any chance you remember what page that's on?   \n",
       "...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    ...   \n",
       "159287                                                                                                                                                                                                                                                                                                                                           \":::::And for the second time of asking, when your view completely contradicts the coverage in reliable sources, why should anyone care what you feel? You can't even give a consistent argument - is the opening only supposed to mention significant aspects, or the \"\"most significant\"\" ones?   \\n\\n\"   \n",
       "159288                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               You should be ashamed of yourself \\n\\nThat is a horrible thing you put on my talk page.  128.61.19.93   \n",
       "159289                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 Spitzer \\n\\nUmm, theres no actual article for prostitution ring.  - Crunch Captain.   \n",
       "159290                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                And it looks like it was actually you who put on the speedy to have the first version deleted now that I look at it.   \n",
       "159291                                                                                                                                                                                                                                                                                                                                                                                                                                                      \"\\nAnd ... I really don't think you understand.  I came here and my idea was bad right away.  What kind of community goes \"\"you have bad ideas\"\" go away, instead of helping rewrite them.   \"   \n",
       "\n",
       "        toxic  \n",
       "0           0  \n",
       "1           0  \n",
       "2           0  \n",
       "3           0  \n",
       "4           0  \n",
       "...       ...  \n",
       "159287      0  \n",
       "159288      0  \n",
       "159289      0  \n",
       "159290      0  \n",
       "159291      0  \n",
       "\n",
       "[159292 rows x 3 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#прочтем данные и выведем их\n",
    "data = pd.read_csv('/datasets/toxic_comments.csv')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 159292 entries, 0 to 159291\n",
      "Data columns (total 3 columns):\n",
      " #   Column      Non-Null Count   Dtype \n",
      "---  ------      --------------   ----- \n",
      " 0   Unnamed: 0  159292 non-null  int64 \n",
      " 1   text        159292 non-null  object\n",
      " 2   toxic       159292 non-null  int64 \n",
      "dtypes: int64(2), object(1)\n",
      "memory usage: 3.6+ MB\n",
      "None\n",
      "Количество строк данных 159292 и количество стобцов 3\n",
      "Количество пропущеннызх данных: Unnamed: 0    0\n",
      "text          0\n",
      "toxic         0\n",
      "dtype: int64\n",
      "Количесвто дублирующих данных: 0\n",
      "Index(['Unnamed: 0', 'text', 'toxic'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(data.info())\n",
    "print(f'Количество строк данных {data.shape[0]} и количество стобцов {data.shape[1]}')\n",
    "print(f'Количество пропущеннызх данных: {data.isna().sum()}')\n",
    "print(f'Количесвто дублирующих данных: {data.duplicated().sum()}')\n",
    "print(data.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В данных нет пропусков и дублирующих строк. Целевой признак столбец ***toxic***, признаки по которым следует классифицировать токсичность комментариев столбец ***text***. Столбец ***Unnamed: 0*** возможно образовался при извлечении комментариев с ресурса и добавлением в общие данные, данный столбец не несет никакой информации и для нашей задачи он не нужен, удалим его."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Explanation\\nWhy the edits made under my username Hardcore Metallica Fan were reverted? They weren't vandalisms, just closure on some GAs after I voted at New York Dolls FAC. And please don't remove the template from the talk page since I'm retired now.89.205.38.27</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D'aww! He matches this background colour I'm seemingly stuck with. Thanks.  (talk) 21:51, January 11, 2016 (UTC)</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hey man, I'm really not trying to edit war. It's just that this guy is constantly removing relevant information and talking to me through edits instead of my talk page. He seems to care more about the formatting than the actual info.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on improvement - I wondered if the section statistics should be later on, or a subsection of \"\"types of accidents\"\"  -I think the references may need tidying so that they are all in the exact same format ie date format etc. I can do that later on, if no-one else does first - if you have any preferences for formatting style on references or want to do it yourself please let me know.\\n\\nThere appears to be a backlog on articles for review so I guess there may be a delay until a reviewer turns up. It's listed in the relevant form eg Wikipedia:Good_article_nominations#Transport  \"</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You, sir, are my hero. Any chance you remember what page that's on?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159287</th>\n",
       "      <td>\":::::And for the second time of asking, when your view completely contradicts the coverage in reliable sources, why should anyone care what you feel? You can't even give a consistent argument - is the opening only supposed to mention significant aspects, or the \"\"most significant\"\" ones?   \\n\\n\"</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159288</th>\n",
       "      <td>You should be ashamed of yourself \\n\\nThat is a horrible thing you put on my talk page.  128.61.19.93</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159289</th>\n",
       "      <td>Spitzer \\n\\nUmm, theres no actual article for prostitution ring.  - Crunch Captain.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159290</th>\n",
       "      <td>And it looks like it was actually you who put on the speedy to have the first version deleted now that I look at it.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159291</th>\n",
       "      <td>\"\\nAnd ... I really don't think you understand.  I came here and my idea was bad right away.  What kind of community goes \"\"you have bad ideas\"\" go away, instead of helping rewrite them.   \"</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>159292 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      text  \\\n",
       "0                                                                                                                                                                                                                                                                                                                                                                                Explanation\\nWhy the edits made under my username Hardcore Metallica Fan were reverted? They weren't vandalisms, just closure on some GAs after I voted at New York Dolls FAC. And please don't remove the template from the talk page since I'm retired now.89.205.38.27   \n",
       "1                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         D'aww! He matches this background colour I'm seemingly stuck with. Thanks.  (talk) 21:51, January 11, 2016 (UTC)   \n",
       "2                                                                                                                                                                                                                                                                                                                                                                                                                Hey man, I'm really not trying to edit war. It's just that this guy is constantly removing relevant information and talking to me through edits instead of my talk page. He seems to care more about the formatting than the actual info.   \n",
       "3       \"\\nMore\\nI can't make any real suggestions on improvement - I wondered if the section statistics should be later on, or a subsection of \"\"types of accidents\"\"  -I think the references may need tidying so that they are all in the exact same format ie date format etc. I can do that later on, if no-one else does first - if you have any preferences for formatting style on references or want to do it yourself please let me know.\\n\\nThere appears to be a backlog on articles for review so I guess there may be a delay until a reviewer turns up. It's listed in the relevant form eg Wikipedia:Good_article_nominations#Transport  \"   \n",
       "4                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      You, sir, are my hero. Any chance you remember what page that's on?   \n",
       "...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    ...   \n",
       "159287                                                                                                                                                                                                                                                                                                                                           \":::::And for the second time of asking, when your view completely contradicts the coverage in reliable sources, why should anyone care what you feel? You can't even give a consistent argument - is the opening only supposed to mention significant aspects, or the \"\"most significant\"\" ones?   \\n\\n\"   \n",
       "159288                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               You should be ashamed of yourself \\n\\nThat is a horrible thing you put on my talk page.  128.61.19.93   \n",
       "159289                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 Spitzer \\n\\nUmm, theres no actual article for prostitution ring.  - Crunch Captain.   \n",
       "159290                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                And it looks like it was actually you who put on the speedy to have the first version deleted now that I look at it.   \n",
       "159291                                                                                                                                                                                                                                                                                                                                                                                                                                                      \"\\nAnd ... I really don't think you understand.  I came here and my idea was bad right away.  What kind of community goes \"\"you have bad ideas\"\" go away, instead of helping rewrite them.   \"   \n",
       "\n",
       "        toxic  \n",
       "0           0  \n",
       "1           0  \n",
       "2           0  \n",
       "3           0  \n",
       "4           0  \n",
       "...       ...  \n",
       "159287      0  \n",
       "159288      0  \n",
       "159289      0  \n",
       "159290      0  \n",
       "159291      0  \n",
       "\n",
       "[159292 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data.drop(columns=['Unnamed: 0'])\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Главная цель поставленной задачи определить относится ли текст/ комментарий к токсичному или же нет. Данная задача относится к задачам классификации, следует посмотреть как распределенны классы по целевому столбцу ***toxic***."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    143106\n",
      "1     16186\n",
      "Name: toxic, dtype: int64\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(data['toxic'].value_counts())\n",
    "\n",
    "data['toxic'].value_counts().plot(kind='bar')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Классы разнятся в 8.8 раз\n"
     ]
    }
   ],
   "source": [
    "difference = data['toxic'].value_counts()[0] / data['toxic'].value_counts()[1]\n",
    "print(f'Классы разнятся в {difference.round(1)} раз')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Есть дисбаланс классов, положительных отзывов почти в 9 раз больше чем токсичных/ отрицательных. При обучении модели следует это учесть."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Так как выборка достаточно большая и процесс обработки и лемматизации занимает достаточно большое количество времени, из генеральной совокупности возьмем только 70% данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    100155\n",
      "1     11349\n",
      "Name: toxic, dtype: int64\n",
      "После сокращения данных классы разнятся в 8.8 раз\n"
     ]
    }
   ],
   "source": [
    "data = data.sample(int(data.shape[0] * 0.7))\n",
    "print(data['toxic'].value_counts())\n",
    "difference = data['toxic'].value_counts()[0] / data['toxic'].value_counts()[1]\n",
    "print(f'После сокращения данных классы разнятся в {difference.round(1)} раз')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В тексте присутствуют разные регистры, а также символы и числа. Обработаем данные и уберем все лижние."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['text'] = data['text'].map(lambda x: x.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#функция для определения POS-тега \n",
    "def get_wordnet_pos(word):\n",
    "    tag = nltk.pos_tag([word])[0][1][0].upper()\n",
    "    tag_dict = {'J': wordnet.ADJ\n",
    "                , 'N': wordnet.NOUN\n",
    "                , 'V': wordnet.VERB\n",
    "                , 'R': wordnet.ADV\n",
    "               }  \n",
    "    return tag_dict.get(tag, wordnet.NOUN)\n",
    "\n",
    "def lemmat_text(text):\n",
    "    text = [lemmat.lemmatize(word, get_wordnet_pos(word)) for word in text]\n",
    "    return ' '.join(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 33min 22s\n",
      "Wall time: 34min 26s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "stop_words = stopwords.words('english')\n",
    "lemmat = WordNetLemmatizer()\n",
    "\n",
    "#токенизировал/ разделил строки на отдельные слова\n",
    "data['text_clean'] = data['text'].map(lambda x: nltk.word_tokenize(x, language = 'english'))\n",
    "#print(1, data['text_clean'][1])\n",
    "\n",
    "#проверил и удалил встречающиеся стоп слова\n",
    "data['text_clean'] = data['text_clean'].map(lambda x: [word for word in x if word not in stop_words])\n",
    "#print(2, data['text_clean'][1])\n",
    "\n",
    "#собрал из слов предложение\n",
    "data['text_clean'] = data['text_clean'].map(lambda x: ' '.join(x))\n",
    "#print(3, data['text_clean'][1])\n",
    "\n",
    "#удалил из предложений все лишние знаки\n",
    "data['text_clean'] = data['text_clean'].map(lambda x: re.sub(r'((www\\.[^\\s]+)|(https?://[^\\s]+)|(http?://[^\\s]+))', 'ssite', x))\n",
    "data['text_clean'] = data['text_clean'].map(lambda x: re.sub(r'(@[^s]+)', 'polzovatel', x))\n",
    "#print(4, data['text_clean'][1])\n",
    "\n",
    "stop_words.append('ssite')\n",
    "stop_words.append('polzovatel')\n",
    "\n",
    "data['text_clean'] = data['text_clean'].map(lambda x: re.sub(r'[^a-z]', ' ', x))\n",
    "#print(5, data['text_clean'][1])\n",
    "\n",
    "#снова токенизировал/ разделил строки на отдельные слова\n",
    "data['text_clean'] = data['text_clean'].map(lambda x: nltk.word_tokenize(x, language = 'english'))\n",
    "#print(6, data['text_clean'][1])\n",
    "\n",
    "#проверил и удалили встречающиеся стоп слова\n",
    "data['text_clean'] = data['text_clean'].map(lambda x: [word for word in x if word not in stop_words])                                      \n",
    "#print(7, data['text_clean'][1])\n",
    "\n",
    "#data['text_clean'] = data['text_clean'].apply(lemmat_text)print(8, data['text_clean'][1])\n",
    "\n",
    "#лематтизировал слова, привел к начальной форме и собрал из слов предложение\n",
    "data['text_clean'] = data['text_clean'].apply(lemmat_text)\n",
    "#print(8, data['text_clean'][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обучение"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выделим отдельно целевой и общий признак."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data['text_clean']\n",
    "y = data['toxic']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разделим наш датасет на обучающую и тестовую выборки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(89203,)\n",
      "(22301,)\n",
      "(89203,)\n",
      "(22301,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, shuffle=True, random_state=RANDOM_STATE, test_size=0.2)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(89203, 105072)\n",
      "(22301, 105072)\n"
     ]
    }
   ],
   "source": [
    "stopwords = set(nltk_stopwords.words('english'))\n",
    "count_tf_idf = TfidfVectorizer(stop_words=stopwords)\n",
    "\n",
    "X_train = count_tf_idf.fit_transform(X_train)\n",
    "X_test = count_tf_idf.transform(X_test)\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#напишем функцию для моделей с учетом дисбаланса классов\n",
    "def cv_model(model, params, X, y):\n",
    "    best_model = GridSearchCV(estimator = model\n",
    "                              , param_grid = params\n",
    "                              , scoring = 'f1'\n",
    "                              #, n_jobs=-1\n",
    "                              , cv = 5\n",
    "                              , verbose = 5\n",
    "                             )\n",
    "    return best_model.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Обучим модель LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "[CV 1/5] END clf__class_weight=balanced, clf__max_iter=500, clf__penalty=l2, clf__random_state=12345, clf__solver=lbfgs;, score=0.747 total time=   2.1s\n",
      "[CV 2/5] END clf__class_weight=balanced, clf__max_iter=500, clf__penalty=l2, clf__random_state=12345, clf__solver=lbfgs;, score=0.742 total time=   2.9s\n",
      "[CV 3/5] END clf__class_weight=balanced, clf__max_iter=500, clf__penalty=l2, clf__random_state=12345, clf__solver=lbfgs;, score=0.733 total time=   1.8s\n",
      "[CV 4/5] END clf__class_weight=balanced, clf__max_iter=500, clf__penalty=l2, clf__random_state=12345, clf__solver=lbfgs;, score=0.742 total time=   2.6s\n",
      "[CV 5/5] END clf__class_weight=balanced, clf__max_iter=500, clf__penalty=l2, clf__random_state=12345, clf__solver=lbfgs;, score=0.743 total time=   1.5s\n",
      "[CV 1/5] END clf__class_weight=balanced, clf__max_iter=500, clf__penalty=l2, clf__random_state=12345, clf__solver=liblinear;, score=0.747 total time=   0.6s\n",
      "[CV 2/5] END clf__class_weight=balanced, clf__max_iter=500, clf__penalty=l2, clf__random_state=12345, clf__solver=liblinear;, score=0.742 total time=   0.6s\n",
      "[CV 3/5] END clf__class_weight=balanced, clf__max_iter=500, clf__penalty=l2, clf__random_state=12345, clf__solver=liblinear;, score=0.733 total time=   0.6s\n",
      "[CV 4/5] END clf__class_weight=balanced, clf__max_iter=500, clf__penalty=l2, clf__random_state=12345, clf__solver=liblinear;, score=0.742 total time=   0.7s\n",
      "[CV 5/5] END clf__class_weight=balanced, clf__max_iter=500, clf__penalty=l2, clf__random_state=12345, clf__solver=liblinear;, score=0.743 total time=   0.6s\n",
      "[CV 1/5] END clf__class_weight=balanced, clf__max_iter=500, clf__penalty=l1, clf__random_state=12345, clf__solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5] END clf__class_weight=balanced, clf__max_iter=500, clf__penalty=l1, clf__random_state=12345, clf__solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5] END clf__class_weight=balanced, clf__max_iter=500, clf__penalty=l1, clf__random_state=12345, clf__solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5] END clf__class_weight=balanced, clf__max_iter=500, clf__penalty=l1, clf__random_state=12345, clf__solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5] END clf__class_weight=balanced, clf__max_iter=500, clf__penalty=l1, clf__random_state=12345, clf__solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/5] END clf__class_weight=balanced, clf__max_iter=500, clf__penalty=l1, clf__random_state=12345, clf__solver=liblinear;, score=0.744 total time=   0.6s\n",
      "[CV 2/5] END clf__class_weight=balanced, clf__max_iter=500, clf__penalty=l1, clf__random_state=12345, clf__solver=liblinear;, score=0.740 total time=   0.6s\n",
      "[CV 3/5] END clf__class_weight=balanced, clf__max_iter=500, clf__penalty=l1, clf__random_state=12345, clf__solver=liblinear;, score=0.729 total time=   0.5s\n",
      "[CV 4/5] END clf__class_weight=balanced, clf__max_iter=500, clf__penalty=l1, clf__random_state=12345, clf__solver=liblinear;, score=0.743 total time=   0.6s\n",
      "[CV 5/5] END clf__class_weight=balanced, clf__max_iter=500, clf__penalty=l1, clf__random_state=12345, clf__solver=liblinear;, score=0.745 total time=   0.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TFL\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "5 fits failed out of a total of 20.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TFL\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TFL\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 394, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"C:\\Users\\TFL\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TFL\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\TFL\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [0.74130238 0.74126558        nan 0.74008994]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Лучшие параметры модели LogisticRegression: {'clf__class_weight': 'balanced', 'clf__max_iter': 500, 'clf__penalty': 'l2', 'clf__random_state': 12345, 'clf__solver': 'lbfgs'}\n",
      "Лучший показатель RMSE для LogisticRegression: 0.7413023785904349\n",
      "Wall time: 21 s\n"
     ]
    }
   ],
   "source": [
    "#%%time\n",
    "\n",
    "#pipe_lr = Pipeline([('clf', LogisticRegression())])\n",
    "\n",
    "#grid_params_lr = [{'clf__random_state': [RANDOM_STATE]\n",
    "#                , 'clf__solver': ['lbfgs', 'liblinear']\n",
    "#                , 'clf__max_iter': [500]\n",
    "#                , 'clf__penalty': ['l2', 'l1']\n",
    "#                , 'clf__class_weight': ['balanced']\n",
    "#               }]\n",
    "\n",
    "#best_model_lr = cv_model(pipe_lr\n",
    "#                         , grid_params_lr \n",
    "#                         , X_train\n",
    "#                         , y_train)\n",
    "#print(f'Лучшие параметры модели LogisticRegression: {best_model_lr.best_params_}')\n",
    "#print(f'Лучший показатель RMSE для LogisticRegression: {best_model_lr.best_score_}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "[CV 1/5] END class_weight=balanced, max_iter=700, penalty=l2, random_state=12345, solver=lbfgs;, score=0.740 total time=   1.8s\n",
      "[CV 2/5] END class_weight=balanced, max_iter=700, penalty=l2, random_state=12345, solver=lbfgs;, score=0.754 total time=   1.6s\n",
      "[CV 3/5] END class_weight=balanced, max_iter=700, penalty=l2, random_state=12345, solver=lbfgs;, score=0.748 total time=   2.3s\n",
      "[CV 4/5] END class_weight=balanced, max_iter=700, penalty=l2, random_state=12345, solver=lbfgs;, score=0.745 total time=   1.4s\n",
      "[CV 5/5] END class_weight=balanced, max_iter=700, penalty=l2, random_state=12345, solver=lbfgs;, score=0.736 total time=   2.0s\n",
      "[CV 1/5] END class_weight=balanced, max_iter=700, penalty=l2, random_state=12345, solver=liblinear;, score=0.740 total time=   0.6s\n",
      "[CV 2/5] END class_weight=balanced, max_iter=700, penalty=l2, random_state=12345, solver=liblinear;, score=0.754 total time=   0.8s\n",
      "[CV 3/5] END class_weight=balanced, max_iter=700, penalty=l2, random_state=12345, solver=liblinear;, score=0.748 total time=   0.7s\n",
      "[CV 4/5] END class_weight=balanced, max_iter=700, penalty=l2, random_state=12345, solver=liblinear;, score=0.745 total time=   0.7s\n",
      "[CV 5/5] END class_weight=balanced, max_iter=700, penalty=l2, random_state=12345, solver=liblinear;, score=0.736 total time=   0.6s\n",
      "[CV 1/5] END class_weight=balanced, max_iter=700, penalty=l1, random_state=12345, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5] END class_weight=balanced, max_iter=700, penalty=l1, random_state=12345, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5] END class_weight=balanced, max_iter=700, penalty=l1, random_state=12345, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5] END class_weight=balanced, max_iter=700, penalty=l1, random_state=12345, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5] END class_weight=balanced, max_iter=700, penalty=l1, random_state=12345, solver=lbfgs;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\79174\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END class_weight=balanced, max_iter=700, penalty=l1, random_state=12345, solver=liblinear;, score=0.737 total time=47.6min\n",
      "[CV 2/5] END class_weight=balanced, max_iter=700, penalty=l1, random_state=12345, solver=liblinear;, score=0.753 total time=   0.7s\n",
      "[CV 3/5] END class_weight=balanced, max_iter=700, penalty=l1, random_state=12345, solver=liblinear;, score=0.744 total time=   0.9s\n",
      "[CV 4/5] END class_weight=balanced, max_iter=700, penalty=l1, random_state=12345, solver=liblinear;, score=0.746 total time=   0.8s\n",
      "[CV 5/5] END class_weight=balanced, max_iter=700, penalty=l1, random_state=12345, solver=liblinear;, score=0.738 total time=   0.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\79174\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "5 fits failed out of a total of 20.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\79174\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\79174\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\79174\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\79174\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [0.74478677 0.7447868         nan 0.74360088]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Лучшие параметры модели LogisticRegression: {'class_weight': 'balanced', 'max_iter': 700, 'penalty': 'l2', 'random_state': 12345, 'solver': 'liblinear'}\n",
      "Лучший показатель RMSE для LogisticRegression: 0.7447868041321499\n",
      "CPU times: total: 48min 24s\n",
      "Wall time: 47min 53s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "parametrs_lr = {'random_state': [RANDOM_STATE]\n",
    "                , 'solver': ['lbfgs', 'liblinear']\n",
    "                , 'max_iter': [700]\n",
    "                , 'penalty': ['l2', 'l1']\n",
    "                , 'class_weight': ['balanced']\n",
    "               }\n",
    "\n",
    "best_model_lr = cv_model(LogisticRegression()\n",
    "                    , parametrs_lr \n",
    "                    , X_train\n",
    "                    , y_train)\n",
    "print(f'Лучшие параметры модели LogisticRegression: {best_model_lr.best_params_}')\n",
    "print(f'Лучший показатель RMSE для LogisticRegression: {best_model_lr.best_score_}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Обучим модель SGDClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 15 candidates, totalling 75 fits\n",
      "[CV 1/5] END class_weight=balanced, loss=hinge, max_iter=700, penalty=l2, random_state=12345;, score=0.721 total time=   0.2s\n",
      "[CV 2/5] END class_weight=balanced, loss=hinge, max_iter=700, penalty=l2, random_state=12345;, score=0.742 total time=   0.2s\n",
      "[CV 3/5] END class_weight=balanced, loss=hinge, max_iter=700, penalty=l2, random_state=12345;, score=0.735 total time=   0.2s\n",
      "[CV 4/5] END class_weight=balanced, loss=hinge, max_iter=700, penalty=l2, random_state=12345;, score=0.744 total time=   0.2s\n",
      "[CV 5/5] END class_weight=balanced, loss=hinge, max_iter=700, penalty=l2, random_state=12345;, score=0.729 total time=   0.1s\n",
      "[CV 1/5] END class_weight=balanced, loss=hinge, max_iter=700, penalty=l1, random_state=12345;, score=0.712 total time=   0.7s\n",
      "[CV 2/5] END class_weight=balanced, loss=hinge, max_iter=700, penalty=l1, random_state=12345;, score=0.717 total time=   0.9s\n",
      "[CV 3/5] END class_weight=balanced, loss=hinge, max_iter=700, penalty=l1, random_state=12345;, score=0.719 total time=   1.0s\n",
      "[CV 4/5] END class_weight=balanced, loss=hinge, max_iter=700, penalty=l1, random_state=12345;, score=0.721 total time=   0.6s\n",
      "[CV 5/5] END class_weight=balanced, loss=hinge, max_iter=700, penalty=l1, random_state=12345;, score=0.717 total time=   0.6s\n",
      "[CV 1/5] END class_weight=balanced, loss=hinge, max_iter=700, penalty=elasticnet, random_state=12345;, score=0.724 total time=   0.6s\n",
      "[CV 2/5] END class_weight=balanced, loss=hinge, max_iter=700, penalty=elasticnet, random_state=12345;, score=0.739 total time=   0.3s\n",
      "[CV 3/5] END class_weight=balanced, loss=hinge, max_iter=700, penalty=elasticnet, random_state=12345;, score=0.738 total time=   0.3s\n",
      "[CV 4/5] END class_weight=balanced, loss=hinge, max_iter=700, penalty=elasticnet, random_state=12345;, score=0.745 total time=   0.3s\n",
      "[CV 5/5] END class_weight=balanced, loss=hinge, max_iter=700, penalty=elasticnet, random_state=12345;, score=0.733 total time=   0.3s\n",
      "[CV 1/5] END class_weight=balanced, loss=log, max_iter=700, penalty=l2, random_state=12345;, score=0.701 total time=   0.2s\n",
      "[CV 2/5] END class_weight=balanced, loss=log, max_iter=700, penalty=l2, random_state=12345;, score=0.715 total time=   0.1s\n",
      "[CV 3/5] END class_weight=balanced, loss=log, max_iter=700, penalty=l2, random_state=12345;, score=0.713 total time=   0.2s\n",
      "[CV 4/5] END class_weight=balanced, loss=log, max_iter=700, penalty=l2, random_state=12345;, score=0.704 total time=   0.1s\n",
      "[CV 5/5] END class_weight=balanced, loss=log, max_iter=700, penalty=l2, random_state=12345;, score=0.705 total time=   0.2s\n",
      "[CV 1/5] END class_weight=balanced, loss=log, max_iter=700, penalty=l1, random_state=12345;, score=0.713 total time=   0.5s\n",
      "[CV 2/5] END class_weight=balanced, loss=log, max_iter=700, penalty=l1, random_state=12345;, score=0.722 total time=   0.2s\n",
      "[CV 3/5] END class_weight=balanced, loss=log, max_iter=700, penalty=l1, random_state=12345;, score=0.712 total time=   0.2s\n",
      "[CV 4/5] END class_weight=balanced, loss=log, max_iter=700, penalty=l1, random_state=12345;, score=0.720 total time=   0.4s\n",
      "[CV 5/5] END class_weight=balanced, loss=log, max_iter=700, penalty=l1, random_state=12345;, score=0.720 total time=   0.4s\n",
      "[CV 1/5] END class_weight=balanced, loss=log, max_iter=700, penalty=elasticnet, random_state=12345;, score=0.697 total time=   0.6s\n",
      "[CV 2/5] END class_weight=balanced, loss=log, max_iter=700, penalty=elasticnet, random_state=12345;, score=0.711 total time=   0.3s\n",
      "[CV 3/5] END class_weight=balanced, loss=log, max_iter=700, penalty=elasticnet, random_state=12345;, score=0.708 total time=   0.6s\n",
      "[CV 4/5] END class_weight=balanced, loss=log, max_iter=700, penalty=elasticnet, random_state=12345;, score=0.700 total time=   0.6s\n",
      "[CV 5/5] END class_weight=balanced, loss=log, max_iter=700, penalty=elasticnet, random_state=12345;, score=0.705 total time=   0.4s\n",
      "[CV 1/5] END class_weight=balanced, loss=modified_huber, max_iter=700, penalty=l2, random_state=12345;, score=0.744 total time=   0.3s\n",
      "[CV 2/5] END class_weight=balanced, loss=modified_huber, max_iter=700, penalty=l2, random_state=12345;, score=0.759 total time=   0.2s\n",
      "[CV 3/5] END class_weight=balanced, loss=modified_huber, max_iter=700, penalty=l2, random_state=12345;, score=0.752 total time=   0.2s\n",
      "[CV 4/5] END class_weight=balanced, loss=modified_huber, max_iter=700, penalty=l2, random_state=12345;, score=0.748 total time=   0.2s\n",
      "[CV 5/5] END class_weight=balanced, loss=modified_huber, max_iter=700, penalty=l2, random_state=12345;, score=0.741 total time=   0.1s\n",
      "[CV 1/5] END class_weight=balanced, loss=modified_huber, max_iter=700, penalty=l1, random_state=12345;, score=0.675 total time=   5.3s\n",
      "[CV 2/5] END class_weight=balanced, loss=modified_huber, max_iter=700, penalty=l1, random_state=12345;, score=0.673 total time=   5.1s\n",
      "[CV 3/5] END class_weight=balanced, loss=modified_huber, max_iter=700, penalty=l1, random_state=12345;, score=0.673 total time=   4.8s\n",
      "[CV 4/5] END class_weight=balanced, loss=modified_huber, max_iter=700, penalty=l1, random_state=12345;, score=0.669 total time=   5.0s\n",
      "[CV 5/5] END class_weight=balanced, loss=modified_huber, max_iter=700, penalty=l1, random_state=12345;, score=0.660 total time=   5.9s\n",
      "[CV 1/5] END class_weight=balanced, loss=modified_huber, max_iter=700, penalty=elasticnet, random_state=12345;, score=0.739 total time=   0.5s\n",
      "[CV 2/5] END class_weight=balanced, loss=modified_huber, max_iter=700, penalty=elasticnet, random_state=12345;, score=0.752 total time=   0.5s\n",
      "[CV 3/5] END class_weight=balanced, loss=modified_huber, max_iter=700, penalty=elasticnet, random_state=12345;, score=0.747 total time=   0.8s\n",
      "[CV 4/5] END class_weight=balanced, loss=modified_huber, max_iter=700, penalty=elasticnet, random_state=12345;, score=0.750 total time=   0.5s\n",
      "[CV 5/5] END class_weight=balanced, loss=modified_huber, max_iter=700, penalty=elasticnet, random_state=12345;, score=0.731 total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\79174\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:696: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END class_weight=balanced, loss=squared_hinge, max_iter=700, penalty=l2, random_state=12345;, score=0.691 total time=  10.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\79174\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:696: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END class_weight=balanced, loss=squared_hinge, max_iter=700, penalty=l2, random_state=12345;, score=0.710 total time=  11.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\79174\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:696: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END class_weight=balanced, loss=squared_hinge, max_iter=700, penalty=l2, random_state=12345;, score=0.701 total time=  10.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\79174\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:696: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END class_weight=balanced, loss=squared_hinge, max_iter=700, penalty=l2, random_state=12345;, score=0.691 total time=   9.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\79174\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:696: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END class_weight=balanced, loss=squared_hinge, max_iter=700, penalty=l2, random_state=12345;, score=0.690 total time=  11.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\79174\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:696: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END class_weight=balanced, loss=squared_hinge, max_iter=700, penalty=l1, random_state=12345;, score=0.722 total time=  21.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\79174\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:696: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END class_weight=balanced, loss=squared_hinge, max_iter=700, penalty=l1, random_state=12345;, score=0.700 total time=  21.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\79174\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:696: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END class_weight=balanced, loss=squared_hinge, max_iter=700, penalty=l1, random_state=12345;, score=0.704 total time=  22.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\79174\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:696: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END class_weight=balanced, loss=squared_hinge, max_iter=700, penalty=l1, random_state=12345;, score=0.696 total time=  22.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\79174\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:696: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END class_weight=balanced, loss=squared_hinge, max_iter=700, penalty=l1, random_state=12345;, score=0.709 total time=  21.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\79174\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:696: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END class_weight=balanced, loss=squared_hinge, max_iter=700, penalty=elasticnet, random_state=12345;, score=0.700 total time=  21.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\79174\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:696: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END class_weight=balanced, loss=squared_hinge, max_iter=700, penalty=elasticnet, random_state=12345;, score=0.710 total time=  21.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\79174\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:696: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END class_weight=balanced, loss=squared_hinge, max_iter=700, penalty=elasticnet, random_state=12345;, score=0.707 total time=  22.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\79174\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:696: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END class_weight=balanced, loss=squared_hinge, max_iter=700, penalty=elasticnet, random_state=12345;, score=0.699 total time=  22.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\79174\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:696: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END class_weight=balanced, loss=squared_hinge, max_iter=700, penalty=elasticnet, random_state=12345;, score=0.694 total time=  21.6s\n",
      "[CV 1/5] END class_weight=balanced, loss=perceptron, max_iter=700, penalty=l2, random_state=12345;, score=0.710 total time=   0.1s\n",
      "[CV 2/5] END class_weight=balanced, loss=perceptron, max_iter=700, penalty=l2, random_state=12345;, score=0.706 total time=   0.1s\n",
      "[CV 3/5] END class_weight=balanced, loss=perceptron, max_iter=700, penalty=l2, random_state=12345;, score=0.705 total time=   0.1s\n",
      "[CV 4/5] END class_weight=balanced, loss=perceptron, max_iter=700, penalty=l2, random_state=12345;, score=0.708 total time=   0.1s\n",
      "[CV 5/5] END class_weight=balanced, loss=perceptron, max_iter=700, penalty=l2, random_state=12345;, score=0.701 total time=   0.1s\n",
      "[CV 1/5] END class_weight=balanced, loss=perceptron, max_iter=700, penalty=l1, random_state=12345;, score=0.615 total time=   0.4s\n",
      "[CV 2/5] END class_weight=balanced, loss=perceptron, max_iter=700, penalty=l1, random_state=12345;, score=0.511 total time=   0.3s\n",
      "[CV 3/5] END class_weight=balanced, loss=perceptron, max_iter=700, penalty=l1, random_state=12345;, score=0.600 total time=   0.4s\n",
      "[CV 4/5] END class_weight=balanced, loss=perceptron, max_iter=700, penalty=l1, random_state=12345;, score=0.608 total time=   0.4s\n",
      "[CV 5/5] END class_weight=balanced, loss=perceptron, max_iter=700, penalty=l1, random_state=12345;, score=0.368 total time=   0.4s\n",
      "[CV 1/5] END class_weight=balanced, loss=perceptron, max_iter=700, penalty=elasticnet, random_state=12345;, score=0.640 total time=   0.2s\n",
      "[CV 2/5] END class_weight=balanced, loss=perceptron, max_iter=700, penalty=elasticnet, random_state=12345;, score=0.480 total time=   0.1s\n",
      "[CV 3/5] END class_weight=balanced, loss=perceptron, max_iter=700, penalty=elasticnet, random_state=12345;, score=0.582 total time=   0.2s\n",
      "[CV 4/5] END class_weight=balanced, loss=perceptron, max_iter=700, penalty=elasticnet, random_state=12345;, score=0.461 total time=   0.2s\n",
      "[CV 5/5] END class_weight=balanced, loss=perceptron, max_iter=700, penalty=elasticnet, random_state=12345;, score=0.576 total time=   0.2s\n",
      "Лучшие параметры модели SGDClassifier: {'class_weight': 'balanced', 'loss': 'modified_huber', 'max_iter': 700, 'penalty': 'l2', 'random_state': 12345}\n",
      "Лучший показатель RMSE для SGDClassifier: 0.7487866215280784\n",
      "CPU times: total: 6min 7s\n",
      "Wall time: 5min 25s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "parametrs_sgdc = {'random_state': [RANDOM_STATE]\n",
    "                  , 'loss': ['hinge', 'log', 'modified_huber', 'squared_hinge', 'perceptron']\n",
    "                  , 'max_iter': [700]\n",
    "                  , 'penalty': ['l2', 'l1', 'elasticnet']\n",
    "                  , 'class_weight': ['balanced']}\n",
    "best_model_sgdc = cv_model(SGDClassifier()\n",
    "                          , parametrs_sgdc\n",
    "                          , X_train\n",
    "                          , y_train)\n",
    "\n",
    "print(f'Лучшие параметры модели SGDClassifier: {best_model_sgdc.best_params_}')\n",
    "print(f'Лучший показатель RMSE для SGDClassifier: {best_model_sgdc.best_score_}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Обучим модель LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\79174\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=0.2, class_weight=balanced, loss=hinge, max_iter=700, penalty=l2, random_state=12345;, score=0.723 total time=   0.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\79174\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=0.2, class_weight=balanced, loss=hinge, max_iter=700, penalty=l2, random_state=12345;, score=0.746 total time=   0.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\79174\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=0.2, class_weight=balanced, loss=hinge, max_iter=700, penalty=l2, random_state=12345;, score=0.740 total time=   0.6s\n",
      "[CV 4/5] END C=0.2, class_weight=balanced, loss=hinge, max_iter=700, penalty=l2, random_state=12345;, score=0.744 total time=   0.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\79174\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=0.2, class_weight=balanced, loss=hinge, max_iter=700, penalty=l2, random_state=12345;, score=0.732 total time=   0.6s\n",
      "[CV 1/5] END C=0.2, class_weight=balanced, loss=hinge, max_iter=700, penalty=l1, random_state=12345;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.2, class_weight=balanced, loss=hinge, max_iter=700, penalty=l1, random_state=12345;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.2, class_weight=balanced, loss=hinge, max_iter=700, penalty=l1, random_state=12345;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.2, class_weight=balanced, loss=hinge, max_iter=700, penalty=l1, random_state=12345;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.2, class_weight=balanced, loss=hinge, max_iter=700, penalty=l1, random_state=12345;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.2, class_weight=balanced, loss=squared_hinge, max_iter=700, penalty=l2, random_state=12345;, score=0.746 total time=   0.6s\n",
      "[CV 2/5] END C=0.2, class_weight=balanced, loss=squared_hinge, max_iter=700, penalty=l2, random_state=12345;, score=0.762 total time=   0.6s\n",
      "[CV 3/5] END C=0.2, class_weight=balanced, loss=squared_hinge, max_iter=700, penalty=l2, random_state=12345;, score=0.758 total time=   0.6s\n",
      "[CV 4/5] END C=0.2, class_weight=balanced, loss=squared_hinge, max_iter=700, penalty=l2, random_state=12345;, score=0.755 total time=   0.5s\n",
      "[CV 5/5] END C=0.2, class_weight=balanced, loss=squared_hinge, max_iter=700, penalty=l2, random_state=12345;, score=0.746 total time=   0.6s\n",
      "[CV 1/5] END C=0.2, class_weight=balanced, loss=squared_hinge, max_iter=700, penalty=l1, random_state=12345;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.2, class_weight=balanced, loss=squared_hinge, max_iter=700, penalty=l1, random_state=12345;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.2, class_weight=balanced, loss=squared_hinge, max_iter=700, penalty=l1, random_state=12345;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.2, class_weight=balanced, loss=squared_hinge, max_iter=700, penalty=l1, random_state=12345;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.2, class_weight=balanced, loss=squared_hinge, max_iter=700, penalty=l1, random_state=12345;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\79174\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=0.3, class_weight=balanced, loss=hinge, max_iter=700, penalty=l2, random_state=12345;, score=0.732 total time=   0.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\79174\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=0.3, class_weight=balanced, loss=hinge, max_iter=700, penalty=l2, random_state=12345;, score=0.748 total time=   0.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\79174\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=0.3, class_weight=balanced, loss=hinge, max_iter=700, penalty=l2, random_state=12345;, score=0.741 total time=   0.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\79174\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=0.3, class_weight=balanced, loss=hinge, max_iter=700, penalty=l2, random_state=12345;, score=0.746 total time=   0.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\79174\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=0.3, class_weight=balanced, loss=hinge, max_iter=700, penalty=l2, random_state=12345;, score=0.736 total time=   0.7s\n",
      "[CV 1/5] END C=0.3, class_weight=balanced, loss=hinge, max_iter=700, penalty=l1, random_state=12345;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.3, class_weight=balanced, loss=hinge, max_iter=700, penalty=l1, random_state=12345;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.3, class_weight=balanced, loss=hinge, max_iter=700, penalty=l1, random_state=12345;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.3, class_weight=balanced, loss=hinge, max_iter=700, penalty=l1, random_state=12345;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.3, class_weight=balanced, loss=hinge, max_iter=700, penalty=l1, random_state=12345;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.3, class_weight=balanced, loss=squared_hinge, max_iter=700, penalty=l2, random_state=12345;, score=0.749 total time=   0.6s\n",
      "[CV 2/5] END C=0.3, class_weight=balanced, loss=squared_hinge, max_iter=700, penalty=l2, random_state=12345;, score=0.762 total time=   0.6s\n",
      "[CV 3/5] END C=0.3, class_weight=balanced, loss=squared_hinge, max_iter=700, penalty=l2, random_state=12345;, score=0.761 total time=   0.6s\n",
      "[CV 4/5] END C=0.3, class_weight=balanced, loss=squared_hinge, max_iter=700, penalty=l2, random_state=12345;, score=0.758 total time=   0.7s\n",
      "[CV 5/5] END C=0.3, class_weight=balanced, loss=squared_hinge, max_iter=700, penalty=l2, random_state=12345;, score=0.747 total time=   0.8s\n",
      "[CV 1/5] END C=0.3, class_weight=balanced, loss=squared_hinge, max_iter=700, penalty=l1, random_state=12345;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.3, class_weight=balanced, loss=squared_hinge, max_iter=700, penalty=l1, random_state=12345;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.3, class_weight=balanced, loss=squared_hinge, max_iter=700, penalty=l1, random_state=12345;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.3, class_weight=balanced, loss=squared_hinge, max_iter=700, penalty=l1, random_state=12345;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.3, class_weight=balanced, loss=squared_hinge, max_iter=700, penalty=l1, random_state=12345;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\79174\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=0.4, class_weight=balanced, loss=hinge, max_iter=700, penalty=l2, random_state=12345;, score=0.737 total time=   1.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\79174\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=0.4, class_weight=balanced, loss=hinge, max_iter=700, penalty=l2, random_state=12345;, score=0.749 total time=   1.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\79174\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=0.4, class_weight=balanced, loss=hinge, max_iter=700, penalty=l2, random_state=12345;, score=0.745 total time=   1.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\79174\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=0.4, class_weight=balanced, loss=hinge, max_iter=700, penalty=l2, random_state=12345;, score=0.747 total time=   1.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\79174\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=0.4, class_weight=balanced, loss=hinge, max_iter=700, penalty=l2, random_state=12345;, score=0.734 total time=   1.1s\n",
      "[CV 1/5] END C=0.4, class_weight=balanced, loss=hinge, max_iter=700, penalty=l1, random_state=12345;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.4, class_weight=balanced, loss=hinge, max_iter=700, penalty=l1, random_state=12345;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.4, class_weight=balanced, loss=hinge, max_iter=700, penalty=l1, random_state=12345;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.4, class_weight=balanced, loss=hinge, max_iter=700, penalty=l1, random_state=12345;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.4, class_weight=balanced, loss=hinge, max_iter=700, penalty=l1, random_state=12345;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.4, class_weight=balanced, loss=squared_hinge, max_iter=700, penalty=l2, random_state=12345;, score=0.751 total time=   0.9s\n",
      "[CV 2/5] END C=0.4, class_weight=balanced, loss=squared_hinge, max_iter=700, penalty=l2, random_state=12345;, score=0.761 total time=   0.9s\n",
      "[CV 3/5] END C=0.4, class_weight=balanced, loss=squared_hinge, max_iter=700, penalty=l2, random_state=12345;, score=0.762 total time=   0.9s\n",
      "[CV 4/5] END C=0.4, class_weight=balanced, loss=squared_hinge, max_iter=700, penalty=l2, random_state=12345;, score=0.756 total time=   0.9s\n",
      "[CV 5/5] END C=0.4, class_weight=balanced, loss=squared_hinge, max_iter=700, penalty=l2, random_state=12345;, score=0.746 total time=   0.8s\n",
      "[CV 1/5] END C=0.4, class_weight=balanced, loss=squared_hinge, max_iter=700, penalty=l1, random_state=12345;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.4, class_weight=balanced, loss=squared_hinge, max_iter=700, penalty=l1, random_state=12345;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.4, class_weight=balanced, loss=squared_hinge, max_iter=700, penalty=l1, random_state=12345;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.4, class_weight=balanced, loss=squared_hinge, max_iter=700, penalty=l1, random_state=12345;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.4, class_weight=balanced, loss=squared_hinge, max_iter=700, penalty=l1, random_state=12345;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.5, class_weight=balanced, loss=hinge, max_iter=700, penalty=l2, random_state=12345;, score=0.736 total time=   1.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\79174\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=0.5, class_weight=balanced, loss=hinge, max_iter=700, penalty=l2, random_state=12345;, score=0.752 total time=   1.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\79174\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=0.5, class_weight=balanced, loss=hinge, max_iter=700, penalty=l2, random_state=12345;, score=0.747 total time=   1.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\79174\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=0.5, class_weight=balanced, loss=hinge, max_iter=700, penalty=l2, random_state=12345;, score=0.747 total time=   1.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\79174\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=0.5, class_weight=balanced, loss=hinge, max_iter=700, penalty=l2, random_state=12345;, score=0.736 total time=   1.3s\n",
      "[CV 1/5] END C=0.5, class_weight=balanced, loss=hinge, max_iter=700, penalty=l1, random_state=12345;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.5, class_weight=balanced, loss=hinge, max_iter=700, penalty=l1, random_state=12345;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.5, class_weight=balanced, loss=hinge, max_iter=700, penalty=l1, random_state=12345;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.5, class_weight=balanced, loss=hinge, max_iter=700, penalty=l1, random_state=12345;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.5, class_weight=balanced, loss=hinge, max_iter=700, penalty=l1, random_state=12345;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.5, class_weight=balanced, loss=squared_hinge, max_iter=700, penalty=l2, random_state=12345;, score=0.753 total time=   1.0s\n",
      "[CV 2/5] END C=0.5, class_weight=balanced, loss=squared_hinge, max_iter=700, penalty=l2, random_state=12345;, score=0.762 total time=   1.0s\n",
      "[CV 3/5] END C=0.5, class_weight=balanced, loss=squared_hinge, max_iter=700, penalty=l2, random_state=12345;, score=0.763 total time=   1.0s\n",
      "[CV 4/5] END C=0.5, class_weight=balanced, loss=squared_hinge, max_iter=700, penalty=l2, random_state=12345;, score=0.757 total time=   0.9s\n",
      "[CV 5/5] END C=0.5, class_weight=balanced, loss=squared_hinge, max_iter=700, penalty=l2, random_state=12345;, score=0.745 total time=   1.0s\n",
      "[CV 1/5] END C=0.5, class_weight=balanced, loss=squared_hinge, max_iter=700, penalty=l1, random_state=12345;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.5, class_weight=balanced, loss=squared_hinge, max_iter=700, penalty=l1, random_state=12345;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.5, class_weight=balanced, loss=squared_hinge, max_iter=700, penalty=l1, random_state=12345;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.5, class_weight=balanced, loss=squared_hinge, max_iter=700, penalty=l1, random_state=12345;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.5, class_weight=balanced, loss=squared_hinge, max_iter=700, penalty=l1, random_state=12345;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\79174\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "40 fits failed out of a total of 80.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "20 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\79174\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\79174\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_classes.py\", line 257, in fit\n",
      "    self.coef_, self.intercept_, self.n_iter_ = _fit_liblinear(\n",
      "  File \"C:\\Users\\79174\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 1185, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"C:\\Users\\79174\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 1024, in _get_liblinear_solver_type\n",
      "    raise ValueError(\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "20 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\79174\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\79174\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_classes.py\", line 257, in fit\n",
      "    self.coef_, self.intercept_, self.n_iter_ = _fit_liblinear(\n",
      "  File \"C:\\Users\\79174\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 1185, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"C:\\Users\\79174\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 1024, in _get_liblinear_solver_type\n",
      "    raise ValueError(\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\79174\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [0.73709519        nan 0.75352081        nan 0.74055379        nan\n",
      " 0.755357          nan 0.7423859         nan 0.7554329         nan\n",
      " 0.74366509        nan 0.75581331        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Лучшие параметры модели LinearSVC: {'C': 0.5, 'class_weight': 'balanced', 'loss': 'squared_hinge', 'max_iter': 700, 'penalty': 'l2', 'random_state': 12345}\n",
      "Лучший показатель RMSE для LinearSVC: 0.7558133067868076\n",
      "CPU times: total: 40.5 s\n",
      "Wall time: 41.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "parametrs_lsvc = {'random_state': [RANDOM_STATE]\n",
    "                  , 'loss': ['hinge', 'squared_hinge']\n",
    "                  , 'C': [0.2, 0.3, 0.4, 0.5]\n",
    "                  , 'max_iter': [700]\n",
    "                  , 'penalty': ['l2', 'l1']\n",
    "                  , 'class_weight': ['balanced']}\n",
    "best_model_lsvc = cv_model(LinearSVC()\n",
    "                          , parametrs_lsvc\n",
    "                          , X_train\n",
    "                          , y_train)\n",
    "\n",
    "print(f'Лучшие параметры модели LinearSVC: {best_model_lsvc.best_params_}')\n",
    "print(f'Лучший показатель RMSE для LinearSVC: {best_model_lsvc.best_score_}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Обучим модель DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 7 candidates, totalling 35 fits\n",
      "[CV 1/5] END class_weight=balanced, max_depth=100, random_state=12345;, score=0.641 total time=  36.5s\n",
      "[CV 2/5] END class_weight=balanced, max_depth=100, random_state=12345;, score=0.644 total time=  37.3s\n",
      "[CV 3/5] END class_weight=balanced, max_depth=100, random_state=12345;, score=0.635 total time=  38.5s\n",
      "[CV 4/5] END class_weight=balanced, max_depth=100, random_state=12345;, score=0.646 total time=  39.4s\n",
      "[CV 5/5] END class_weight=balanced, max_depth=100, random_state=12345;, score=0.644 total time=  38.6s\n",
      "[CV 1/5] END class_weight=balanced, max_depth=125, random_state=12345;, score=0.651 total time=  36.3s\n",
      "[CV 2/5] END class_weight=balanced, max_depth=125, random_state=12345;, score=0.648 total time=  38.8s\n",
      "[CV 3/5] END class_weight=balanced, max_depth=125, random_state=12345;, score=0.646 total time=  42.7s\n",
      "[CV 4/5] END class_weight=balanced, max_depth=125, random_state=12345;, score=0.650 total time=  46.4s\n",
      "[CV 5/5] END class_weight=balanced, max_depth=125, random_state=12345;, score=0.644 total time=  42.1s\n",
      "[CV 1/5] END class_weight=balanced, max_depth=150, random_state=12345;, score=0.647 total time=  40.0s\n",
      "[CV 2/5] END class_weight=balanced, max_depth=150, random_state=12345;, score=0.649 total time=  41.2s\n",
      "[CV 3/5] END class_weight=balanced, max_depth=150, random_state=12345;, score=0.642 total time=  40.7s\n",
      "[CV 4/5] END class_weight=balanced, max_depth=150, random_state=12345;, score=0.653 total time=  39.4s\n",
      "[CV 5/5] END class_weight=balanced, max_depth=150, random_state=12345;, score=0.649 total time=  40.6s\n",
      "[CV 1/5] END class_weight=balanced, max_depth=175, random_state=12345;, score=0.648 total time=  45.5s\n",
      "[CV 2/5] END class_weight=balanced, max_depth=175, random_state=12345;, score=0.643 total time=  47.7s\n",
      "[CV 3/5] END class_weight=balanced, max_depth=175, random_state=12345;, score=0.642 total time=  48.2s\n",
      "[CV 4/5] END class_weight=balanced, max_depth=175, random_state=12345;, score=0.651 total time=  40.6s\n",
      "[CV 5/5] END class_weight=balanced, max_depth=175, random_state=12345;, score=0.649 total time=  40.7s\n",
      "[CV 1/5] END class_weight=balanced, max_depth=200, random_state=12345;, score=0.648 total time=  39.4s\n",
      "[CV 2/5] END class_weight=balanced, max_depth=200, random_state=12345;, score=0.657 total time=  42.8s\n",
      "[CV 3/5] END class_weight=balanced, max_depth=200, random_state=12345;, score=0.643 total time=  41.3s\n",
      "[CV 4/5] END class_weight=balanced, max_depth=200, random_state=12345;, score=0.654 total time=  41.6s\n",
      "[CV 5/5] END class_weight=balanced, max_depth=200, random_state=12345;, score=0.652 total time=  41.8s\n",
      "[CV 1/5] END class_weight=balanced, max_depth=225, random_state=12345;, score=0.644 total time=  40.7s\n",
      "[CV 2/5] END class_weight=balanced, max_depth=225, random_state=12345;, score=0.647 total time=  43.8s\n",
      "[CV 3/5] END class_weight=balanced, max_depth=225, random_state=12345;, score=0.646 total time=  42.2s\n",
      "[CV 4/5] END class_weight=balanced, max_depth=225, random_state=12345;, score=0.646 total time=  42.2s\n",
      "[CV 5/5] END class_weight=balanced, max_depth=225, random_state=12345;, score=0.653 total time=  42.9s\n",
      "[CV 1/5] END class_weight=balanced, max_depth=250, random_state=12345;, score=0.649 total time=  41.4s\n",
      "[CV 2/5] END class_weight=balanced, max_depth=250, random_state=12345;, score=0.652 total time=  44.4s\n",
      "[CV 3/5] END class_weight=balanced, max_depth=250, random_state=12345;, score=0.645 total time=  42.9s\n",
      "[CV 4/5] END class_weight=balanced, max_depth=250, random_state=12345;, score=0.646 total time=  43.1s\n",
      "[CV 5/5] END class_weight=balanced, max_depth=250, random_state=12345;, score=0.648 total time=  43.6s\n",
      "Лучшие параметры модели DecisionTreeClassifier: {'class_weight': 'balanced', 'max_depth': 200, 'random_state': 12345}\n",
      "Лучший показатель RMSE для DecisionTreeClassifier: 0.6510802082766839\n",
      "CPU times: total: 24min 47s\n",
      "Wall time: 25min 7s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "parametrs_dtc = {'random_state': [RANDOM_STATE]\n",
    "                 , 'class_weight': ['balanced']\n",
    "                 , 'max_depth': range(100, 251, 25)\n",
    "                }\n",
    "best_model_dtc = cv_model(DecisionTreeClassifier()\n",
    "                          , parametrs_dtc\n",
    "                          , X_train\n",
    "                          , y_train)\n",
    "\n",
    "print(f'Лучшие параметры модели DecisionTreeClassifier: {best_model_dtc.best_params_}')\n",
    "print(f'Лучший показатель RMSE для DecisionTreeClassifier: {best_model_dtc.best_score_}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Обучим модель RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "[CV 1/5] END class_weight=balanced, max_depth=175, n_estimators=10, random_state=12345;, score=0.565 total time=  29.4s\n",
      "[CV 2/5] END class_weight=balanced, max_depth=175, n_estimators=10, random_state=12345;, score=0.566 total time=  30.1s\n",
      "[CV 3/5] END class_weight=balanced, max_depth=175, n_estimators=10, random_state=12345;, score=0.525 total time=  30.3s\n",
      "[CV 4/5] END class_weight=balanced, max_depth=175, n_estimators=10, random_state=12345;, score=0.536 total time=  30.2s\n",
      "[CV 5/5] END class_weight=balanced, max_depth=175, n_estimators=10, random_state=12345;, score=0.542 total time=  30.2s\n",
      "[CV 1/5] END class_weight=balanced, max_depth=200, n_estimators=10, random_state=12345;, score=0.575 total time=  32.0s\n",
      "[CV 2/5] END class_weight=balanced, max_depth=200, n_estimators=10, random_state=12345;, score=0.577 total time=  32.3s\n",
      "[CV 3/5] END class_weight=balanced, max_depth=200, n_estimators=10, random_state=12345;, score=0.546 total time=  32.4s\n",
      "[CV 4/5] END class_weight=balanced, max_depth=200, n_estimators=10, random_state=12345;, score=0.561 total time=  32.9s\n",
      "[CV 5/5] END class_weight=balanced, max_depth=200, n_estimators=10, random_state=12345;, score=0.565 total time=  31.9s\n",
      "[CV 1/5] END class_weight=balanced, max_depth=225, n_estimators=10, random_state=12345;, score=0.583 total time=  33.2s\n",
      "[CV 2/5] END class_weight=balanced, max_depth=225, n_estimators=10, random_state=12345;, score=0.585 total time=  34.5s\n",
      "[CV 3/5] END class_weight=balanced, max_depth=225, n_estimators=10, random_state=12345;, score=0.524 total time=  33.9s\n",
      "[CV 4/5] END class_weight=balanced, max_depth=225, n_estimators=10, random_state=12345;, score=0.557 total time=  34.4s\n",
      "[CV 5/5] END class_weight=balanced, max_depth=225, n_estimators=10, random_state=12345;, score=0.563 total time=  33.9s\n",
      "[CV 1/5] END class_weight=balanced, max_depth=250, n_estimators=10, random_state=12345;, score=0.582 total time=  35.2s\n",
      "[CV 2/5] END class_weight=balanced, max_depth=250, n_estimators=10, random_state=12345;, score=0.571 total time=  35.1s\n",
      "[CV 3/5] END class_weight=balanced, max_depth=250, n_estimators=10, random_state=12345;, score=0.544 total time=  36.0s\n",
      "[CV 4/5] END class_weight=balanced, max_depth=250, n_estimators=10, random_state=12345;, score=0.551 total time=  35.3s\n",
      "[CV 5/5] END class_weight=balanced, max_depth=250, n_estimators=10, random_state=12345;, score=0.572 total time=  35.3s\n",
      "Лучшие параметры модели RandomForestClassifier: {'class_weight': 'balanced', 'max_depth': 200, 'n_estimators': 10, 'random_state': 12345}\n",
      "Лучший показатель RMSE для RandomForestClassifier: 0.5648451716341112\n",
      "CPU times: total: 11min 17s\n",
      "Wall time: 11min 17s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "parametrs_rfc = {'random_state': [RANDOM_STATE]\n",
    "                 , 'class_weight': ['balanced']\n",
    "                 , 'n_estimators': [10]\n",
    "                 , 'max_depth': [175, 200, 225, 250]\n",
    "                }\n",
    "\n",
    "best_model_rfc = cv_model(RandomForestClassifier()\n",
    "                          , parametrs_rfc\n",
    "                          , X_train\n",
    "                          , y_train)\n",
    "\n",
    "print(f'Лучшие параметры модели RandomForestClassifier: {best_model_rfc.best_params_}')\n",
    "print(f'Лучший показатель RMSE для RandomForestClassifier: {best_model_rfc.best_score_}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Обучим модель LGBMClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 32 candidates, totalling 160 fits\n",
      "[CV 1/5] END class_weight=balanced, max_depth=10, n_estimators=100, random_state=12345;, score=0.723 total time=   8.3s\n",
      "[CV 2/5] END class_weight=balanced, max_depth=10, n_estimators=100, random_state=12345;, score=0.729 total time=   8.1s\n",
      "[CV 3/5] END class_weight=balanced, max_depth=10, n_estimators=100, random_state=12345;, score=0.726 total time=   8.8s\n",
      "[CV 4/5] END class_weight=balanced, max_depth=10, n_estimators=100, random_state=12345;, score=0.740 total time=   8.6s\n",
      "[CV 5/5] END class_weight=balanced, max_depth=10, n_estimators=100, random_state=12345;, score=0.737 total time=   8.2s\n",
      "[CV 1/5] END class_weight=balanced, max_depth=10, n_estimators=150, random_state=12345;, score=0.733 total time=  11.2s\n",
      "[CV 2/5] END class_weight=balanced, max_depth=10, n_estimators=150, random_state=12345;, score=0.742 total time=  10.7s\n",
      "[CV 3/5] END class_weight=balanced, max_depth=10, n_estimators=150, random_state=12345;, score=0.734 total time=  10.4s\n",
      "[CV 4/5] END class_weight=balanced, max_depth=10, n_estimators=150, random_state=12345;, score=0.749 total time=  10.6s\n",
      "[CV 5/5] END class_weight=balanced, max_depth=10, n_estimators=150, random_state=12345;, score=0.745 total time=  10.4s\n",
      "[CV 1/5] END class_weight=balanced, max_depth=10, n_estimators=200, random_state=12345;, score=0.735 total time=  12.5s\n",
      "[CV 2/5] END class_weight=balanced, max_depth=10, n_estimators=200, random_state=12345;, score=0.745 total time=  12.6s\n",
      "[CV 3/5] END class_weight=balanced, max_depth=10, n_estimators=200, random_state=12345;, score=0.736 total time=  13.3s\n",
      "[CV 4/5] END class_weight=balanced, max_depth=10, n_estimators=200, random_state=12345;, score=0.749 total time=  13.8s\n",
      "[CV 5/5] END class_weight=balanced, max_depth=10, n_estimators=200, random_state=12345;, score=0.749 total time=  13.2s\n",
      "[CV 1/5] END class_weight=balanced, max_depth=10, n_estimators=250, random_state=12345;, score=0.748 total time=  15.9s\n",
      "[CV 2/5] END class_weight=balanced, max_depth=10, n_estimators=250, random_state=12345;, score=0.752 total time=  15.0s\n",
      "[CV 3/5] END class_weight=balanced, max_depth=10, n_estimators=250, random_state=12345;, score=0.743 total time=  14.7s\n",
      "[CV 4/5] END class_weight=balanced, max_depth=10, n_estimators=250, random_state=12345;, score=0.751 total time=  15.0s\n",
      "[CV 5/5] END class_weight=balanced, max_depth=10, n_estimators=250, random_state=12345;, score=0.751 total time=  14.9s\n",
      "[CV 1/5] END class_weight=balanced, max_depth=15, n_estimators=100, random_state=12345;, score=0.728 total time=   9.5s\n",
      "[CV 2/5] END class_weight=balanced, max_depth=15, n_estimators=100, random_state=12345;, score=0.736 total time=   9.5s\n",
      "[CV 3/5] END class_weight=balanced, max_depth=15, n_estimators=100, random_state=12345;, score=0.732 total time=   9.5s\n",
      "[CV 4/5] END class_weight=balanced, max_depth=15, n_estimators=100, random_state=12345;, score=0.743 total time=   9.8s\n",
      "[CV 5/5] END class_weight=balanced, max_depth=15, n_estimators=100, random_state=12345;, score=0.740 total time=  10.1s\n",
      "[CV 1/5] END class_weight=balanced, max_depth=15, n_estimators=150, random_state=12345;, score=0.740 total time=  12.4s\n",
      "[CV 2/5] END class_weight=balanced, max_depth=15, n_estimators=150, random_state=12345;, score=0.743 total time=  14.8s\n",
      "[CV 3/5] END class_weight=balanced, max_depth=15, n_estimators=150, random_state=12345;, score=0.732 total time=  12.4s\n",
      "[CV 4/5] END class_weight=balanced, max_depth=15, n_estimators=150, random_state=12345;, score=0.747 total time=  12.3s\n",
      "[CV 5/5] END class_weight=balanced, max_depth=15, n_estimators=150, random_state=12345;, score=0.745 total time=  12.5s\n",
      "[CV 1/5] END class_weight=balanced, max_depth=15, n_estimators=200, random_state=12345;, score=0.743 total time=  14.9s\n",
      "[CV 2/5] END class_weight=balanced, max_depth=15, n_estimators=200, random_state=12345;, score=0.752 total time=  15.1s\n",
      "[CV 3/5] END class_weight=balanced, max_depth=15, n_estimators=200, random_state=12345;, score=0.739 total time=  15.4s\n",
      "[CV 4/5] END class_weight=balanced, max_depth=15, n_estimators=200, random_state=12345;, score=0.750 total time=  15.2s\n",
      "[CV 5/5] END class_weight=balanced, max_depth=15, n_estimators=200, random_state=12345;, score=0.748 total time=  14.9s\n",
      "[CV 1/5] END class_weight=balanced, max_depth=15, n_estimators=250, random_state=12345;, score=0.750 total time=  17.8s\n",
      "[CV 2/5] END class_weight=balanced, max_depth=15, n_estimators=250, random_state=12345;, score=0.760 total time=  18.0s\n",
      "[CV 3/5] END class_weight=balanced, max_depth=15, n_estimators=250, random_state=12345;, score=0.743 total time=  18.4s\n",
      "[CV 4/5] END class_weight=balanced, max_depth=15, n_estimators=250, random_state=12345;, score=0.751 total time=  18.4s\n",
      "[CV 5/5] END class_weight=balanced, max_depth=15, n_estimators=250, random_state=12345;, score=0.750 total time=  18.4s\n",
      "[CV 1/5] END class_weight=balanced, max_depth=20, n_estimators=100, random_state=12345;, score=0.734 total time=  10.4s\n",
      "[CV 2/5] END class_weight=balanced, max_depth=20, n_estimators=100, random_state=12345;, score=0.738 total time=  10.3s\n",
      "[CV 3/5] END class_weight=balanced, max_depth=20, n_estimators=100, random_state=12345;, score=0.729 total time=  10.4s\n",
      "[CV 4/5] END class_weight=balanced, max_depth=20, n_estimators=100, random_state=12345;, score=0.743 total time=  10.3s\n",
      "[CV 5/5] END class_weight=balanced, max_depth=20, n_estimators=100, random_state=12345;, score=0.740 total time=  10.2s\n",
      "[CV 1/5] END class_weight=balanced, max_depth=20, n_estimators=150, random_state=12345;, score=0.739 total time=  13.5s\n",
      "[CV 2/5] END class_weight=balanced, max_depth=20, n_estimators=150, random_state=12345;, score=0.748 total time=  13.7s\n",
      "[CV 3/5] END class_weight=balanced, max_depth=20, n_estimators=150, random_state=12345;, score=0.738 total time=  13.5s\n",
      "[CV 4/5] END class_weight=balanced, max_depth=20, n_estimators=150, random_state=12345;, score=0.747 total time=  13.5s\n",
      "[CV 5/5] END class_weight=balanced, max_depth=20, n_estimators=150, random_state=12345;, score=0.746 total time=  13.5s\n",
      "[CV 1/5] END class_weight=balanced, max_depth=20, n_estimators=200, random_state=12345;, score=0.746 total time=  18.8s\n",
      "[CV 2/5] END class_weight=balanced, max_depth=20, n_estimators=200, random_state=12345;, score=0.751 total time=  17.3s\n",
      "[CV 3/5] END class_weight=balanced, max_depth=20, n_estimators=200, random_state=12345;, score=0.741 total time=  18.6s\n",
      "[CV 4/5] END class_weight=balanced, max_depth=20, n_estimators=200, random_state=12345;, score=0.750 total time=  17.4s\n",
      "[CV 5/5] END class_weight=balanced, max_depth=20, n_estimators=200, random_state=12345;, score=0.754 total time=  16.6s\n",
      "[CV 1/5] END class_weight=balanced, max_depth=20, n_estimators=250, random_state=12345;, score=0.749 total time=  19.7s\n",
      "[CV 2/5] END class_weight=balanced, max_depth=20, n_estimators=250, random_state=12345;, score=0.758 total time=  20.0s\n",
      "[CV 3/5] END class_weight=balanced, max_depth=20, n_estimators=250, random_state=12345;, score=0.744 total time=  20.5s\n",
      "[CV 4/5] END class_weight=balanced, max_depth=20, n_estimators=250, random_state=12345;, score=0.752 total time=  19.8s\n",
      "[CV 5/5] END class_weight=balanced, max_depth=20, n_estimators=250, random_state=12345;, score=0.754 total time=  20.0s\n",
      "[CV 1/5] END class_weight=balanced, max_depth=25, n_estimators=100, random_state=12345;, score=0.728 total time=  11.0s\n",
      "[CV 2/5] END class_weight=balanced, max_depth=25, n_estimators=100, random_state=12345;, score=0.738 total time=  11.0s\n",
      "[CV 3/5] END class_weight=balanced, max_depth=25, n_estimators=100, random_state=12345;, score=0.726 total time=  11.2s\n",
      "[CV 4/5] END class_weight=balanced, max_depth=25, n_estimators=100, random_state=12345;, score=0.738 total time=  11.0s\n",
      "[CV 5/5] END class_weight=balanced, max_depth=25, n_estimators=100, random_state=12345;, score=0.733 total time=  11.0s\n",
      "[CV 1/5] END class_weight=balanced, max_depth=25, n_estimators=150, random_state=12345;, score=0.736 total time=  15.3s\n",
      "[CV 2/5] END class_weight=balanced, max_depth=25, n_estimators=150, random_state=12345;, score=0.739 total time=  15.7s\n",
      "[CV 3/5] END class_weight=balanced, max_depth=25, n_estimators=150, random_state=12345;, score=0.736 total time=  14.7s\n",
      "[CV 4/5] END class_weight=balanced, max_depth=25, n_estimators=150, random_state=12345;, score=0.738 total time=  14.6s\n",
      "[CV 5/5] END class_weight=balanced, max_depth=25, n_estimators=150, random_state=12345;, score=0.744 total time=  15.3s\n",
      "[CV 1/5] END class_weight=balanced, max_depth=25, n_estimators=200, random_state=12345;, score=0.742 total time=  18.0s\n",
      "[CV 2/5] END class_weight=balanced, max_depth=25, n_estimators=200, random_state=12345;, score=0.749 total time=  18.3s\n",
      "[CV 3/5] END class_weight=balanced, max_depth=25, n_estimators=200, random_state=12345;, score=0.742 total time=  18.3s\n",
      "[CV 4/5] END class_weight=balanced, max_depth=25, n_estimators=200, random_state=12345;, score=0.743 total time=  18.1s\n",
      "[CV 5/5] END class_weight=balanced, max_depth=25, n_estimators=200, random_state=12345;, score=0.745 total time=  18.1s\n",
      "[CV 1/5] END class_weight=balanced, max_depth=25, n_estimators=250, random_state=12345;, score=0.744 total time=  21.7s\n",
      "[CV 2/5] END class_weight=balanced, max_depth=25, n_estimators=250, random_state=12345;, score=0.755 total time=  22.3s\n",
      "[CV 3/5] END class_weight=balanced, max_depth=25, n_estimators=250, random_state=12345;, score=0.743 total time=  21.8s\n",
      "[CV 4/5] END class_weight=balanced, max_depth=25, n_estimators=250, random_state=12345;, score=0.742 total time=  22.3s\n",
      "[CV 5/5] END class_weight=balanced, max_depth=25, n_estimators=250, random_state=12345;, score=0.747 total time=  21.9s\n",
      "[CV 1/5] END class_weight=balanced, max_depth=30, n_estimators=100, random_state=12345;, score=0.725 total time=  11.5s\n",
      "[CV 2/5] END class_weight=balanced, max_depth=30, n_estimators=100, random_state=12345;, score=0.737 total time=  11.6s\n",
      "[CV 3/5] END class_weight=balanced, max_depth=30, n_estimators=100, random_state=12345;, score=0.724 total time=  12.1s\n",
      "[CV 4/5] END class_weight=balanced, max_depth=30, n_estimators=100, random_state=12345;, score=0.732 total time=  11.7s\n",
      "[CV 5/5] END class_weight=balanced, max_depth=30, n_estimators=100, random_state=12345;, score=0.734 total time=  11.5s\n",
      "[CV 1/5] END class_weight=balanced, max_depth=30, n_estimators=150, random_state=12345;, score=0.733 total time=  15.4s\n",
      "[CV 2/5] END class_weight=balanced, max_depth=30, n_estimators=150, random_state=12345;, score=0.739 total time=  15.6s\n",
      "[CV 3/5] END class_weight=balanced, max_depth=30, n_estimators=150, random_state=12345;, score=0.730 total time=  18.2s\n",
      "[CV 4/5] END class_weight=balanced, max_depth=30, n_estimators=150, random_state=12345;, score=0.740 total time=  17.5s\n",
      "[CV 5/5] END class_weight=balanced, max_depth=30, n_estimators=150, random_state=12345;, score=0.736 total time=  18.5s\n",
      "[CV 1/5] END class_weight=balanced, max_depth=30, n_estimators=200, random_state=12345;, score=0.738 total time=  21.8s\n",
      "[CV 2/5] END class_weight=balanced, max_depth=30, n_estimators=200, random_state=12345;, score=0.742 total time=  24.6s\n",
      "[CV 3/5] END class_weight=balanced, max_depth=30, n_estimators=200, random_state=12345;, score=0.733 total time=  24.2s\n",
      "[CV 4/5] END class_weight=balanced, max_depth=30, n_estimators=200, random_state=12345;, score=0.745 total time=  23.6s\n",
      "[CV 5/5] END class_weight=balanced, max_depth=30, n_estimators=200, random_state=12345;, score=0.741 total time=  22.4s\n",
      "[CV 1/5] END class_weight=balanced, max_depth=30, n_estimators=250, random_state=12345;, score=0.736 total time=  35.2s\n",
      "[CV 2/5] END class_weight=balanced, max_depth=30, n_estimators=250, random_state=12345;, score=0.749 total time=  30.8s\n",
      "[CV 3/5] END class_weight=balanced, max_depth=30, n_estimators=250, random_state=12345;, score=0.740 total time=  24.6s\n",
      "[CV 4/5] END class_weight=balanced, max_depth=30, n_estimators=250, random_state=12345;, score=0.743 total time=  23.8s\n",
      "[CV 5/5] END class_weight=balanced, max_depth=30, n_estimators=250, random_state=12345;, score=0.745 total time=  22.8s\n",
      "[CV 1/5] END class_weight=balanced, max_depth=35, n_estimators=100, random_state=12345;, score=0.725 total time=  11.6s\n",
      "[CV 2/5] END class_weight=balanced, max_depth=35, n_estimators=100, random_state=12345;, score=0.737 total time=  12.1s\n",
      "[CV 3/5] END class_weight=balanced, max_depth=35, n_estimators=100, random_state=12345;, score=0.724 total time=  11.6s\n",
      "[CV 4/5] END class_weight=balanced, max_depth=35, n_estimators=100, random_state=12345;, score=0.732 total time=  11.5s\n",
      "[CV 5/5] END class_weight=balanced, max_depth=35, n_estimators=100, random_state=12345;, score=0.734 total time=  12.6s\n",
      "[CV 1/5] END class_weight=balanced, max_depth=35, n_estimators=150, random_state=12345;, score=0.733 total time=  15.7s\n",
      "[CV 2/5] END class_weight=balanced, max_depth=35, n_estimators=150, random_state=12345;, score=0.739 total time=  15.6s\n",
      "[CV 3/5] END class_weight=balanced, max_depth=35, n_estimators=150, random_state=12345;, score=0.730 total time=  15.4s\n",
      "[CV 4/5] END class_weight=balanced, max_depth=35, n_estimators=150, random_state=12345;, score=0.740 total time=  15.5s\n",
      "[CV 5/5] END class_weight=balanced, max_depth=35, n_estimators=150, random_state=12345;, score=0.736 total time=  15.6s\n",
      "[CV 1/5] END class_weight=balanced, max_depth=35, n_estimators=200, random_state=12345;, score=0.738 total time=  19.4s\n",
      "[CV 2/5] END class_weight=balanced, max_depth=35, n_estimators=200, random_state=12345;, score=0.742 total time=  19.2s\n",
      "[CV 3/5] END class_weight=balanced, max_depth=35, n_estimators=200, random_state=12345;, score=0.733 total time=  19.4s\n",
      "[CV 4/5] END class_weight=balanced, max_depth=35, n_estimators=200, random_state=12345;, score=0.745 total time=  19.1s\n",
      "[CV 5/5] END class_weight=balanced, max_depth=35, n_estimators=200, random_state=12345;, score=0.741 total time=  18.9s\n",
      "[CV 1/5] END class_weight=balanced, max_depth=35, n_estimators=250, random_state=12345;, score=0.736 total time=  23.1s\n",
      "[CV 2/5] END class_weight=balanced, max_depth=35, n_estimators=250, random_state=12345;, score=0.749 total time=  23.1s\n",
      "[CV 3/5] END class_weight=balanced, max_depth=35, n_estimators=250, random_state=12345;, score=0.740 total time=  23.5s\n",
      "[CV 4/5] END class_weight=balanced, max_depth=35, n_estimators=250, random_state=12345;, score=0.743 total time=  22.8s\n",
      "[CV 5/5] END class_weight=balanced, max_depth=35, n_estimators=250, random_state=12345;, score=0.745 total time=  23.1s\n",
      "[CV 1/5] END class_weight=balanced, max_depth=40, n_estimators=100, random_state=12345;, score=0.725 total time=  12.0s\n",
      "[CV 2/5] END class_weight=balanced, max_depth=40, n_estimators=100, random_state=12345;, score=0.737 total time=  13.4s\n",
      "[CV 3/5] END class_weight=balanced, max_depth=40, n_estimators=100, random_state=12345;, score=0.724 total time=  13.0s\n",
      "[CV 4/5] END class_weight=balanced, max_depth=40, n_estimators=100, random_state=12345;, score=0.732 total time=  13.5s\n",
      "[CV 5/5] END class_weight=balanced, max_depth=40, n_estimators=100, random_state=12345;, score=0.734 total time=  12.6s\n",
      "[CV 1/5] END class_weight=balanced, max_depth=40, n_estimators=150, random_state=12345;, score=0.733 total time=  21.5s\n",
      "[CV 2/5] END class_weight=balanced, max_depth=40, n_estimators=150, random_state=12345;, score=0.739 total time=  18.4s\n",
      "[CV 3/5] END class_weight=balanced, max_depth=40, n_estimators=150, random_state=12345;, score=0.730 total time=  16.3s\n",
      "[CV 4/5] END class_weight=balanced, max_depth=40, n_estimators=150, random_state=12345;, score=0.740 total time=  15.8s\n",
      "[CV 5/5] END class_weight=balanced, max_depth=40, n_estimators=150, random_state=12345;, score=0.736 total time=  15.2s\n",
      "[CV 1/5] END class_weight=balanced, max_depth=40, n_estimators=200, random_state=12345;, score=0.738 total time=  19.4s\n",
      "[CV 2/5] END class_weight=balanced, max_depth=40, n_estimators=200, random_state=12345;, score=0.742 total time=  19.8s\n",
      "[CV 3/5] END class_weight=balanced, max_depth=40, n_estimators=200, random_state=12345;, score=0.733 total time=  24.4s\n",
      "[CV 4/5] END class_weight=balanced, max_depth=40, n_estimators=200, random_state=12345;, score=0.745 total time=  25.2s\n",
      "[CV 5/5] END class_weight=balanced, max_depth=40, n_estimators=200, random_state=12345;, score=0.741 total time=  22.6s\n",
      "[CV 1/5] END class_weight=balanced, max_depth=40, n_estimators=250, random_state=12345;, score=0.736 total time=  32.0s\n",
      "[CV 2/5] END class_weight=balanced, max_depth=40, n_estimators=250, random_state=12345;, score=0.749 total time=  31.1s\n",
      "[CV 3/5] END class_weight=balanced, max_depth=40, n_estimators=250, random_state=12345;, score=0.740 total time=  30.7s\n",
      "[CV 4/5] END class_weight=balanced, max_depth=40, n_estimators=250, random_state=12345;, score=0.743 total time=  30.2s\n",
      "[CV 5/5] END class_weight=balanced, max_depth=40, n_estimators=250, random_state=12345;, score=0.745 total time=  34.5s\n",
      "[CV 1/5] END class_weight=balanced, max_depth=45, n_estimators=100, random_state=12345;, score=0.725 total time=  15.5s\n",
      "[CV 2/5] END class_weight=balanced, max_depth=45, n_estimators=100, random_state=12345;, score=0.737 total time=  14.8s\n",
      "[CV 3/5] END class_weight=balanced, max_depth=45, n_estimators=100, random_state=12345;, score=0.724 total time=  14.6s\n",
      "[CV 4/5] END class_weight=balanced, max_depth=45, n_estimators=100, random_state=12345;, score=0.732 total time=  18.8s\n",
      "[CV 5/5] END class_weight=balanced, max_depth=45, n_estimators=100, random_state=12345;, score=0.734 total time=  18.2s\n",
      "[CV 1/5] END class_weight=balanced, max_depth=45, n_estimators=150, random_state=12345;, score=0.733 total time=  19.6s\n",
      "[CV 2/5] END class_weight=balanced, max_depth=45, n_estimators=150, random_state=12345;, score=0.739 total time=  20.7s\n",
      "[CV 3/5] END class_weight=balanced, max_depth=45, n_estimators=150, random_state=12345;, score=0.730 total time=  20.7s\n",
      "[CV 4/5] END class_weight=balanced, max_depth=45, n_estimators=150, random_state=12345;, score=0.740 total time=  19.2s\n",
      "[CV 5/5] END class_weight=balanced, max_depth=45, n_estimators=150, random_state=12345;, score=0.736 total time=  16.6s\n",
      "[CV 1/5] END class_weight=balanced, max_depth=45, n_estimators=200, random_state=12345;, score=0.738 total time=  20.4s\n",
      "[CV 2/5] END class_weight=balanced, max_depth=45, n_estimators=200, random_state=12345;, score=0.742 total time=  20.9s\n",
      "[CV 3/5] END class_weight=balanced, max_depth=45, n_estimators=200, random_state=12345;, score=0.733 total time=  24.9s\n",
      "[CV 4/5] END class_weight=balanced, max_depth=45, n_estimators=200, random_state=12345;, score=0.745 total time=  30.8s\n",
      "[CV 5/5] END class_weight=balanced, max_depth=45, n_estimators=200, random_state=12345;, score=0.741 total time=  24.7s\n",
      "[CV 1/5] END class_weight=balanced, max_depth=45, n_estimators=250, random_state=12345;, score=0.736 total time=  29.2s\n",
      "[CV 2/5] END class_weight=balanced, max_depth=45, n_estimators=250, random_state=12345;, score=0.749 total time=  28.4s\n",
      "[CV 3/5] END class_weight=balanced, max_depth=45, n_estimators=250, random_state=12345;, score=0.740 total time=  25.5s\n",
      "[CV 4/5] END class_weight=balanced, max_depth=45, n_estimators=250, random_state=12345;, score=0.743 total time=  26.6s\n",
      "[CV 5/5] END class_weight=balanced, max_depth=45, n_estimators=250, random_state=12345;, score=0.745 total time=  25.7s\n",
      "Лучшие параметры модели LightGBMRegressor: {'class_weight': 'balanced', 'max_depth': 20, 'n_estimators': 250, 'random_state': 12345}\n",
      "Лучший показатель RMSE для LightGBMRegressor: 0.751450589836779\n",
      "CPU times: total: 2h 41min 19s\n",
      "Wall time: 46min 44s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "parametrs_lgbmc = {'random_state': [RANDOM_STATE]\n",
    "                   , 'class_weight': ['balanced']\n",
    "                   , 'n_estimators': range(100, 251, 50)\n",
    "                   , 'max_depth': range(10, 50, 5)}\n",
    "\n",
    "best_model_lgbmc = cv_model(LGBMClassifier()\n",
    "                            , parametrs_lgbmc\n",
    "                            , X_train\n",
    "                            , y_train)\n",
    "\n",
    "print(f'Лучшие параметры модели LightGBMRegressor: {best_model_lgbmc.best_params_}')\n",
    "print(f'Лучший показатель RMSE для LightGBMRegressor: {best_model_lgbmc.best_score_}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Обучим модель CatBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Learning rate set to 0.12034\n",
      "0:\tlearn: 0.6428587\ttotal: 1.39s\tremaining: 11m 32s\n",
      "1:\tlearn: 0.6067874\ttotal: 2.45s\tremaining: 10m 9s\n",
      "2:\tlearn: 0.5806789\ttotal: 3.29s\tremaining: 9m 5s\n",
      "3:\tlearn: 0.5619470\ttotal: 4.15s\tremaining: 8m 34s\n",
      "4:\tlearn: 0.5498864\ttotal: 5.13s\tremaining: 8m 28s\n",
      "5:\tlearn: 0.5396614\ttotal: 6s\tremaining: 8m 13s\n",
      "6:\tlearn: 0.5310166\ttotal: 6.84s\tremaining: 8m 1s\n",
      "7:\tlearn: 0.5206713\ttotal: 7.68s\tremaining: 7m 52s\n",
      "8:\tlearn: 0.5138065\ttotal: 8.59s\tremaining: 7m 48s\n",
      "9:\tlearn: 0.5075563\ttotal: 9.66s\tremaining: 7m 53s\n",
      "10:\tlearn: 0.5021367\ttotal: 10.6s\tremaining: 7m 49s\n",
      "11:\tlearn: 0.4971553\ttotal: 11.5s\tremaining: 7m 47s\n",
      "12:\tlearn: 0.4930247\ttotal: 12.4s\tremaining: 7m 44s\n",
      "13:\tlearn: 0.4883778\ttotal: 13.3s\tremaining: 7m 40s\n",
      "14:\tlearn: 0.4841099\ttotal: 14.1s\tremaining: 7m 35s\n",
      "15:\tlearn: 0.4805429\ttotal: 15s\tremaining: 7m 34s\n",
      "16:\tlearn: 0.4766485\ttotal: 15.9s\tremaining: 7m 30s\n",
      "17:\tlearn: 0.4722222\ttotal: 16.7s\tremaining: 7m 27s\n",
      "18:\tlearn: 0.4670818\ttotal: 17.5s\tremaining: 7m 24s\n",
      "19:\tlearn: 0.4627799\ttotal: 18.4s\tremaining: 7m 20s\n",
      "20:\tlearn: 0.4592881\ttotal: 19.2s\tremaining: 7m 17s\n",
      "21:\tlearn: 0.4568462\ttotal: 20s\tremaining: 7m 15s\n",
      "22:\tlearn: 0.4531541\ttotal: 20.9s\tremaining: 7m 13s\n",
      "23:\tlearn: 0.4501470\ttotal: 21.8s\tremaining: 7m 11s\n",
      "24:\tlearn: 0.4468885\ttotal: 22.6s\tremaining: 7m 8s\n",
      "25:\tlearn: 0.4446351\ttotal: 23.4s\tremaining: 7m 6s\n",
      "26:\tlearn: 0.4396116\ttotal: 24.2s\tremaining: 7m 4s\n",
      "27:\tlearn: 0.4374638\ttotal: 25.2s\tremaining: 7m 5s\n",
      "28:\tlearn: 0.4353395\ttotal: 26.1s\tremaining: 7m 4s\n",
      "29:\tlearn: 0.4338368\ttotal: 27s\tremaining: 7m 2s\n",
      "30:\tlearn: 0.4317770\ttotal: 27.8s\tremaining: 7m\n",
      "31:\tlearn: 0.4293931\ttotal: 28.6s\tremaining: 6m 58s\n",
      "32:\tlearn: 0.4276193\ttotal: 29.5s\tremaining: 6m 57s\n",
      "33:\tlearn: 0.4260355\ttotal: 30.5s\tremaining: 6m 57s\n",
      "34:\tlearn: 0.4236733\ttotal: 31.3s\tremaining: 6m 56s\n",
      "35:\tlearn: 0.4221813\ttotal: 32.1s\tremaining: 6m 54s\n",
      "36:\tlearn: 0.4210627\ttotal: 33s\tremaining: 6m 52s\n",
      "37:\tlearn: 0.4192283\ttotal: 33.9s\tremaining: 6m 52s\n",
      "38:\tlearn: 0.4180366\ttotal: 34.9s\tremaining: 6m 52s\n",
      "39:\tlearn: 0.4160556\ttotal: 35.8s\tremaining: 6m 51s\n",
      "40:\tlearn: 0.4146215\ttotal: 36.7s\tremaining: 6m 50s\n",
      "41:\tlearn: 0.4122311\ttotal: 37.7s\tremaining: 6m 51s\n",
      "42:\tlearn: 0.4097300\ttotal: 38.5s\tremaining: 6m 49s\n",
      "43:\tlearn: 0.4082246\ttotal: 39.4s\tremaining: 6m 48s\n",
      "44:\tlearn: 0.4070428\ttotal: 40.2s\tremaining: 6m 46s\n",
      "45:\tlearn: 0.4055569\ttotal: 41.1s\tremaining: 6m 45s\n",
      "46:\tlearn: 0.4038409\ttotal: 42.3s\tremaining: 6m 47s\n",
      "47:\tlearn: 0.4021357\ttotal: 43.4s\tremaining: 6m 49s\n",
      "48:\tlearn: 0.4007534\ttotal: 44.4s\tremaining: 6m 48s\n",
      "49:\tlearn: 0.3999604\ttotal: 45.4s\tremaining: 6m 48s\n",
      "50:\tlearn: 0.3985459\ttotal: 46.4s\tremaining: 6m 48s\n",
      "51:\tlearn: 0.3973428\ttotal: 47.3s\tremaining: 6m 47s\n",
      "52:\tlearn: 0.3960605\ttotal: 48.2s\tremaining: 6m 46s\n",
      "53:\tlearn: 0.3949693\ttotal: 49.1s\tremaining: 6m 45s\n",
      "54:\tlearn: 0.3937895\ttotal: 50s\tremaining: 6m 44s\n",
      "55:\tlearn: 0.3924003\ttotal: 50.8s\tremaining: 6m 42s\n",
      "56:\tlearn: 0.3914375\ttotal: 51.7s\tremaining: 6m 42s\n",
      "57:\tlearn: 0.3898941\ttotal: 52.7s\tremaining: 6m 41s\n",
      "58:\tlearn: 0.3888366\ttotal: 53.7s\tremaining: 6m 41s\n",
      "59:\tlearn: 0.3878026\ttotal: 54.7s\tremaining: 6m 41s\n",
      "60:\tlearn: 0.3861633\ttotal: 55.7s\tremaining: 6m 40s\n",
      "61:\tlearn: 0.3848171\ttotal: 56.5s\tremaining: 6m 39s\n",
      "62:\tlearn: 0.3836138\ttotal: 57.4s\tremaining: 6m 38s\n",
      "63:\tlearn: 0.3823477\ttotal: 58.5s\tremaining: 6m 38s\n",
      "64:\tlearn: 0.3812983\ttotal: 59.5s\tremaining: 6m 38s\n",
      "65:\tlearn: 0.3802985\ttotal: 1m\tremaining: 6m 38s\n",
      "66:\tlearn: 0.3793998\ttotal: 1m 1s\tremaining: 6m 36s\n",
      "67:\tlearn: 0.3783802\ttotal: 1m 2s\tremaining: 6m 35s\n",
      "68:\tlearn: 0.3775839\ttotal: 1m 3s\tremaining: 6m 33s\n",
      "69:\tlearn: 0.3769357\ttotal: 1m 3s\tremaining: 6m 32s\n",
      "70:\tlearn: 0.3756499\ttotal: 1m 4s\tremaining: 6m 31s\n",
      "71:\tlearn: 0.3747908\ttotal: 1m 5s\tremaining: 6m 30s\n",
      "72:\tlearn: 0.3739213\ttotal: 1m 6s\tremaining: 6m 29s\n",
      "73:\tlearn: 0.3728803\ttotal: 1m 7s\tremaining: 6m 27s\n",
      "74:\tlearn: 0.3713549\ttotal: 1m 8s\tremaining: 6m 27s\n",
      "75:\tlearn: 0.3702440\ttotal: 1m 9s\tremaining: 6m 26s\n",
      "76:\tlearn: 0.3694701\ttotal: 1m 10s\tremaining: 6m 25s\n",
      "77:\tlearn: 0.3689205\ttotal: 1m 11s\tremaining: 6m 24s\n",
      "78:\tlearn: 0.3681074\ttotal: 1m 12s\tremaining: 6m 25s\n",
      "79:\tlearn: 0.3672029\ttotal: 1m 13s\tremaining: 6m 24s\n",
      "80:\tlearn: 0.3660941\ttotal: 1m 14s\tremaining: 6m 23s\n",
      "81:\tlearn: 0.3652284\ttotal: 1m 15s\tremaining: 6m 22s\n",
      "82:\tlearn: 0.3641570\ttotal: 1m 16s\tremaining: 6m 21s\n",
      "83:\tlearn: 0.3628005\ttotal: 1m 16s\tremaining: 6m 20s\n",
      "84:\tlearn: 0.3616460\ttotal: 1m 17s\tremaining: 6m 19s\n",
      "85:\tlearn: 0.3607322\ttotal: 1m 18s\tremaining: 6m 18s\n",
      "86:\tlearn: 0.3599004\ttotal: 1m 19s\tremaining: 6m 16s\n",
      "87:\tlearn: 0.3590331\ttotal: 1m 20s\tremaining: 6m 15s\n",
      "88:\tlearn: 0.3582490\ttotal: 1m 21s\tremaining: 6m 14s\n",
      "89:\tlearn: 0.3570454\ttotal: 1m 22s\tremaining: 6m 13s\n",
      "90:\tlearn: 0.3556028\ttotal: 1m 22s\tremaining: 6m 12s\n",
      "91:\tlearn: 0.3547383\ttotal: 1m 23s\tremaining: 6m 11s\n",
      "92:\tlearn: 0.3534427\ttotal: 1m 24s\tremaining: 6m 10s\n",
      "93:\tlearn: 0.3526001\ttotal: 1m 25s\tremaining: 6m 9s\n",
      "94:\tlearn: 0.3518439\ttotal: 1m 26s\tremaining: 6m 8s\n",
      "95:\tlearn: 0.3507905\ttotal: 1m 27s\tremaining: 6m 7s\n",
      "96:\tlearn: 0.3496902\ttotal: 1m 28s\tremaining: 6m 6s\n",
      "97:\tlearn: 0.3489477\ttotal: 1m 29s\tremaining: 6m 5s\n",
      "98:\tlearn: 0.3478787\ttotal: 1m 29s\tremaining: 6m 4s\n",
      "99:\tlearn: 0.3470250\ttotal: 1m 30s\tremaining: 6m 3s\n",
      "100:\tlearn: 0.3463216\ttotal: 1m 32s\tremaining: 6m 3s\n",
      "101:\tlearn: 0.3456417\ttotal: 1m 33s\tremaining: 6m 3s\n",
      "102:\tlearn: 0.3445881\ttotal: 1m 34s\tremaining: 6m 2s\n",
      "103:\tlearn: 0.3437383\ttotal: 1m 34s\tremaining: 6m 1s\n",
      "104:\tlearn: 0.3429689\ttotal: 1m 35s\tremaining: 6m\n",
      "105:\tlearn: 0.3414755\ttotal: 1m 37s\tremaining: 6m\n",
      "106:\tlearn: 0.3406467\ttotal: 1m 37s\tremaining: 5m 59s\n",
      "107:\tlearn: 0.3398510\ttotal: 1m 38s\tremaining: 5m 58s\n",
      "108:\tlearn: 0.3391582\ttotal: 1m 39s\tremaining: 5m 57s\n",
      "109:\tlearn: 0.3383134\ttotal: 1m 40s\tremaining: 5m 56s\n",
      "110:\tlearn: 0.3373085\ttotal: 1m 41s\tremaining: 5m 54s\n",
      "111:\tlearn: 0.3365840\ttotal: 1m 42s\tremaining: 5m 53s\n",
      "112:\tlearn: 0.3353383\ttotal: 1m 42s\tremaining: 5m 52s\n",
      "113:\tlearn: 0.3345108\ttotal: 1m 43s\tremaining: 5m 51s\n",
      "114:\tlearn: 0.3337545\ttotal: 1m 44s\tremaining: 5m 50s\n",
      "115:\tlearn: 0.3329068\ttotal: 1m 45s\tremaining: 5m 48s\n",
      "116:\tlearn: 0.3318135\ttotal: 1m 46s\tremaining: 5m 47s\n",
      "117:\tlearn: 0.3309475\ttotal: 1m 47s\tremaining: 5m 46s\n",
      "118:\tlearn: 0.3302083\ttotal: 1m 47s\tremaining: 5m 45s\n",
      "119:\tlearn: 0.3295558\ttotal: 1m 48s\tremaining: 5m 44s\n",
      "120:\tlearn: 0.3286920\ttotal: 1m 49s\tremaining: 5m 43s\n",
      "121:\tlearn: 0.3278185\ttotal: 1m 50s\tremaining: 5m 42s\n",
      "122:\tlearn: 0.3270641\ttotal: 1m 51s\tremaining: 5m 41s\n",
      "123:\tlearn: 0.3260556\ttotal: 1m 52s\tremaining: 5m 41s\n",
      "124:\tlearn: 0.3253481\ttotal: 1m 53s\tremaining: 5m 40s\n",
      "125:\tlearn: 0.3246809\ttotal: 1m 54s\tremaining: 5m 40s\n",
      "126:\tlearn: 0.3241491\ttotal: 1m 55s\tremaining: 5m 39s\n",
      "127:\tlearn: 0.3233857\ttotal: 1m 56s\tremaining: 5m 38s\n",
      "128:\tlearn: 0.3227692\ttotal: 1m 57s\tremaining: 5m 37s\n",
      "129:\tlearn: 0.3219140\ttotal: 1m 58s\tremaining: 5m 36s\n",
      "130:\tlearn: 0.3212449\ttotal: 1m 59s\tremaining: 5m 35s\n",
      "131:\tlearn: 0.3205216\ttotal: 2m\tremaining: 5m 34s\n",
      "132:\tlearn: 0.3197625\ttotal: 2m\tremaining: 5m 33s\n",
      "133:\tlearn: 0.3191786\ttotal: 2m 1s\tremaining: 5m 32s\n",
      "134:\tlearn: 0.3178368\ttotal: 2m 2s\tremaining: 5m 31s\n",
      "135:\tlearn: 0.3171605\ttotal: 2m 3s\tremaining: 5m 30s\n",
      "136:\tlearn: 0.3163656\ttotal: 2m 4s\tremaining: 5m 29s\n",
      "137:\tlearn: 0.3156879\ttotal: 2m 5s\tremaining: 5m 28s\n",
      "138:\tlearn: 0.3151008\ttotal: 2m 6s\tremaining: 5m 28s\n",
      "139:\tlearn: 0.3144862\ttotal: 2m 7s\tremaining: 5m 27s\n",
      "140:\tlearn: 0.3138931\ttotal: 2m 8s\tremaining: 5m 26s\n",
      "141:\tlearn: 0.3134020\ttotal: 2m 9s\tremaining: 5m 25s\n",
      "142:\tlearn: 0.3128469\ttotal: 2m 9s\tremaining: 5m 24s\n",
      "143:\tlearn: 0.3118289\ttotal: 2m 10s\tremaining: 5m 23s\n",
      "144:\tlearn: 0.3112233\ttotal: 2m 11s\tremaining: 5m 22s\n",
      "145:\tlearn: 0.3106322\ttotal: 2m 12s\tremaining: 5m 21s\n",
      "146:\tlearn: 0.3100549\ttotal: 2m 13s\tremaining: 5m 20s\n",
      "147:\tlearn: 0.3094897\ttotal: 2m 14s\tremaining: 5m 19s\n",
      "148:\tlearn: 0.3088133\ttotal: 2m 14s\tremaining: 5m 18s\n",
      "149:\tlearn: 0.3083266\ttotal: 2m 15s\tremaining: 5m 17s\n",
      "150:\tlearn: 0.3076758\ttotal: 2m 16s\tremaining: 5m 16s\n",
      "151:\tlearn: 0.3070222\ttotal: 2m 17s\tremaining: 5m 15s\n",
      "152:\tlearn: 0.3065596\ttotal: 2m 18s\tremaining: 5m 14s\n",
      "153:\tlearn: 0.3060150\ttotal: 2m 19s\tremaining: 5m 13s\n",
      "154:\tlearn: 0.3054418\ttotal: 2m 20s\tremaining: 5m 12s\n",
      "155:\tlearn: 0.3049085\ttotal: 2m 21s\tremaining: 5m 11s\n",
      "156:\tlearn: 0.3043715\ttotal: 2m 22s\tremaining: 5m 10s\n",
      "157:\tlearn: 0.3037927\ttotal: 2m 22s\tremaining: 5m 9s\n",
      "158:\tlearn: 0.3031530\ttotal: 2m 23s\tremaining: 5m 8s\n",
      "159:\tlearn: 0.3027395\ttotal: 2m 24s\tremaining: 5m 7s\n",
      "160:\tlearn: 0.3022790\ttotal: 2m 25s\tremaining: 5m 6s\n",
      "161:\tlearn: 0.3015934\ttotal: 2m 26s\tremaining: 5m 5s\n",
      "162:\tlearn: 0.3009246\ttotal: 2m 27s\tremaining: 5m 4s\n",
      "163:\tlearn: 0.3004489\ttotal: 2m 28s\tremaining: 5m 3s\n",
      "164:\tlearn: 0.2996985\ttotal: 2m 29s\tremaining: 5m 2s\n",
      "165:\tlearn: 0.2991638\ttotal: 2m 29s\tremaining: 5m 1s\n",
      "166:\tlearn: 0.2983869\ttotal: 2m 30s\tremaining: 5m\n",
      "167:\tlearn: 0.2975374\ttotal: 2m 31s\tremaining: 4m 59s\n",
      "168:\tlearn: 0.2971086\ttotal: 2m 32s\tremaining: 4m 58s\n",
      "169:\tlearn: 0.2964291\ttotal: 2m 33s\tremaining: 4m 57s\n",
      "170:\tlearn: 0.2959784\ttotal: 2m 34s\tremaining: 4m 56s\n",
      "171:\tlearn: 0.2953278\ttotal: 2m 34s\tremaining: 4m 55s\n",
      "172:\tlearn: 0.2947618\ttotal: 2m 35s\tremaining: 4m 54s\n",
      "173:\tlearn: 0.2943195\ttotal: 2m 36s\tremaining: 4m 53s\n",
      "174:\tlearn: 0.2937928\ttotal: 2m 37s\tremaining: 4m 52s\n",
      "175:\tlearn: 0.2934186\ttotal: 2m 38s\tremaining: 4m 51s\n",
      "176:\tlearn: 0.2929676\ttotal: 2m 39s\tremaining: 4m 50s\n",
      "177:\tlearn: 0.2924689\ttotal: 2m 39s\tremaining: 4m 49s\n",
      "178:\tlearn: 0.2919614\ttotal: 2m 40s\tremaining: 4m 48s\n",
      "179:\tlearn: 0.2916058\ttotal: 2m 41s\tremaining: 4m 47s\n",
      "180:\tlearn: 0.2911304\ttotal: 2m 42s\tremaining: 4m 46s\n",
      "181:\tlearn: 0.2907239\ttotal: 2m 43s\tremaining: 4m 45s\n",
      "182:\tlearn: 0.2901975\ttotal: 2m 44s\tremaining: 4m 44s\n",
      "183:\tlearn: 0.2896924\ttotal: 2m 44s\tremaining: 4m 43s\n",
      "184:\tlearn: 0.2892055\ttotal: 2m 45s\tremaining: 4m 42s\n",
      "185:\tlearn: 0.2887060\ttotal: 2m 46s\tremaining: 4m 41s\n",
      "186:\tlearn: 0.2882189\ttotal: 2m 47s\tremaining: 4m 40s\n",
      "187:\tlearn: 0.2877211\ttotal: 2m 48s\tremaining: 4m 39s\n",
      "188:\tlearn: 0.2874166\ttotal: 2m 49s\tremaining: 4m 38s\n",
      "189:\tlearn: 0.2870117\ttotal: 2m 49s\tremaining: 4m 37s\n",
      "190:\tlearn: 0.2865423\ttotal: 2m 50s\tremaining: 4m 36s\n",
      "191:\tlearn: 0.2861353\ttotal: 2m 51s\tremaining: 4m 35s\n",
      "192:\tlearn: 0.2856885\ttotal: 2m 52s\tremaining: 4m 34s\n",
      "193:\tlearn: 0.2847443\ttotal: 2m 53s\tremaining: 4m 33s\n",
      "194:\tlearn: 0.2844162\ttotal: 2m 54s\tremaining: 4m 32s\n",
      "195:\tlearn: 0.2839703\ttotal: 2m 54s\tremaining: 4m 31s\n",
      "196:\tlearn: 0.2835216\ttotal: 2m 55s\tremaining: 4m 30s\n",
      "197:\tlearn: 0.2830700\ttotal: 2m 56s\tremaining: 4m 29s\n",
      "198:\tlearn: 0.2826400\ttotal: 2m 57s\tremaining: 4m 28s\n",
      "199:\tlearn: 0.2817880\ttotal: 2m 58s\tremaining: 4m 27s\n",
      "200:\tlearn: 0.2813875\ttotal: 2m 59s\tremaining: 4m 26s\n",
      "201:\tlearn: 0.2809465\ttotal: 2m 59s\tremaining: 4m 25s\n",
      "202:\tlearn: 0.2805840\ttotal: 3m\tremaining: 4m 24s\n",
      "203:\tlearn: 0.2800971\ttotal: 3m 1s\tremaining: 4m 23s\n",
      "204:\tlearn: 0.2797333\ttotal: 3m 2s\tremaining: 4m 22s\n",
      "205:\tlearn: 0.2793649\ttotal: 3m 3s\tremaining: 4m 21s\n",
      "206:\tlearn: 0.2790105\ttotal: 3m 4s\tremaining: 4m 20s\n",
      "207:\tlearn: 0.2785356\ttotal: 3m 5s\tremaining: 4m 19s\n",
      "208:\tlearn: 0.2781284\ttotal: 3m 5s\tremaining: 4m 18s\n",
      "209:\tlearn: 0.2777063\ttotal: 3m 6s\tremaining: 4m 17s\n",
      "210:\tlearn: 0.2772465\ttotal: 3m 7s\tremaining: 4m 16s\n",
      "211:\tlearn: 0.2767464\ttotal: 3m 8s\tremaining: 4m 15s\n",
      "212:\tlearn: 0.2761113\ttotal: 3m 9s\tremaining: 4m 14s\n",
      "213:\tlearn: 0.2757443\ttotal: 3m 9s\tremaining: 4m 13s\n",
      "214:\tlearn: 0.2753022\ttotal: 3m 10s\tremaining: 4m 12s\n",
      "215:\tlearn: 0.2748906\ttotal: 3m 11s\tremaining: 4m 11s\n",
      "216:\tlearn: 0.2745716\ttotal: 3m 12s\tremaining: 4m 10s\n",
      "217:\tlearn: 0.2740594\ttotal: 3m 13s\tremaining: 4m 9s\n",
      "218:\tlearn: 0.2736959\ttotal: 3m 14s\tremaining: 4m 9s\n",
      "219:\tlearn: 0.2733100\ttotal: 3m 14s\tremaining: 4m 8s\n",
      "220:\tlearn: 0.2729111\ttotal: 3m 15s\tremaining: 4m 7s\n",
      "221:\tlearn: 0.2724073\ttotal: 3m 16s\tremaining: 4m 6s\n",
      "222:\tlearn: 0.2721567\ttotal: 3m 17s\tremaining: 4m 5s\n",
      "223:\tlearn: 0.2717206\ttotal: 3m 18s\tremaining: 4m 4s\n",
      "224:\tlearn: 0.2713126\ttotal: 3m 19s\tremaining: 4m 3s\n",
      "225:\tlearn: 0.2710037\ttotal: 3m 20s\tremaining: 4m 3s\n",
      "226:\tlearn: 0.2700749\ttotal: 3m 21s\tremaining: 4m 2s\n",
      "227:\tlearn: 0.2697095\ttotal: 3m 22s\tremaining: 4m 1s\n",
      "228:\tlearn: 0.2693302\ttotal: 3m 23s\tremaining: 4m\n",
      "229:\tlearn: 0.2689248\ttotal: 3m 23s\tremaining: 3m 59s\n",
      "230:\tlearn: 0.2685443\ttotal: 3m 24s\tremaining: 3m 58s\n",
      "231:\tlearn: 0.2681602\ttotal: 3m 25s\tremaining: 3m 57s\n",
      "232:\tlearn: 0.2678765\ttotal: 3m 26s\tremaining: 3m 56s\n",
      "233:\tlearn: 0.2674810\ttotal: 3m 27s\tremaining: 3m 55s\n",
      "234:\tlearn: 0.2671554\ttotal: 3m 28s\tremaining: 3m 54s\n",
      "235:\tlearn: 0.2668538\ttotal: 3m 28s\tremaining: 3m 53s\n",
      "236:\tlearn: 0.2665984\ttotal: 3m 29s\tremaining: 3m 52s\n",
      "237:\tlearn: 0.2661611\ttotal: 3m 30s\tremaining: 3m 51s\n",
      "238:\tlearn: 0.2658127\ttotal: 3m 31s\tremaining: 3m 50s\n",
      "239:\tlearn: 0.2654403\ttotal: 3m 32s\tremaining: 3m 49s\n",
      "240:\tlearn: 0.2651027\ttotal: 3m 33s\tremaining: 3m 48s\n",
      "241:\tlearn: 0.2647818\ttotal: 3m 33s\tremaining: 3m 48s\n",
      "242:\tlearn: 0.2645418\ttotal: 3m 34s\tremaining: 3m 47s\n",
      "243:\tlearn: 0.2641869\ttotal: 3m 35s\tremaining: 3m 46s\n",
      "244:\tlearn: 0.2639463\ttotal: 3m 36s\tremaining: 3m 45s\n",
      "245:\tlearn: 0.2637198\ttotal: 3m 37s\tremaining: 3m 44s\n",
      "246:\tlearn: 0.2634362\ttotal: 3m 38s\tremaining: 3m 43s\n",
      "247:\tlearn: 0.2632392\ttotal: 3m 38s\tremaining: 3m 42s\n",
      "248:\tlearn: 0.2628327\ttotal: 3m 39s\tremaining: 3m 41s\n",
      "249:\tlearn: 0.2624706\ttotal: 3m 40s\tremaining: 3m 40s\n",
      "250:\tlearn: 0.2619037\ttotal: 3m 41s\tremaining: 3m 39s\n",
      "251:\tlearn: 0.2614976\ttotal: 3m 42s\tremaining: 3m 38s\n",
      "252:\tlearn: 0.2611773\ttotal: 3m 43s\tremaining: 3m 37s\n",
      "253:\tlearn: 0.2608281\ttotal: 3m 43s\tremaining: 3m 36s\n",
      "254:\tlearn: 0.2605764\ttotal: 3m 44s\tremaining: 3m 35s\n",
      "255:\tlearn: 0.2602328\ttotal: 3m 45s\tremaining: 3m 34s\n",
      "256:\tlearn: 0.2599740\ttotal: 3m 46s\tremaining: 3m 34s\n",
      "257:\tlearn: 0.2593353\ttotal: 3m 47s\tremaining: 3m 33s\n",
      "258:\tlearn: 0.2589869\ttotal: 3m 47s\tremaining: 3m 32s\n",
      "259:\tlearn: 0.2586510\ttotal: 3m 48s\tremaining: 3m 31s\n",
      "260:\tlearn: 0.2583512\ttotal: 3m 49s\tremaining: 3m 30s\n",
      "261:\tlearn: 0.2580180\ttotal: 3m 50s\tremaining: 3m 29s\n",
      "262:\tlearn: 0.2574993\ttotal: 3m 51s\tremaining: 3m 28s\n",
      "263:\tlearn: 0.2571743\ttotal: 3m 52s\tremaining: 3m 27s\n",
      "264:\tlearn: 0.2566182\ttotal: 3m 52s\tremaining: 3m 26s\n",
      "265:\tlearn: 0.2562903\ttotal: 3m 53s\tremaining: 3m 25s\n",
      "266:\tlearn: 0.2560726\ttotal: 3m 54s\tremaining: 3m 24s\n",
      "267:\tlearn: 0.2557988\ttotal: 3m 55s\tremaining: 3m 23s\n",
      "268:\tlearn: 0.2554294\ttotal: 3m 56s\tremaining: 3m 22s\n",
      "269:\tlearn: 0.2549815\ttotal: 3m 57s\tremaining: 3m 21s\n",
      "270:\tlearn: 0.2545925\ttotal: 3m 57s\tremaining: 3m 21s\n",
      "271:\tlearn: 0.2542921\ttotal: 3m 58s\tremaining: 3m 20s\n",
      "272:\tlearn: 0.2537771\ttotal: 3m 59s\tremaining: 3m 19s\n",
      "273:\tlearn: 0.2535823\ttotal: 4m\tremaining: 3m 18s\n",
      "274:\tlearn: 0.2529526\ttotal: 4m 1s\tremaining: 3m 17s\n",
      "275:\tlearn: 0.2526210\ttotal: 4m 2s\tremaining: 3m 16s\n",
      "276:\tlearn: 0.2523854\ttotal: 4m 2s\tremaining: 3m 15s\n",
      "277:\tlearn: 0.2520238\ttotal: 4m 3s\tremaining: 3m 14s\n",
      "278:\tlearn: 0.2517015\ttotal: 4m 4s\tremaining: 3m 13s\n",
      "279:\tlearn: 0.2513681\ttotal: 4m 5s\tremaining: 3m 12s\n",
      "280:\tlearn: 0.2511950\ttotal: 4m 6s\tremaining: 3m 12s\n",
      "281:\tlearn: 0.2508870\ttotal: 4m 7s\tremaining: 3m 11s\n",
      "282:\tlearn: 0.2506207\ttotal: 4m 8s\tremaining: 3m 10s\n",
      "283:\tlearn: 0.2503501\ttotal: 4m 9s\tremaining: 3m 9s\n",
      "284:\tlearn: 0.2500630\ttotal: 4m 10s\tremaining: 3m 8s\n",
      "285:\tlearn: 0.2496587\ttotal: 4m 11s\tremaining: 3m 7s\n",
      "286:\tlearn: 0.2494041\ttotal: 4m 12s\tremaining: 3m 7s\n",
      "287:\tlearn: 0.2491074\ttotal: 4m 12s\tremaining: 3m 6s\n",
      "288:\tlearn: 0.2488520\ttotal: 4m 13s\tremaining: 3m 5s\n",
      "289:\tlearn: 0.2485610\ttotal: 4m 14s\tremaining: 3m 4s\n",
      "290:\tlearn: 0.2482950\ttotal: 4m 15s\tremaining: 3m 3s\n",
      "291:\tlearn: 0.2480737\ttotal: 4m 16s\tremaining: 3m 2s\n",
      "292:\tlearn: 0.2477635\ttotal: 4m 17s\tremaining: 3m 1s\n",
      "293:\tlearn: 0.2475112\ttotal: 4m 18s\tremaining: 3m\n",
      "294:\tlearn: 0.2468607\ttotal: 4m 19s\tremaining: 3m\n",
      "295:\tlearn: 0.2466181\ttotal: 4m 20s\tremaining: 2m 59s\n",
      "296:\tlearn: 0.2462980\ttotal: 4m 20s\tremaining: 2m 58s\n",
      "297:\tlearn: 0.2459451\ttotal: 4m 21s\tremaining: 2m 57s\n",
      "298:\tlearn: 0.2455544\ttotal: 4m 22s\tremaining: 2m 56s\n",
      "299:\tlearn: 0.2454031\ttotal: 4m 23s\tremaining: 2m 55s\n",
      "300:\tlearn: 0.2452030\ttotal: 4m 24s\tremaining: 2m 54s\n",
      "301:\tlearn: 0.2450000\ttotal: 4m 25s\tremaining: 2m 53s\n",
      "302:\tlearn: 0.2447586\ttotal: 4m 25s\tremaining: 2m 52s\n",
      "303:\tlearn: 0.2444376\ttotal: 4m 26s\tremaining: 2m 51s\n",
      "304:\tlearn: 0.2440711\ttotal: 4m 27s\tremaining: 2m 51s\n",
      "305:\tlearn: 0.2436123\ttotal: 4m 28s\tremaining: 2m 50s\n",
      "306:\tlearn: 0.2432641\ttotal: 4m 29s\tremaining: 2m 49s\n",
      "307:\tlearn: 0.2430079\ttotal: 4m 30s\tremaining: 2m 48s\n",
      "308:\tlearn: 0.2427112\ttotal: 4m 31s\tremaining: 2m 47s\n",
      "309:\tlearn: 0.2423785\ttotal: 4m 31s\tremaining: 2m 46s\n",
      "310:\tlearn: 0.2421855\ttotal: 4m 32s\tremaining: 2m 45s\n",
      "311:\tlearn: 0.2419386\ttotal: 4m 33s\tremaining: 2m 44s\n",
      "312:\tlearn: 0.2417064\ttotal: 4m 34s\tremaining: 2m 43s\n",
      "313:\tlearn: 0.2413236\ttotal: 4m 35s\tremaining: 2m 42s\n",
      "314:\tlearn: 0.2410200\ttotal: 4m 35s\tremaining: 2m 42s\n",
      "315:\tlearn: 0.2408322\ttotal: 4m 36s\tremaining: 2m 41s\n",
      "316:\tlearn: 0.2404544\ttotal: 4m 37s\tremaining: 2m 40s\n",
      "317:\tlearn: 0.2402344\ttotal: 4m 38s\tremaining: 2m 39s\n",
      "318:\tlearn: 0.2399299\ttotal: 4m 39s\tremaining: 2m 38s\n",
      "319:\tlearn: 0.2397883\ttotal: 4m 40s\tremaining: 2m 37s\n",
      "320:\tlearn: 0.2395981\ttotal: 4m 40s\tremaining: 2m 36s\n",
      "321:\tlearn: 0.2392622\ttotal: 4m 41s\tremaining: 2m 35s\n",
      "322:\tlearn: 0.2390538\ttotal: 4m 42s\tremaining: 2m 34s\n",
      "323:\tlearn: 0.2387971\ttotal: 4m 43s\tremaining: 2m 34s\n",
      "324:\tlearn: 0.2386650\ttotal: 4m 44s\tremaining: 2m 33s\n",
      "325:\tlearn: 0.2384856\ttotal: 4m 45s\tremaining: 2m 32s\n",
      "326:\tlearn: 0.2381662\ttotal: 4m 45s\tremaining: 2m 31s\n",
      "327:\tlearn: 0.2378863\ttotal: 4m 46s\tremaining: 2m 30s\n",
      "328:\tlearn: 0.2374425\ttotal: 4m 47s\tremaining: 2m 29s\n",
      "329:\tlearn: 0.2372265\ttotal: 4m 48s\tremaining: 2m 28s\n",
      "330:\tlearn: 0.2369087\ttotal: 4m 49s\tremaining: 2m 27s\n",
      "331:\tlearn: 0.2365867\ttotal: 4m 50s\tremaining: 2m 26s\n",
      "332:\tlearn: 0.2363545\ttotal: 4m 50s\tremaining: 2m 25s\n",
      "333:\tlearn: 0.2361040\ttotal: 4m 51s\tremaining: 2m 25s\n",
      "334:\tlearn: 0.2358664\ttotal: 4m 52s\tremaining: 2m 24s\n",
      "335:\tlearn: 0.2357362\ttotal: 4m 53s\tremaining: 2m 23s\n",
      "336:\tlearn: 0.2355017\ttotal: 4m 54s\tremaining: 2m 22s\n",
      "337:\tlearn: 0.2352292\ttotal: 4m 55s\tremaining: 2m 21s\n",
      "338:\tlearn: 0.2349671\ttotal: 4m 55s\tremaining: 2m 20s\n",
      "339:\tlearn: 0.2347568\ttotal: 4m 56s\tremaining: 2m 19s\n",
      "340:\tlearn: 0.2345870\ttotal: 4m 57s\tremaining: 2m 18s\n",
      "341:\tlearn: 0.2343581\ttotal: 4m 58s\tremaining: 2m 17s\n",
      "342:\tlearn: 0.2340573\ttotal: 4m 59s\tremaining: 2m 16s\n",
      "343:\tlearn: 0.2338316\ttotal: 5m\tremaining: 2m 16s\n",
      "344:\tlearn: 0.2337065\ttotal: 5m\tremaining: 2m 15s\n",
      "345:\tlearn: 0.2335334\ttotal: 5m 1s\tremaining: 2m 14s\n",
      "346:\tlearn: 0.2333060\ttotal: 5m 2s\tremaining: 2m 13s\n",
      "347:\tlearn: 0.2331282\ttotal: 5m 3s\tremaining: 2m 12s\n",
      "348:\tlearn: 0.2329021\ttotal: 5m 4s\tremaining: 2m 11s\n",
      "349:\tlearn: 0.2325976\ttotal: 5m 5s\tremaining: 2m 10s\n",
      "350:\tlearn: 0.2323015\ttotal: 5m 5s\tremaining: 2m 9s\n",
      "351:\tlearn: 0.2320651\ttotal: 5m 6s\tremaining: 2m 8s\n",
      "352:\tlearn: 0.2317720\ttotal: 5m 7s\tremaining: 2m 8s\n",
      "353:\tlearn: 0.2315972\ttotal: 5m 8s\tremaining: 2m 7s\n",
      "354:\tlearn: 0.2313731\ttotal: 5m 9s\tremaining: 2m 6s\n",
      "355:\tlearn: 0.2312104\ttotal: 5m 9s\tremaining: 2m 5s\n",
      "356:\tlearn: 0.2309295\ttotal: 5m 10s\tremaining: 2m 4s\n",
      "357:\tlearn: 0.2305916\ttotal: 5m 11s\tremaining: 2m 3s\n",
      "358:\tlearn: 0.2304220\ttotal: 5m 12s\tremaining: 2m 2s\n",
      "359:\tlearn: 0.2302153\ttotal: 5m 13s\tremaining: 2m 1s\n",
      "360:\tlearn: 0.2300964\ttotal: 5m 14s\tremaining: 2m\n",
      "361:\tlearn: 0.2298631\ttotal: 5m 14s\tremaining: 2m\n",
      "362:\tlearn: 0.2296068\ttotal: 5m 15s\tremaining: 1m 59s\n",
      "363:\tlearn: 0.2293658\ttotal: 5m 16s\tremaining: 1m 58s\n",
      "364:\tlearn: 0.2291905\ttotal: 5m 17s\tremaining: 1m 57s\n",
      "365:\tlearn: 0.2290196\ttotal: 5m 18s\tremaining: 1m 56s\n",
      "366:\tlearn: 0.2289018\ttotal: 5m 18s\tremaining: 1m 55s\n",
      "367:\tlearn: 0.2286698\ttotal: 5m 19s\tremaining: 1m 54s\n",
      "368:\tlearn: 0.2284207\ttotal: 5m 20s\tremaining: 1m 53s\n",
      "369:\tlearn: 0.2281523\ttotal: 5m 21s\tremaining: 1m 52s\n",
      "370:\tlearn: 0.2279665\ttotal: 5m 22s\tremaining: 1m 52s\n",
      "371:\tlearn: 0.2276471\ttotal: 5m 23s\tremaining: 1m 51s\n",
      "372:\tlearn: 0.2274973\ttotal: 5m 23s\tremaining: 1m 50s\n",
      "373:\tlearn: 0.2272595\ttotal: 5m 24s\tremaining: 1m 49s\n",
      "374:\tlearn: 0.2271444\ttotal: 5m 25s\tremaining: 1m 48s\n",
      "375:\tlearn: 0.2268891\ttotal: 5m 26s\tremaining: 1m 47s\n",
      "376:\tlearn: 0.2264781\ttotal: 5m 27s\tremaining: 1m 46s\n",
      "377:\tlearn: 0.2260579\ttotal: 5m 28s\tremaining: 1m 45s\n",
      "378:\tlearn: 0.2258525\ttotal: 5m 28s\tremaining: 1m 44s\n",
      "379:\tlearn: 0.2255869\ttotal: 5m 29s\tremaining: 1m 44s\n",
      "380:\tlearn: 0.2254423\ttotal: 5m 30s\tremaining: 1m 43s\n",
      "381:\tlearn: 0.2252361\ttotal: 5m 31s\tremaining: 1m 42s\n",
      "382:\tlearn: 0.2249821\ttotal: 5m 32s\tremaining: 1m 41s\n",
      "383:\tlearn: 0.2247577\ttotal: 5m 32s\tremaining: 1m 40s\n",
      "384:\tlearn: 0.2246452\ttotal: 5m 33s\tremaining: 1m 39s\n",
      "385:\tlearn: 0.2244890\ttotal: 5m 34s\tremaining: 1m 38s\n",
      "386:\tlearn: 0.2243786\ttotal: 5m 35s\tremaining: 1m 37s\n",
      "387:\tlearn: 0.2241612\ttotal: 5m 36s\tremaining: 1m 37s\n",
      "388:\tlearn: 0.2239530\ttotal: 5m 37s\tremaining: 1m 36s\n",
      "389:\tlearn: 0.2236859\ttotal: 5m 37s\tremaining: 1m 35s\n",
      "390:\tlearn: 0.2235733\ttotal: 5m 38s\tremaining: 1m 34s\n",
      "391:\tlearn: 0.2233607\ttotal: 5m 39s\tremaining: 1m 33s\n",
      "392:\tlearn: 0.2231198\ttotal: 5m 40s\tremaining: 1m 32s\n",
      "393:\tlearn: 0.2226889\ttotal: 5m 41s\tremaining: 1m 31s\n",
      "394:\tlearn: 0.2223812\ttotal: 5m 42s\tremaining: 1m 30s\n",
      "395:\tlearn: 0.2222397\ttotal: 5m 42s\tremaining: 1m 30s\n",
      "396:\tlearn: 0.2220184\ttotal: 5m 43s\tremaining: 1m 29s\n",
      "397:\tlearn: 0.2219092\ttotal: 5m 44s\tremaining: 1m 28s\n",
      "398:\tlearn: 0.2218009\ttotal: 5m 45s\tremaining: 1m 27s\n",
      "399:\tlearn: 0.2215076\ttotal: 5m 46s\tremaining: 1m 26s\n",
      "400:\tlearn: 0.2213637\ttotal: 5m 47s\tremaining: 1m 25s\n",
      "401:\tlearn: 0.2210501\ttotal: 5m 48s\tremaining: 1m 24s\n",
      "402:\tlearn: 0.2208952\ttotal: 5m 49s\tremaining: 1m 24s\n",
      "403:\tlearn: 0.2206389\ttotal: 5m 50s\tremaining: 1m 23s\n",
      "404:\tlearn: 0.2205334\ttotal: 5m 51s\tremaining: 1m 22s\n",
      "405:\tlearn: 0.2203301\ttotal: 5m 52s\tremaining: 1m 21s\n",
      "406:\tlearn: 0.2200888\ttotal: 5m 53s\tremaining: 1m 20s\n",
      "407:\tlearn: 0.2198582\ttotal: 5m 54s\tremaining: 1m 19s\n",
      "408:\tlearn: 0.2196681\ttotal: 5m 55s\tremaining: 1m 19s\n",
      "409:\tlearn: 0.2194851\ttotal: 5m 56s\tremaining: 1m 18s\n",
      "410:\tlearn: 0.2193780\ttotal: 5m 57s\tremaining: 1m 17s\n",
      "411:\tlearn: 0.2191347\ttotal: 5m 58s\tremaining: 1m 16s\n",
      "412:\tlearn: 0.2189162\ttotal: 5m 59s\tremaining: 1m 15s\n",
      "413:\tlearn: 0.2188107\ttotal: 6m\tremaining: 1m 14s\n",
      "414:\tlearn: 0.2185531\ttotal: 6m 1s\tremaining: 1m 14s\n",
      "415:\tlearn: 0.2182919\ttotal: 6m 3s\tremaining: 1m 13s\n",
      "416:\tlearn: 0.2180952\ttotal: 6m 4s\tremaining: 1m 12s\n",
      "417:\tlearn: 0.2179468\ttotal: 6m 5s\tremaining: 1m 11s\n",
      "418:\tlearn: 0.2177061\ttotal: 6m 6s\tremaining: 1m 10s\n",
      "419:\tlearn: 0.2174751\ttotal: 6m 7s\tremaining: 1m 10s\n",
      "420:\tlearn: 0.2171818\ttotal: 6m 8s\tremaining: 1m 9s\n",
      "421:\tlearn: 0.2170028\ttotal: 6m 9s\tremaining: 1m 8s\n",
      "422:\tlearn: 0.2167948\ttotal: 6m 10s\tremaining: 1m 7s\n",
      "423:\tlearn: 0.2164614\ttotal: 6m 11s\tremaining: 1m 6s\n",
      "424:\tlearn: 0.2159517\ttotal: 6m 13s\tremaining: 1m 5s\n",
      "425:\tlearn: 0.2158479\ttotal: 6m 14s\tremaining: 1m 5s\n",
      "426:\tlearn: 0.2157258\ttotal: 6m 15s\tremaining: 1m 4s\n",
      "427:\tlearn: 0.2155304\ttotal: 6m 16s\tremaining: 1m 3s\n",
      "428:\tlearn: 0.2153181\ttotal: 6m 17s\tremaining: 1m 2s\n",
      "429:\tlearn: 0.2150736\ttotal: 6m 18s\tremaining: 1m 1s\n",
      "430:\tlearn: 0.2148715\ttotal: 6m 20s\tremaining: 1m\n",
      "431:\tlearn: 0.2146243\ttotal: 6m 21s\tremaining: 1m\n",
      "432:\tlearn: 0.2144976\ttotal: 6m 22s\tremaining: 59.2s\n",
      "433:\tlearn: 0.2141843\ttotal: 6m 23s\tremaining: 58.3s\n",
      "434:\tlearn: 0.2139881\ttotal: 6m 24s\tremaining: 57.4s\n",
      "435:\tlearn: 0.2138043\ttotal: 6m 25s\tremaining: 56.6s\n",
      "436:\tlearn: 0.2135353\ttotal: 6m 26s\tremaining: 55.7s\n",
      "437:\tlearn: 0.2134334\ttotal: 6m 27s\tremaining: 54.9s\n",
      "438:\tlearn: 0.2132099\ttotal: 6m 28s\tremaining: 54s\n",
      "439:\tlearn: 0.2129918\ttotal: 6m 29s\tremaining: 53.1s\n",
      "440:\tlearn: 0.2127791\ttotal: 6m 30s\tremaining: 52.3s\n",
      "441:\tlearn: 0.2124360\ttotal: 6m 31s\tremaining: 51.4s\n",
      "442:\tlearn: 0.2121728\ttotal: 6m 32s\tremaining: 50.5s\n",
      "443:\tlearn: 0.2120199\ttotal: 6m 33s\tremaining: 49.6s\n",
      "444:\tlearn: 0.2116084\ttotal: 6m 34s\tremaining: 48.7s\n",
      "445:\tlearn: 0.2111302\ttotal: 6m 35s\tremaining: 47.9s\n",
      "446:\tlearn: 0.2110294\ttotal: 6m 36s\tremaining: 47s\n",
      "447:\tlearn: 0.2108146\ttotal: 6m 37s\tremaining: 46.1s\n",
      "448:\tlearn: 0.2105717\ttotal: 6m 38s\tremaining: 45.2s\n",
      "449:\tlearn: 0.2104403\ttotal: 6m 39s\tremaining: 44.3s\n",
      "450:\tlearn: 0.2103365\ttotal: 6m 40s\tremaining: 43.5s\n",
      "451:\tlearn: 0.2102397\ttotal: 6m 41s\tremaining: 42.6s\n",
      "452:\tlearn: 0.2099800\ttotal: 6m 42s\tremaining: 41.7s\n",
      "453:\tlearn: 0.2097788\ttotal: 6m 43s\tremaining: 40.9s\n",
      "454:\tlearn: 0.2096794\ttotal: 6m 44s\tremaining: 40s\n",
      "455:\tlearn: 0.2094930\ttotal: 6m 45s\tremaining: 39.1s\n",
      "456:\tlearn: 0.2092750\ttotal: 6m 46s\tremaining: 38.2s\n",
      "457:\tlearn: 0.2091752\ttotal: 6m 47s\tremaining: 37.3s\n",
      "458:\tlearn: 0.2090771\ttotal: 6m 48s\tremaining: 36.5s\n",
      "459:\tlearn: 0.2089781\ttotal: 6m 49s\tremaining: 35.6s\n",
      "460:\tlearn: 0.2088786\ttotal: 6m 50s\tremaining: 34.7s\n",
      "461:\tlearn: 0.2086676\ttotal: 6m 51s\tremaining: 33.8s\n",
      "462:\tlearn: 0.2085700\ttotal: 6m 51s\tremaining: 32.9s\n",
      "463:\tlearn: 0.2082513\ttotal: 6m 52s\tremaining: 32s\n",
      "464:\tlearn: 0.2080752\ttotal: 6m 54s\tremaining: 31.2s\n",
      "465:\tlearn: 0.2079223\ttotal: 6m 55s\tremaining: 30.3s\n",
      "466:\tlearn: 0.2077335\ttotal: 6m 56s\tremaining: 29.4s\n",
      "467:\tlearn: 0.2075054\ttotal: 6m 57s\tremaining: 28.5s\n",
      "468:\tlearn: 0.2074052\ttotal: 6m 58s\tremaining: 27.6s\n",
      "469:\tlearn: 0.2072379\ttotal: 6m 59s\tremaining: 26.7s\n",
      "470:\tlearn: 0.2071428\ttotal: 7m\tremaining: 25.9s\n",
      "471:\tlearn: 0.2070292\ttotal: 7m\tremaining: 25s\n",
      "472:\tlearn: 0.2067764\ttotal: 7m 2s\tremaining: 24.1s\n",
      "473:\tlearn: 0.2066853\ttotal: 7m 3s\tremaining: 23.2s\n",
      "474:\tlearn: 0.2064987\ttotal: 7m 3s\tremaining: 22.3s\n",
      "475:\tlearn: 0.2064044\ttotal: 7m 4s\tremaining: 21.4s\n",
      "476:\tlearn: 0.2062049\ttotal: 7m 6s\tremaining: 20.5s\n",
      "477:\tlearn: 0.2060571\ttotal: 7m 7s\tremaining: 19.7s\n",
      "478:\tlearn: 0.2059661\ttotal: 7m 7s\tremaining: 18.8s\n",
      "479:\tlearn: 0.2058032\ttotal: 7m 8s\tremaining: 17.9s\n",
      "480:\tlearn: 0.2056106\ttotal: 7m 10s\tremaining: 17s\n",
      "481:\tlearn: 0.2054052\ttotal: 7m 11s\tremaining: 16.1s\n",
      "482:\tlearn: 0.2052792\ttotal: 7m 12s\tremaining: 15.2s\n",
      "483:\tlearn: 0.2050718\ttotal: 7m 13s\tremaining: 14.3s\n",
      "484:\tlearn: 0.2049807\ttotal: 7m 14s\tremaining: 13.4s\n",
      "485:\tlearn: 0.2047663\ttotal: 7m 15s\tremaining: 12.5s\n",
      "486:\tlearn: 0.2046493\ttotal: 7m 16s\tremaining: 11.6s\n",
      "487:\tlearn: 0.2044885\ttotal: 7m 17s\tremaining: 10.8s\n",
      "488:\tlearn: 0.2040371\ttotal: 7m 18s\tremaining: 9.86s\n",
      "489:\tlearn: 0.2038400\ttotal: 7m 19s\tremaining: 8.97s\n",
      "490:\tlearn: 0.2036108\ttotal: 7m 20s\tremaining: 8.07s\n",
      "491:\tlearn: 0.2034130\ttotal: 7m 21s\tremaining: 7.18s\n",
      "492:\tlearn: 0.2033253\ttotal: 7m 22s\tremaining: 6.28s\n",
      "493:\tlearn: 0.2031292\ttotal: 7m 23s\tremaining: 5.38s\n",
      "494:\tlearn: 0.2029615\ttotal: 7m 24s\tremaining: 4.49s\n",
      "495:\tlearn: 0.2027883\ttotal: 7m 25s\tremaining: 3.59s\n",
      "496:\tlearn: 0.2025889\ttotal: 7m 25s\tremaining: 2.69s\n",
      "497:\tlearn: 0.2022816\ttotal: 7m 26s\tremaining: 1.79s\n",
      "498:\tlearn: 0.2020740\ttotal: 7m 27s\tremaining: 897ms\n",
      "499:\tlearn: 0.2019832\ttotal: 7m 28s\tremaining: 0us\n",
      "[CV 1/5] END auto_class_weights=Balanced, iterations=500, random_state=12345;, score=0.735 total time= 7.6min\n",
      "Learning rate set to 0.12034\n",
      "0:\tlearn: 0.6410586\ttotal: 946ms\tremaining: 7m 52s\n",
      "1:\tlearn: 0.6061702\ttotal: 1.84s\tremaining: 7m 39s\n",
      "2:\tlearn: 0.5824541\ttotal: 2.81s\tremaining: 7m 45s\n",
      "3:\tlearn: 0.5618203\ttotal: 3.92s\tremaining: 8m 6s\n",
      "4:\tlearn: 0.5464861\ttotal: 4.97s\tremaining: 8m 12s\n",
      "5:\tlearn: 0.5383988\ttotal: 5.91s\tremaining: 8m 6s\n",
      "6:\tlearn: 0.5302520\ttotal: 6.85s\tremaining: 8m 2s\n",
      "7:\tlearn: 0.5245450\ttotal: 7.8s\tremaining: 7m 59s\n",
      "8:\tlearn: 0.5187587\ttotal: 8.82s\tremaining: 8m 1s\n",
      "9:\tlearn: 0.5121937\ttotal: 9.86s\tremaining: 8m 3s\n",
      "10:\tlearn: 0.5035229\ttotal: 10.9s\tremaining: 8m 2s\n",
      "11:\tlearn: 0.4995752\ttotal: 11.8s\tremaining: 8m\n",
      "12:\tlearn: 0.4934171\ttotal: 12.8s\tremaining: 7m 58s\n",
      "13:\tlearn: 0.4898136\ttotal: 13.8s\tremaining: 7m 57s\n",
      "14:\tlearn: 0.4870577\ttotal: 14.7s\tremaining: 7m 54s\n",
      "15:\tlearn: 0.4831656\ttotal: 15.7s\tremaining: 7m 54s\n",
      "16:\tlearn: 0.4758818\ttotal: 16.7s\tremaining: 7m 54s\n",
      "17:\tlearn: 0.4722624\ttotal: 17.6s\tremaining: 7m 50s\n",
      "18:\tlearn: 0.4694639\ttotal: 18.5s\tremaining: 7m 48s\n",
      "19:\tlearn: 0.4648258\ttotal: 19.4s\tremaining: 7m 44s\n",
      "20:\tlearn: 0.4615930\ttotal: 20.3s\tremaining: 7m 43s\n",
      "21:\tlearn: 0.4585472\ttotal: 21.3s\tremaining: 7m 42s\n",
      "22:\tlearn: 0.4559097\ttotal: 22.3s\tremaining: 7m 43s\n",
      "23:\tlearn: 0.4533842\ttotal: 23.2s\tremaining: 7m 39s\n",
      "24:\tlearn: 0.4495532\ttotal: 24s\tremaining: 7m 36s\n",
      "25:\tlearn: 0.4457823\ttotal: 24.9s\tremaining: 7m 34s\n",
      "26:\tlearn: 0.4431641\ttotal: 25.8s\tremaining: 7m 32s\n",
      "27:\tlearn: 0.4409205\ttotal: 26.7s\tremaining: 7m 30s\n",
      "28:\tlearn: 0.4386346\ttotal: 27.7s\tremaining: 7m 29s\n",
      "29:\tlearn: 0.4370441\ttotal: 28.5s\tremaining: 7m 26s\n",
      "30:\tlearn: 0.4346287\ttotal: 29.4s\tremaining: 7m 24s\n",
      "31:\tlearn: 0.4307689\ttotal: 30.3s\tremaining: 7m 23s\n",
      "32:\tlearn: 0.4278380\ttotal: 31.2s\tremaining: 7m 21s\n",
      "33:\tlearn: 0.4261355\ttotal: 32s\tremaining: 7m 18s\n",
      "34:\tlearn: 0.4242080\ttotal: 32.9s\tremaining: 7m 16s\n",
      "35:\tlearn: 0.4224462\ttotal: 33.7s\tremaining: 7m 14s\n",
      "36:\tlearn: 0.4211448\ttotal: 34.6s\tremaining: 7m 12s\n",
      "37:\tlearn: 0.4190275\ttotal: 35.5s\tremaining: 7m 11s\n",
      "38:\tlearn: 0.4175896\ttotal: 36.4s\tremaining: 7m 9s\n",
      "39:\tlearn: 0.4157337\ttotal: 37.2s\tremaining: 7m 7s\n",
      "40:\tlearn: 0.4140289\ttotal: 38s\tremaining: 7m 5s\n",
      "41:\tlearn: 0.4122730\ttotal: 38.9s\tremaining: 7m 4s\n",
      "42:\tlearn: 0.4110213\ttotal: 39.7s\tremaining: 7m 2s\n",
      "43:\tlearn: 0.4093850\ttotal: 40.6s\tremaining: 7m\n",
      "44:\tlearn: 0.4080048\ttotal: 41.5s\tremaining: 6m 59s\n",
      "45:\tlearn: 0.4070203\ttotal: 42.3s\tremaining: 6m 57s\n",
      "46:\tlearn: 0.4057679\ttotal: 43.1s\tremaining: 6m 55s\n",
      "47:\tlearn: 0.4040335\ttotal: 44s\tremaining: 6m 54s\n",
      "48:\tlearn: 0.4029444\ttotal: 44.9s\tremaining: 6m 53s\n",
      "49:\tlearn: 0.4016205\ttotal: 45.8s\tremaining: 6m 51s\n",
      "50:\tlearn: 0.4001926\ttotal: 46.6s\tremaining: 6m 50s\n",
      "51:\tlearn: 0.3990008\ttotal: 47.5s\tremaining: 6m 49s\n",
      "52:\tlearn: 0.3974343\ttotal: 48.3s\tremaining: 6m 47s\n",
      "53:\tlearn: 0.3957772\ttotal: 49.2s\tremaining: 6m 46s\n",
      "54:\tlearn: 0.3947465\ttotal: 50.1s\tremaining: 6m 44s\n",
      "55:\tlearn: 0.3929124\ttotal: 50.9s\tremaining: 6m 43s\n",
      "56:\tlearn: 0.3917765\ttotal: 51.7s\tremaining: 6m 42s\n",
      "57:\tlearn: 0.3903295\ttotal: 52.6s\tremaining: 6m 40s\n",
      "58:\tlearn: 0.3891836\ttotal: 53.4s\tremaining: 6m 39s\n",
      "59:\tlearn: 0.3883058\ttotal: 54.3s\tremaining: 6m 38s\n",
      "60:\tlearn: 0.3872572\ttotal: 55.1s\tremaining: 6m 36s\n",
      "61:\tlearn: 0.3861222\ttotal: 56s\tremaining: 6m 35s\n",
      "62:\tlearn: 0.3843149\ttotal: 56.8s\tremaining: 6m 34s\n",
      "63:\tlearn: 0.3834781\ttotal: 57.7s\tremaining: 6m 33s\n",
      "64:\tlearn: 0.3818163\ttotal: 58.5s\tremaining: 6m 31s\n",
      "65:\tlearn: 0.3809882\ttotal: 59.4s\tremaining: 6m 30s\n",
      "66:\tlearn: 0.3801574\ttotal: 1m\tremaining: 6m 29s\n",
      "67:\tlearn: 0.3788053\ttotal: 1m 1s\tremaining: 6m 28s\n",
      "68:\tlearn: 0.3780765\ttotal: 1m 1s\tremaining: 6m 27s\n",
      "69:\tlearn: 0.3772933\ttotal: 1m 2s\tremaining: 6m 25s\n",
      "70:\tlearn: 0.3761058\ttotal: 1m 3s\tremaining: 6m 24s\n",
      "71:\tlearn: 0.3750678\ttotal: 1m 4s\tremaining: 6m 23s\n",
      "72:\tlearn: 0.3741001\ttotal: 1m 5s\tremaining: 6m 22s\n",
      "73:\tlearn: 0.3732818\ttotal: 1m 6s\tremaining: 6m 21s\n",
      "74:\tlearn: 0.3723018\ttotal: 1m 7s\tremaining: 6m 19s\n",
      "75:\tlearn: 0.3710302\ttotal: 1m 7s\tremaining: 6m 18s\n",
      "76:\tlearn: 0.3703510\ttotal: 1m 8s\tremaining: 6m 17s\n",
      "77:\tlearn: 0.3698986\ttotal: 1m 9s\tremaining: 6m 16s\n",
      "78:\tlearn: 0.3690727\ttotal: 1m 10s\tremaining: 6m 15s\n",
      "79:\tlearn: 0.3679157\ttotal: 1m 11s\tremaining: 6m 14s\n",
      "80:\tlearn: 0.3671531\ttotal: 1m 12s\tremaining: 6m 13s\n",
      "81:\tlearn: 0.3661925\ttotal: 1m 12s\tremaining: 6m 12s\n",
      "82:\tlearn: 0.3652633\ttotal: 1m 13s\tremaining: 6m 10s\n",
      "83:\tlearn: 0.3643161\ttotal: 1m 14s\tremaining: 6m 9s\n",
      "84:\tlearn: 0.3635098\ttotal: 1m 15s\tremaining: 6m 8s\n",
      "85:\tlearn: 0.3626595\ttotal: 1m 16s\tremaining: 6m 7s\n",
      "86:\tlearn: 0.3613342\ttotal: 1m 17s\tremaining: 6m 6s\n",
      "87:\tlearn: 0.3604458\ttotal: 1m 18s\tremaining: 6m 5s\n",
      "88:\tlearn: 0.3594532\ttotal: 1m 18s\tremaining: 6m 4s\n",
      "89:\tlearn: 0.3581477\ttotal: 1m 19s\tremaining: 6m 3s\n",
      "90:\tlearn: 0.3566377\ttotal: 1m 20s\tremaining: 6m 2s\n",
      "91:\tlearn: 0.3555792\ttotal: 1m 21s\tremaining: 6m 1s\n",
      "92:\tlearn: 0.3547890\ttotal: 1m 22s\tremaining: 6m\n",
      "93:\tlearn: 0.3534860\ttotal: 1m 23s\tremaining: 5m 59s\n",
      "94:\tlearn: 0.3525417\ttotal: 1m 23s\tremaining: 5m 58s\n",
      "95:\tlearn: 0.3517919\ttotal: 1m 24s\tremaining: 5m 56s\n",
      "96:\tlearn: 0.3507138\ttotal: 1m 25s\tremaining: 5m 55s\n",
      "97:\tlearn: 0.3499666\ttotal: 1m 26s\tremaining: 5m 54s\n",
      "98:\tlearn: 0.3486947\ttotal: 1m 27s\tremaining: 5m 53s\n",
      "99:\tlearn: 0.3474100\ttotal: 1m 28s\tremaining: 5m 52s\n",
      "100:\tlearn: 0.3461467\ttotal: 1m 29s\tremaining: 5m 51s\n",
      "101:\tlearn: 0.3453941\ttotal: 1m 29s\tremaining: 5m 50s\n",
      "102:\tlearn: 0.3445264\ttotal: 1m 30s\tremaining: 5m 49s\n",
      "103:\tlearn: 0.3436018\ttotal: 1m 31s\tremaining: 5m 48s\n",
      "104:\tlearn: 0.3428605\ttotal: 1m 32s\tremaining: 5m 47s\n",
      "105:\tlearn: 0.3420533\ttotal: 1m 33s\tremaining: 5m 46s\n",
      "106:\tlearn: 0.3412190\ttotal: 1m 34s\tremaining: 5m 45s\n",
      "107:\tlearn: 0.3401959\ttotal: 1m 35s\tremaining: 5m 44s\n",
      "108:\tlearn: 0.3395358\ttotal: 1m 35s\tremaining: 5m 43s\n",
      "109:\tlearn: 0.3387655\ttotal: 1m 36s\tremaining: 5m 42s\n",
      "110:\tlearn: 0.3380566\ttotal: 1m 37s\tremaining: 5m 42s\n",
      "111:\tlearn: 0.3372683\ttotal: 1m 38s\tremaining: 5m 41s\n",
      "112:\tlearn: 0.3360103\ttotal: 1m 39s\tremaining: 5m 40s\n",
      "113:\tlearn: 0.3349755\ttotal: 1m 40s\tremaining: 5m 39s\n",
      "114:\tlearn: 0.3342096\ttotal: 1m 41s\tremaining: 5m 38s\n",
      "115:\tlearn: 0.3335735\ttotal: 1m 41s\tremaining: 5m 37s\n",
      "116:\tlearn: 0.3327383\ttotal: 1m 42s\tremaining: 5m 36s\n",
      "117:\tlearn: 0.3317971\ttotal: 1m 43s\tremaining: 5m 35s\n",
      "118:\tlearn: 0.3309075\ttotal: 1m 44s\tremaining: 5m 34s\n",
      "119:\tlearn: 0.3300425\ttotal: 1m 45s\tremaining: 5m 33s\n",
      "120:\tlearn: 0.3293361\ttotal: 1m 46s\tremaining: 5m 32s\n",
      "121:\tlearn: 0.3287225\ttotal: 1m 47s\tremaining: 5m 31s\n",
      "122:\tlearn: 0.3279120\ttotal: 1m 47s\tremaining: 5m 30s\n",
      "123:\tlearn: 0.3264274\ttotal: 1m 48s\tremaining: 5m 29s\n",
      "124:\tlearn: 0.3256873\ttotal: 1m 49s\tremaining: 5m 28s\n",
      "125:\tlearn: 0.3250748\ttotal: 1m 50s\tremaining: 5m 27s\n",
      "126:\tlearn: 0.3243453\ttotal: 1m 51s\tremaining: 5m 26s\n",
      "127:\tlearn: 0.3237562\ttotal: 1m 52s\tremaining: 5m 25s\n",
      "128:\tlearn: 0.3229401\ttotal: 1m 52s\tremaining: 5m 24s\n",
      "129:\tlearn: 0.3220425\ttotal: 1m 53s\tremaining: 5m 23s\n",
      "130:\tlearn: 0.3214118\ttotal: 1m 54s\tremaining: 5m 22s\n",
      "131:\tlearn: 0.3207854\ttotal: 1m 55s\tremaining: 5m 22s\n",
      "132:\tlearn: 0.3202021\ttotal: 1m 56s\tremaining: 5m 21s\n",
      "133:\tlearn: 0.3194995\ttotal: 1m 57s\tremaining: 5m 20s\n",
      "134:\tlearn: 0.3189418\ttotal: 1m 58s\tremaining: 5m 19s\n",
      "135:\tlearn: 0.3183207\ttotal: 1m 58s\tremaining: 5m 18s\n",
      "136:\tlearn: 0.3176441\ttotal: 1m 59s\tremaining: 5m 17s\n",
      "137:\tlearn: 0.3169422\ttotal: 2m\tremaining: 5m 16s\n",
      "138:\tlearn: 0.3163332\ttotal: 2m 1s\tremaining: 5m 15s\n",
      "139:\tlearn: 0.3156899\ttotal: 2m 2s\tremaining: 5m 14s\n",
      "140:\tlearn: 0.3150047\ttotal: 2m 3s\tremaining: 5m 13s\n",
      "141:\tlearn: 0.3143486\ttotal: 2m 3s\tremaining: 5m 12s\n",
      "142:\tlearn: 0.3135307\ttotal: 2m 4s\tremaining: 5m 11s\n",
      "143:\tlearn: 0.3125336\ttotal: 2m 5s\tremaining: 5m 10s\n",
      "144:\tlearn: 0.3120174\ttotal: 2m 6s\tremaining: 5m 9s\n",
      "145:\tlearn: 0.3113355\ttotal: 2m 7s\tremaining: 5m 8s\n",
      "146:\tlearn: 0.3103779\ttotal: 2m 8s\tremaining: 5m 7s\n",
      "147:\tlearn: 0.3098881\ttotal: 2m 9s\tremaining: 5m 6s\n",
      "148:\tlearn: 0.3093546\ttotal: 2m 9s\tremaining: 5m 5s\n",
      "149:\tlearn: 0.3083962\ttotal: 2m 10s\tremaining: 5m 5s\n",
      "150:\tlearn: 0.3078958\ttotal: 2m 11s\tremaining: 5m 4s\n",
      "151:\tlearn: 0.3074226\ttotal: 2m 12s\tremaining: 5m 3s\n",
      "152:\tlearn: 0.3066389\ttotal: 2m 13s\tremaining: 5m 2s\n",
      "153:\tlearn: 0.3059789\ttotal: 2m 14s\tremaining: 5m 1s\n",
      "154:\tlearn: 0.3054405\ttotal: 2m 14s\tremaining: 5m\n",
      "155:\tlearn: 0.3048249\ttotal: 2m 15s\tremaining: 4m 59s\n",
      "156:\tlearn: 0.3042927\ttotal: 2m 16s\tremaining: 4m 58s\n",
      "157:\tlearn: 0.3037203\ttotal: 2m 17s\tremaining: 4m 57s\n",
      "158:\tlearn: 0.3032370\ttotal: 2m 18s\tremaining: 4m 56s\n",
      "159:\tlearn: 0.3027706\ttotal: 2m 19s\tremaining: 4m 55s\n",
      "160:\tlearn: 0.3022661\ttotal: 2m 20s\tremaining: 4m 55s\n",
      "161:\tlearn: 0.3015703\ttotal: 2m 21s\tremaining: 4m 55s\n",
      "162:\tlearn: 0.3010062\ttotal: 2m 22s\tremaining: 4m 54s\n",
      "163:\tlearn: 0.3003312\ttotal: 2m 23s\tremaining: 4m 53s\n",
      "164:\tlearn: 0.2998426\ttotal: 2m 24s\tremaining: 4m 53s\n",
      "165:\tlearn: 0.2983769\ttotal: 2m 25s\tremaining: 4m 52s\n",
      "166:\tlearn: 0.2979717\ttotal: 2m 26s\tremaining: 4m 52s\n",
      "167:\tlearn: 0.2972478\ttotal: 2m 27s\tremaining: 4m 51s\n",
      "168:\tlearn: 0.2966751\ttotal: 2m 28s\tremaining: 4m 50s\n",
      "169:\tlearn: 0.2961783\ttotal: 2m 29s\tremaining: 4m 50s\n",
      "170:\tlearn: 0.2957293\ttotal: 2m 30s\tremaining: 4m 49s\n",
      "171:\tlearn: 0.2952216\ttotal: 2m 31s\tremaining: 4m 48s\n",
      "172:\tlearn: 0.2948093\ttotal: 2m 32s\tremaining: 4m 47s\n",
      "173:\tlearn: 0.2942974\ttotal: 2m 33s\tremaining: 4m 46s\n",
      "174:\tlearn: 0.2937183\ttotal: 2m 34s\tremaining: 4m 46s\n",
      "175:\tlearn: 0.2931599\ttotal: 2m 35s\tremaining: 4m 45s\n",
      "176:\tlearn: 0.2927934\ttotal: 2m 35s\tremaining: 4m 44s\n",
      "177:\tlearn: 0.2921689\ttotal: 2m 36s\tremaining: 4m 43s\n",
      "178:\tlearn: 0.2917813\ttotal: 2m 37s\tremaining: 4m 42s\n",
      "179:\tlearn: 0.2913291\ttotal: 2m 38s\tremaining: 4m 41s\n",
      "180:\tlearn: 0.2910034\ttotal: 2m 39s\tremaining: 4m 40s\n",
      "181:\tlearn: 0.2905097\ttotal: 2m 40s\tremaining: 4m 40s\n",
      "182:\tlearn: 0.2901102\ttotal: 2m 41s\tremaining: 4m 39s\n",
      "183:\tlearn: 0.2897376\ttotal: 2m 42s\tremaining: 4m 38s\n",
      "184:\tlearn: 0.2892333\ttotal: 2m 43s\tremaining: 4m 37s\n",
      "185:\tlearn: 0.2887827\ttotal: 2m 44s\tremaining: 4m 37s\n",
      "186:\tlearn: 0.2883926\ttotal: 2m 45s\tremaining: 4m 37s\n",
      "187:\tlearn: 0.2878993\ttotal: 2m 46s\tremaining: 4m 36s\n",
      "188:\tlearn: 0.2873569\ttotal: 2m 47s\tremaining: 4m 36s\n",
      "189:\tlearn: 0.2870117\ttotal: 2m 48s\tremaining: 4m 35s\n",
      "190:\tlearn: 0.2865745\ttotal: 2m 49s\tremaining: 4m 34s\n",
      "191:\tlearn: 0.2862608\ttotal: 2m 50s\tremaining: 4m 33s\n",
      "192:\tlearn: 0.2857679\ttotal: 2m 51s\tremaining: 4m 32s\n",
      "193:\tlearn: 0.2853445\ttotal: 2m 52s\tremaining: 4m 32s\n",
      "194:\tlearn: 0.2846181\ttotal: 2m 53s\tremaining: 4m 31s\n",
      "195:\tlearn: 0.2841687\ttotal: 2m 54s\tremaining: 4m 30s\n",
      "196:\tlearn: 0.2838262\ttotal: 2m 55s\tremaining: 4m 29s\n",
      "197:\tlearn: 0.2834197\ttotal: 2m 56s\tremaining: 4m 28s\n",
      "198:\tlearn: 0.2829133\ttotal: 2m 57s\tremaining: 4m 28s\n",
      "199:\tlearn: 0.2825462\ttotal: 2m 58s\tremaining: 4m 27s\n",
      "200:\tlearn: 0.2821301\ttotal: 2m 59s\tremaining: 4m 27s\n",
      "201:\tlearn: 0.2818388\ttotal: 3m\tremaining: 4m 26s\n",
      "202:\tlearn: 0.2813879\ttotal: 3m 1s\tremaining: 4m 25s\n",
      "203:\tlearn: 0.2809835\ttotal: 3m 2s\tremaining: 4m 25s\n",
      "204:\tlearn: 0.2805737\ttotal: 3m 3s\tremaining: 4m 24s\n",
      "205:\tlearn: 0.2800946\ttotal: 3m 5s\tremaining: 4m 24s\n",
      "206:\tlearn: 0.2797902\ttotal: 3m 6s\tremaining: 4m 23s\n",
      "207:\tlearn: 0.2791707\ttotal: 3m 7s\tremaining: 4m 23s\n",
      "208:\tlearn: 0.2787331\ttotal: 3m 8s\tremaining: 4m 22s\n",
      "209:\tlearn: 0.2784015\ttotal: 3m 9s\tremaining: 4m 21s\n",
      "210:\tlearn: 0.2778818\ttotal: 3m 10s\tremaining: 4m 21s\n",
      "211:\tlearn: 0.2773850\ttotal: 3m 11s\tremaining: 4m 20s\n",
      "212:\tlearn: 0.2770546\ttotal: 3m 12s\tremaining: 4m 19s\n",
      "213:\tlearn: 0.2765730\ttotal: 3m 13s\tremaining: 4m 18s\n",
      "214:\tlearn: 0.2761868\ttotal: 3m 14s\tremaining: 4m 17s\n",
      "215:\tlearn: 0.2757522\ttotal: 3m 15s\tremaining: 4m 16s\n",
      "216:\tlearn: 0.2750891\ttotal: 3m 15s\tremaining: 4m 15s\n",
      "217:\tlearn: 0.2747511\ttotal: 3m 16s\tremaining: 4m 14s\n",
      "218:\tlearn: 0.2743996\ttotal: 3m 17s\tremaining: 4m 13s\n",
      "219:\tlearn: 0.2739255\ttotal: 3m 18s\tremaining: 4m 12s\n",
      "220:\tlearn: 0.2736103\ttotal: 3m 19s\tremaining: 4m 11s\n",
      "221:\tlearn: 0.2731992\ttotal: 3m 20s\tremaining: 4m 10s\n",
      "222:\tlearn: 0.2727110\ttotal: 3m 20s\tremaining: 4m 9s\n",
      "223:\tlearn: 0.2723571\ttotal: 3m 21s\tremaining: 4m 8s\n",
      "224:\tlearn: 0.2715650\ttotal: 3m 22s\tremaining: 4m 7s\n",
      "225:\tlearn: 0.2713233\ttotal: 3m 23s\tremaining: 4m 6s\n",
      "226:\tlearn: 0.2709886\ttotal: 3m 24s\tremaining: 4m 5s\n",
      "227:\tlearn: 0.2706078\ttotal: 3m 25s\tremaining: 4m 4s\n",
      "228:\tlearn: 0.2702548\ttotal: 3m 26s\tremaining: 4m 4s\n",
      "229:\tlearn: 0.2698914\ttotal: 3m 27s\tremaining: 4m 3s\n",
      "230:\tlearn: 0.2695445\ttotal: 3m 28s\tremaining: 4m 2s\n",
      "231:\tlearn: 0.2691357\ttotal: 3m 29s\tremaining: 4m 1s\n",
      "232:\tlearn: 0.2685188\ttotal: 3m 30s\tremaining: 4m 1s\n",
      "233:\tlearn: 0.2679754\ttotal: 3m 31s\tremaining: 4m\n",
      "234:\tlearn: 0.2677242\ttotal: 3m 32s\tremaining: 3m 59s\n",
      "235:\tlearn: 0.2672830\ttotal: 3m 33s\tremaining: 3m 58s\n",
      "236:\tlearn: 0.2669465\ttotal: 3m 34s\tremaining: 3m 57s\n",
      "237:\tlearn: 0.2666185\ttotal: 3m 34s\tremaining: 3m 56s\n",
      "238:\tlearn: 0.2662127\ttotal: 3m 35s\tremaining: 3m 55s\n",
      "239:\tlearn: 0.2658371\ttotal: 3m 36s\tremaining: 3m 54s\n",
      "240:\tlearn: 0.2654801\ttotal: 3m 37s\tremaining: 3m 53s\n",
      "241:\tlearn: 0.2652507\ttotal: 3m 38s\tremaining: 3m 52s\n",
      "242:\tlearn: 0.2648013\ttotal: 3m 38s\tremaining: 3m 51s\n",
      "243:\tlearn: 0.2644407\ttotal: 3m 39s\tremaining: 3m 50s\n",
      "244:\tlearn: 0.2640548\ttotal: 3m 40s\tremaining: 3m 49s\n",
      "245:\tlearn: 0.2636070\ttotal: 3m 41s\tremaining: 3m 48s\n",
      "246:\tlearn: 0.2633659\ttotal: 3m 42s\tremaining: 3m 47s\n",
      "247:\tlearn: 0.2628948\ttotal: 3m 43s\tremaining: 3m 46s\n",
      "248:\tlearn: 0.2625386\ttotal: 3m 43s\tremaining: 3m 45s\n",
      "249:\tlearn: 0.2621413\ttotal: 3m 44s\tremaining: 3m 44s\n",
      "250:\tlearn: 0.2617727\ttotal: 3m 45s\tremaining: 3m 43s\n",
      "251:\tlearn: 0.2615652\ttotal: 3m 46s\tremaining: 3m 42s\n",
      "252:\tlearn: 0.2612921\ttotal: 3m 47s\tremaining: 3m 41s\n",
      "253:\tlearn: 0.2609046\ttotal: 3m 48s\tremaining: 3m 41s\n",
      "254:\tlearn: 0.2606637\ttotal: 3m 49s\tremaining: 3m 40s\n",
      "255:\tlearn: 0.2602357\ttotal: 3m 49s\tremaining: 3m 39s\n",
      "256:\tlearn: 0.2598965\ttotal: 3m 50s\tremaining: 3m 38s\n",
      "257:\tlearn: 0.2595339\ttotal: 3m 51s\tremaining: 3m 37s\n",
      "258:\tlearn: 0.2593146\ttotal: 3m 52s\tremaining: 3m 36s\n",
      "259:\tlearn: 0.2591353\ttotal: 3m 53s\tremaining: 3m 35s\n",
      "260:\tlearn: 0.2588053\ttotal: 3m 54s\tremaining: 3m 34s\n",
      "261:\tlearn: 0.2583979\ttotal: 3m 55s\tremaining: 3m 33s\n",
      "262:\tlearn: 0.2581657\ttotal: 3m 56s\tremaining: 3m 32s\n",
      "263:\tlearn: 0.2576956\ttotal: 3m 56s\tremaining: 3m 31s\n",
      "264:\tlearn: 0.2574993\ttotal: 3m 57s\tremaining: 3m 30s\n",
      "265:\tlearn: 0.2572293\ttotal: 3m 58s\tremaining: 3m 29s\n",
      "266:\tlearn: 0.2568919\ttotal: 3m 59s\tremaining: 3m 28s\n",
      "267:\tlearn: 0.2565990\ttotal: 4m\tremaining: 3m 27s\n",
      "268:\tlearn: 0.2562638\ttotal: 4m\tremaining: 3m 26s\n",
      "269:\tlearn: 0.2558613\ttotal: 4m 1s\tremaining: 3m 25s\n",
      "270:\tlearn: 0.2555888\ttotal: 4m 2s\tremaining: 3m 25s\n",
      "271:\tlearn: 0.2553728\ttotal: 4m 3s\tremaining: 3m 24s\n",
      "272:\tlearn: 0.2550983\ttotal: 4m 4s\tremaining: 3m 23s\n",
      "273:\tlearn: 0.2547461\ttotal: 4m 5s\tremaining: 3m 22s\n",
      "274:\tlearn: 0.2542513\ttotal: 4m 5s\tremaining: 3m 21s\n",
      "275:\tlearn: 0.2540909\ttotal: 4m 6s\tremaining: 3m 20s\n",
      "276:\tlearn: 0.2538504\ttotal: 4m 7s\tremaining: 3m 19s\n",
      "277:\tlearn: 0.2536538\ttotal: 4m 8s\tremaining: 3m 18s\n",
      "278:\tlearn: 0.2533594\ttotal: 4m 9s\tremaining: 3m 17s\n",
      "279:\tlearn: 0.2529495\ttotal: 4m 10s\tremaining: 3m 16s\n",
      "280:\tlearn: 0.2526375\ttotal: 4m 10s\tremaining: 3m 15s\n",
      "281:\tlearn: 0.2523480\ttotal: 4m 11s\tremaining: 3m 14s\n",
      "282:\tlearn: 0.2520014\ttotal: 4m 12s\tremaining: 3m 13s\n",
      "283:\tlearn: 0.2517432\ttotal: 4m 13s\tremaining: 3m 12s\n",
      "284:\tlearn: 0.2512768\ttotal: 4m 14s\tremaining: 3m 11s\n",
      "285:\tlearn: 0.2510852\ttotal: 4m 15s\tremaining: 3m 10s\n",
      "286:\tlearn: 0.2509327\ttotal: 4m 15s\tremaining: 3m 9s\n",
      "287:\tlearn: 0.2505529\ttotal: 4m 16s\tremaining: 3m 8s\n",
      "288:\tlearn: 0.2501912\ttotal: 4m 17s\tremaining: 3m 8s\n",
      "289:\tlearn: 0.2499037\ttotal: 4m 18s\tremaining: 3m 7s\n",
      "290:\tlearn: 0.2496910\ttotal: 4m 19s\tremaining: 3m 6s\n",
      "291:\tlearn: 0.2493794\ttotal: 4m 19s\tremaining: 3m 5s\n",
      "292:\tlearn: 0.2490518\ttotal: 4m 20s\tremaining: 3m 4s\n",
      "293:\tlearn: 0.2486462\ttotal: 4m 21s\tremaining: 3m 3s\n",
      "294:\tlearn: 0.2484511\ttotal: 4m 22s\tremaining: 3m 2s\n",
      "295:\tlearn: 0.2481002\ttotal: 4m 23s\tremaining: 3m 1s\n",
      "296:\tlearn: 0.2478263\ttotal: 4m 24s\tremaining: 3m\n",
      "297:\tlearn: 0.2474812\ttotal: 4m 24s\tremaining: 2m 59s\n",
      "298:\tlearn: 0.2471457\ttotal: 4m 25s\tremaining: 2m 58s\n",
      "299:\tlearn: 0.2468832\ttotal: 4m 26s\tremaining: 2m 57s\n",
      "300:\tlearn: 0.2465964\ttotal: 4m 27s\tremaining: 2m 56s\n",
      "301:\tlearn: 0.2462789\ttotal: 4m 28s\tremaining: 2m 55s\n",
      "302:\tlearn: 0.2460909\ttotal: 4m 29s\tremaining: 2m 54s\n",
      "303:\tlearn: 0.2459515\ttotal: 4m 29s\tremaining: 2m 53s\n",
      "304:\tlearn: 0.2456880\ttotal: 4m 30s\tremaining: 2m 53s\n",
      "305:\tlearn: 0.2453741\ttotal: 4m 31s\tremaining: 2m 52s\n",
      "306:\tlearn: 0.2450534\ttotal: 4m 32s\tremaining: 2m 51s\n",
      "307:\tlearn: 0.2448316\ttotal: 4m 33s\tremaining: 2m 50s\n",
      "308:\tlearn: 0.2445257\ttotal: 4m 34s\tremaining: 2m 49s\n",
      "309:\tlearn: 0.2442617\ttotal: 4m 34s\tremaining: 2m 48s\n",
      "310:\tlearn: 0.2438957\ttotal: 4m 35s\tremaining: 2m 47s\n",
      "311:\tlearn: 0.2435738\ttotal: 4m 36s\tremaining: 2m 46s\n",
      "312:\tlearn: 0.2433355\ttotal: 4m 37s\tremaining: 2m 45s\n",
      "313:\tlearn: 0.2431602\ttotal: 4m 38s\tremaining: 2m 44s\n",
      "314:\tlearn: 0.2428470\ttotal: 4m 38s\tremaining: 2m 43s\n",
      "315:\tlearn: 0.2425238\ttotal: 4m 39s\tremaining: 2m 42s\n",
      "316:\tlearn: 0.2421814\ttotal: 4m 40s\tremaining: 2m 41s\n",
      "317:\tlearn: 0.2419872\ttotal: 4m 41s\tremaining: 2m 41s\n",
      "318:\tlearn: 0.2416628\ttotal: 4m 42s\tremaining: 2m 40s\n",
      "319:\tlearn: 0.2413792\ttotal: 4m 43s\tremaining: 2m 39s\n",
      "320:\tlearn: 0.2411718\ttotal: 4m 44s\tremaining: 2m 38s\n",
      "321:\tlearn: 0.2409193\ttotal: 4m 44s\tremaining: 2m 37s\n",
      "322:\tlearn: 0.2406175\ttotal: 4m 45s\tremaining: 2m 36s\n",
      "323:\tlearn: 0.2403459\ttotal: 4m 46s\tremaining: 2m 35s\n",
      "324:\tlearn: 0.2402124\ttotal: 4m 47s\tremaining: 2m 34s\n",
      "325:\tlearn: 0.2399412\ttotal: 4m 48s\tremaining: 2m 33s\n",
      "326:\tlearn: 0.2397642\ttotal: 4m 49s\tremaining: 2m 32s\n",
      "327:\tlearn: 0.2393181\ttotal: 4m 49s\tremaining: 2m 32s\n",
      "328:\tlearn: 0.2390036\ttotal: 4m 50s\tremaining: 2m 31s\n",
      "329:\tlearn: 0.2388415\ttotal: 4m 51s\tremaining: 2m 30s\n",
      "330:\tlearn: 0.2387108\ttotal: 4m 52s\tremaining: 2m 29s\n",
      "331:\tlearn: 0.2385543\ttotal: 4m 53s\tremaining: 2m 28s\n",
      "332:\tlearn: 0.2382714\ttotal: 4m 54s\tremaining: 2m 27s\n",
      "333:\tlearn: 0.2379742\ttotal: 4m 54s\tremaining: 2m 26s\n",
      "334:\tlearn: 0.2377554\ttotal: 4m 55s\tremaining: 2m 25s\n",
      "335:\tlearn: 0.2374949\ttotal: 4m 56s\tremaining: 2m 24s\n",
      "336:\tlearn: 0.2372404\ttotal: 4m 57s\tremaining: 2m 23s\n",
      "337:\tlearn: 0.2366128\ttotal: 4m 58s\tremaining: 2m 22s\n",
      "338:\tlearn: 0.2363405\ttotal: 4m 58s\tremaining: 2m 22s\n",
      "339:\tlearn: 0.2361427\ttotal: 4m 59s\tremaining: 2m 21s\n",
      "340:\tlearn: 0.2358185\ttotal: 5m\tremaining: 2m 20s\n",
      "341:\tlearn: 0.2355712\ttotal: 5m 1s\tremaining: 2m 19s\n",
      "342:\tlearn: 0.2352220\ttotal: 5m 2s\tremaining: 2m 18s\n",
      "343:\tlearn: 0.2349453\ttotal: 5m 3s\tremaining: 2m 17s\n",
      "344:\tlearn: 0.2346368\ttotal: 5m 3s\tremaining: 2m 16s\n",
      "345:\tlearn: 0.2344672\ttotal: 5m 4s\tremaining: 2m 15s\n",
      "346:\tlearn: 0.2337354\ttotal: 5m 5s\tremaining: 2m 14s\n",
      "347:\tlearn: 0.2336093\ttotal: 5m 6s\tremaining: 2m 13s\n",
      "348:\tlearn: 0.2331786\ttotal: 5m 7s\tremaining: 2m 12s\n",
      "349:\tlearn: 0.2330166\ttotal: 5m 8s\tremaining: 2m 12s\n",
      "350:\tlearn: 0.2327306\ttotal: 5m 8s\tremaining: 2m 11s\n",
      "351:\tlearn: 0.2324891\ttotal: 5m 9s\tremaining: 2m 10s\n",
      "352:\tlearn: 0.2323673\ttotal: 5m 10s\tremaining: 2m 9s\n",
      "353:\tlearn: 0.2320823\ttotal: 5m 11s\tremaining: 2m 8s\n",
      "354:\tlearn: 0.2319169\ttotal: 5m 12s\tremaining: 2m 7s\n",
      "355:\tlearn: 0.2316999\ttotal: 5m 12s\tremaining: 2m 6s\n",
      "356:\tlearn: 0.2315782\ttotal: 5m 13s\tremaining: 2m 5s\n",
      "357:\tlearn: 0.2312925\ttotal: 5m 14s\tremaining: 2m 4s\n",
      "358:\tlearn: 0.2310863\ttotal: 5m 15s\tremaining: 2m 3s\n",
      "359:\tlearn: 0.2309161\ttotal: 5m 16s\tremaining: 2m 2s\n",
      "360:\tlearn: 0.2306322\ttotal: 5m 17s\tremaining: 2m 2s\n",
      "361:\tlearn: 0.2304605\ttotal: 5m 17s\tremaining: 2m 1s\n",
      "362:\tlearn: 0.2301232\ttotal: 5m 18s\tremaining: 2m\n",
      "363:\tlearn: 0.2300041\ttotal: 5m 19s\tremaining: 1m 59s\n",
      "364:\tlearn: 0.2297336\ttotal: 5m 20s\tremaining: 1m 58s\n",
      "365:\tlearn: 0.2294689\ttotal: 5m 21s\tremaining: 1m 57s\n",
      "366:\tlearn: 0.2292457\ttotal: 5m 22s\tremaining: 1m 56s\n",
      "367:\tlearn: 0.2289548\ttotal: 5m 22s\tremaining: 1m 55s\n",
      "368:\tlearn: 0.2286788\ttotal: 5m 23s\tremaining: 1m 54s\n",
      "369:\tlearn: 0.2284722\ttotal: 5m 24s\tremaining: 1m 54s\n",
      "370:\tlearn: 0.2281637\ttotal: 5m 25s\tremaining: 1m 53s\n",
      "371:\tlearn: 0.2278989\ttotal: 5m 26s\tremaining: 1m 52s\n",
      "372:\tlearn: 0.2277825\ttotal: 5m 26s\tremaining: 1m 51s\n",
      "373:\tlearn: 0.2276112\ttotal: 5m 27s\tremaining: 1m 50s\n",
      "374:\tlearn: 0.2273275\ttotal: 5m 28s\tremaining: 1m 49s\n",
      "375:\tlearn: 0.2270359\ttotal: 5m 29s\tremaining: 1m 48s\n",
      "376:\tlearn: 0.2268915\ttotal: 5m 30s\tremaining: 1m 47s\n",
      "377:\tlearn: 0.2266612\ttotal: 5m 31s\tremaining: 1m 46s\n",
      "378:\tlearn: 0.2264853\ttotal: 5m 31s\tremaining: 1m 45s\n",
      "379:\tlearn: 0.2261643\ttotal: 5m 32s\tremaining: 1m 45s\n",
      "380:\tlearn: 0.2259330\ttotal: 5m 33s\tremaining: 1m 44s\n",
      "381:\tlearn: 0.2256780\ttotal: 5m 34s\tremaining: 1m 43s\n",
      "382:\tlearn: 0.2255642\ttotal: 5m 35s\tremaining: 1m 42s\n",
      "383:\tlearn: 0.2253503\ttotal: 5m 36s\tremaining: 1m 41s\n",
      "384:\tlearn: 0.2251923\ttotal: 5m 36s\tremaining: 1m 40s\n",
      "385:\tlearn: 0.2250423\ttotal: 5m 37s\tremaining: 1m 39s\n",
      "386:\tlearn: 0.2248191\ttotal: 5m 38s\tremaining: 1m 38s\n",
      "387:\tlearn: 0.2244101\ttotal: 5m 39s\tremaining: 1m 37s\n",
      "388:\tlearn: 0.2241701\ttotal: 5m 40s\tremaining: 1m 37s\n",
      "389:\tlearn: 0.2238860\ttotal: 5m 41s\tremaining: 1m 36s\n",
      "390:\tlearn: 0.2237746\ttotal: 5m 41s\tremaining: 1m 35s\n",
      "391:\tlearn: 0.2235480\ttotal: 5m 42s\tremaining: 1m 34s\n",
      "392:\tlearn: 0.2234053\ttotal: 5m 43s\tremaining: 1m 33s\n",
      "393:\tlearn: 0.2232970\ttotal: 5m 44s\tremaining: 1m 32s\n",
      "394:\tlearn: 0.2230418\ttotal: 5m 45s\tremaining: 1m 31s\n",
      "395:\tlearn: 0.2228773\ttotal: 5m 46s\tremaining: 1m 30s\n",
      "396:\tlearn: 0.2226078\ttotal: 5m 46s\tremaining: 1m 30s\n",
      "397:\tlearn: 0.2224668\ttotal: 5m 47s\tremaining: 1m 29s\n",
      "398:\tlearn: 0.2223583\ttotal: 5m 48s\tremaining: 1m 28s\n",
      "399:\tlearn: 0.2221157\ttotal: 5m 49s\tremaining: 1m 27s\n",
      "400:\tlearn: 0.2219683\ttotal: 5m 50s\tremaining: 1m 26s\n",
      "401:\tlearn: 0.2216330\ttotal: 5m 51s\tremaining: 1m 25s\n",
      "402:\tlearn: 0.2214983\ttotal: 5m 52s\tremaining: 1m 24s\n",
      "403:\tlearn: 0.2212911\ttotal: 5m 52s\tremaining: 1m 23s\n",
      "404:\tlearn: 0.2210688\ttotal: 5m 53s\tremaining: 1m 22s\n",
      "405:\tlearn: 0.2209624\ttotal: 5m 54s\tremaining: 1m 22s\n",
      "406:\tlearn: 0.2207419\ttotal: 5m 55s\tremaining: 1m 21s\n",
      "407:\tlearn: 0.2205833\ttotal: 5m 56s\tremaining: 1m 20s\n",
      "408:\tlearn: 0.2203567\ttotal: 5m 57s\tremaining: 1m 19s\n",
      "409:\tlearn: 0.2200174\ttotal: 5m 58s\tremaining: 1m 18s\n",
      "410:\tlearn: 0.2198603\ttotal: 5m 59s\tremaining: 1m 17s\n",
      "411:\tlearn: 0.2197564\ttotal: 6m\tremaining: 1m 16s\n",
      "412:\tlearn: 0.2195499\ttotal: 6m 1s\tremaining: 1m 16s\n",
      "413:\tlearn: 0.2194194\ttotal: 6m 2s\tremaining: 1m 15s\n",
      "414:\tlearn: 0.2191587\ttotal: 6m 3s\tremaining: 1m 14s\n",
      "415:\tlearn: 0.2189815\ttotal: 6m 3s\tremaining: 1m 13s\n",
      "416:\tlearn: 0.2187625\ttotal: 6m 4s\tremaining: 1m 12s\n",
      "417:\tlearn: 0.2186598\ttotal: 6m 5s\tremaining: 1m 11s\n",
      "418:\tlearn: 0.2185599\ttotal: 6m 6s\tremaining: 1m 10s\n",
      "419:\tlearn: 0.2183832\ttotal: 6m 7s\tremaining: 1m 9s\n",
      "420:\tlearn: 0.2180258\ttotal: 6m 8s\tremaining: 1m 9s\n",
      "421:\tlearn: 0.2178190\ttotal: 6m 9s\tremaining: 1m 8s\n",
      "422:\tlearn: 0.2170725\ttotal: 6m 9s\tremaining: 1m 7s\n",
      "423:\tlearn: 0.2168007\ttotal: 6m 10s\tremaining: 1m 6s\n",
      "424:\tlearn: 0.2165849\ttotal: 6m 11s\tremaining: 1m 5s\n",
      "425:\tlearn: 0.2163576\ttotal: 6m 12s\tremaining: 1m 4s\n",
      "426:\tlearn: 0.2161022\ttotal: 6m 13s\tremaining: 1m 3s\n",
      "427:\tlearn: 0.2157956\ttotal: 6m 14s\tremaining: 1m 2s\n",
      "428:\tlearn: 0.2154933\ttotal: 6m 14s\tremaining: 1m 2s\n",
      "429:\tlearn: 0.2153208\ttotal: 6m 15s\tremaining: 1m 1s\n",
      "430:\tlearn: 0.2150667\ttotal: 6m 16s\tremaining: 1m\n",
      "431:\tlearn: 0.2149676\ttotal: 6m 17s\tremaining: 59.4s\n",
      "432:\tlearn: 0.2147751\ttotal: 6m 18s\tremaining: 58.5s\n",
      "433:\tlearn: 0.2145163\ttotal: 6m 18s\tremaining: 57.6s\n",
      "434:\tlearn: 0.2142903\ttotal: 6m 19s\tremaining: 56.7s\n",
      "435:\tlearn: 0.2141383\ttotal: 6m 20s\tremaining: 55.9s\n",
      "436:\tlearn: 0.2139131\ttotal: 6m 21s\tremaining: 55s\n",
      "437:\tlearn: 0.2136391\ttotal: 6m 22s\tremaining: 54.1s\n",
      "438:\tlearn: 0.2135003\ttotal: 6m 23s\tremaining: 53.2s\n",
      "439:\tlearn: 0.2134008\ttotal: 6m 23s\tremaining: 52.3s\n",
      "440:\tlearn: 0.2133031\ttotal: 6m 24s\tremaining: 51.5s\n",
      "441:\tlearn: 0.2130451\ttotal: 6m 25s\tremaining: 50.6s\n",
      "442:\tlearn: 0.2129459\ttotal: 6m 26s\tremaining: 49.7s\n",
      "443:\tlearn: 0.2127349\ttotal: 6m 27s\tremaining: 48.8s\n",
      "444:\tlearn: 0.2125152\ttotal: 6m 27s\tremaining: 47.9s\n",
      "445:\tlearn: 0.2124186\ttotal: 6m 28s\tremaining: 47.1s\n",
      "446:\tlearn: 0.2123197\ttotal: 6m 29s\tremaining: 46.2s\n",
      "447:\tlearn: 0.2121577\ttotal: 6m 30s\tremaining: 45.3s\n",
      "448:\tlearn: 0.2120588\ttotal: 6m 31s\tremaining: 44.4s\n",
      "449:\tlearn: 0.2118618\ttotal: 6m 32s\tremaining: 43.6s\n",
      "450:\tlearn: 0.2117653\ttotal: 6m 32s\tremaining: 42.7s\n",
      "451:\tlearn: 0.2115807\ttotal: 6m 33s\tremaining: 41.8s\n",
      "452:\tlearn: 0.2114823\ttotal: 6m 34s\tremaining: 40.9s\n",
      "453:\tlearn: 0.2113835\ttotal: 6m 35s\tremaining: 40.1s\n",
      "454:\tlearn: 0.2112853\ttotal: 6m 36s\tremaining: 39.2s\n",
      "455:\tlearn: 0.2111004\ttotal: 6m 36s\tremaining: 38.3s\n",
      "456:\tlearn: 0.2108517\ttotal: 6m 37s\tremaining: 37.4s\n",
      "457:\tlearn: 0.2107438\ttotal: 6m 38s\tremaining: 36.6s\n",
      "458:\tlearn: 0.2105151\ttotal: 6m 39s\tremaining: 35.7s\n",
      "459:\tlearn: 0.2101900\ttotal: 6m 40s\tremaining: 34.8s\n",
      "460:\tlearn: 0.2099868\ttotal: 6m 41s\tremaining: 33.9s\n",
      "461:\tlearn: 0.2098886\ttotal: 6m 41s\tremaining: 33.1s\n",
      "462:\tlearn: 0.2097921\ttotal: 6m 42s\tremaining: 32.2s\n",
      "463:\tlearn: 0.2095829\ttotal: 6m 43s\tremaining: 31.3s\n",
      "464:\tlearn: 0.2094454\ttotal: 6m 44s\tremaining: 30.4s\n",
      "465:\tlearn: 0.2093498\ttotal: 6m 45s\tremaining: 29.6s\n",
      "466:\tlearn: 0.2091861\ttotal: 6m 46s\tremaining: 28.7s\n",
      "467:\tlearn: 0.2090912\ttotal: 6m 46s\tremaining: 27.8s\n",
      "468:\tlearn: 0.2089437\ttotal: 6m 47s\tremaining: 26.9s\n",
      "469:\tlearn: 0.2086643\ttotal: 6m 48s\tremaining: 26.1s\n",
      "470:\tlearn: 0.2085104\ttotal: 6m 49s\tremaining: 25.2s\n",
      "471:\tlearn: 0.2081747\ttotal: 6m 50s\tremaining: 24.3s\n",
      "472:\tlearn: 0.2080806\ttotal: 6m 51s\tremaining: 23.5s\n",
      "473:\tlearn: 0.2079648\ttotal: 6m 51s\tremaining: 22.6s\n",
      "474:\tlearn: 0.2078720\ttotal: 6m 52s\tremaining: 21.7s\n",
      "475:\tlearn: 0.2076014\ttotal: 6m 53s\tremaining: 20.9s\n",
      "476:\tlearn: 0.2073656\ttotal: 6m 54s\tremaining: 20s\n",
      "477:\tlearn: 0.2071121\ttotal: 6m 55s\tremaining: 19.1s\n",
      "478:\tlearn: 0.2069311\ttotal: 6m 55s\tremaining: 18.2s\n",
      "479:\tlearn: 0.2068075\ttotal: 6m 56s\tremaining: 17.4s\n",
      "480:\tlearn: 0.2065932\ttotal: 6m 57s\tremaining: 16.5s\n",
      "481:\tlearn: 0.2063805\ttotal: 6m 58s\tremaining: 15.6s\n",
      "482:\tlearn: 0.2062894\ttotal: 6m 59s\tremaining: 14.8s\n",
      "483:\tlearn: 0.2060897\ttotal: 7m\tremaining: 13.9s\n",
      "484:\tlearn: 0.2059100\ttotal: 7m\tremaining: 13s\n",
      "485:\tlearn: 0.2056953\ttotal: 7m 1s\tremaining: 12.1s\n",
      "486:\tlearn: 0.2056025\ttotal: 7m 2s\tremaining: 11.3s\n",
      "487:\tlearn: 0.2055111\ttotal: 7m 3s\tremaining: 10.4s\n",
      "488:\tlearn: 0.2052921\ttotal: 7m 4s\tremaining: 9.54s\n",
      "489:\tlearn: 0.2051374\ttotal: 7m 5s\tremaining: 8.67s\n",
      "490:\tlearn: 0.2049595\ttotal: 7m 5s\tremaining: 7.8s\n",
      "491:\tlearn: 0.2047327\ttotal: 7m 6s\tremaining: 6.94s\n",
      "492:\tlearn: 0.2046065\ttotal: 7m 7s\tremaining: 6.07s\n",
      "493:\tlearn: 0.2045168\ttotal: 7m 8s\tremaining: 5.2s\n",
      "494:\tlearn: 0.2043201\ttotal: 7m 9s\tremaining: 4.33s\n",
      "495:\tlearn: 0.2041682\ttotal: 7m 9s\tremaining: 3.47s\n",
      "496:\tlearn: 0.2038982\ttotal: 7m 10s\tremaining: 2.6s\n",
      "497:\tlearn: 0.2037659\ttotal: 7m 11s\tremaining: 1.73s\n",
      "498:\tlearn: 0.2036352\ttotal: 7m 12s\tremaining: 867ms\n",
      "499:\tlearn: 0.2035454\ttotal: 7m 13s\tremaining: 0us\n",
      "[CV 2/5] END auto_class_weights=Balanced, iterations=500, random_state=12345;, score=0.757 total time= 7.3min\n",
      "Learning rate set to 0.12034\n",
      "0:\tlearn: 0.6402668\ttotal: 872ms\tremaining: 7m 15s\n",
      "1:\tlearn: 0.6018272\ttotal: 1.7s\tremaining: 7m 4s\n",
      "2:\tlearn: 0.5796790\ttotal: 2.53s\tremaining: 6m 59s\n",
      "3:\tlearn: 0.5642512\ttotal: 3.5s\tremaining: 7m 14s\n",
      "4:\tlearn: 0.5501140\ttotal: 4.47s\tremaining: 7m 22s\n",
      "5:\tlearn: 0.5378710\ttotal: 5.39s\tremaining: 7m 23s\n",
      "6:\tlearn: 0.5296878\ttotal: 6.27s\tremaining: 7m 21s\n",
      "7:\tlearn: 0.5228223\ttotal: 7.15s\tremaining: 7m 19s\n",
      "8:\tlearn: 0.5150314\ttotal: 8.04s\tremaining: 7m 18s\n",
      "9:\tlearn: 0.5070813\ttotal: 8.93s\tremaining: 7m 17s\n",
      "10:\tlearn: 0.5025301\ttotal: 9.76s\tremaining: 7m 13s\n",
      "11:\tlearn: 0.4961553\ttotal: 10.6s\tremaining: 7m 10s\n",
      "12:\tlearn: 0.4915489\ttotal: 11.4s\tremaining: 7m 7s\n",
      "13:\tlearn: 0.4859591\ttotal: 12.3s\tremaining: 7m 5s\n",
      "14:\tlearn: 0.4825032\ttotal: 13.1s\tremaining: 7m 3s\n",
      "15:\tlearn: 0.4784215\ttotal: 13.9s\tremaining: 7m 1s\n",
      "16:\tlearn: 0.4739706\ttotal: 14.8s\tremaining: 7m\n",
      "17:\tlearn: 0.4695835\ttotal: 15.6s\tremaining: 6m 58s\n",
      "18:\tlearn: 0.4661680\ttotal: 16.5s\tremaining: 6m 57s\n",
      "19:\tlearn: 0.4610112\ttotal: 17.3s\tremaining: 6m 55s\n",
      "20:\tlearn: 0.4585578\ttotal: 18.1s\tremaining: 6m 53s\n",
      "21:\tlearn: 0.4548578\ttotal: 19s\tremaining: 6m 51s\n",
      "22:\tlearn: 0.4515670\ttotal: 19.8s\tremaining: 6m 50s\n",
      "23:\tlearn: 0.4493785\ttotal: 20.6s\tremaining: 6m 48s\n",
      "24:\tlearn: 0.4469036\ttotal: 21.4s\tremaining: 6m 47s\n",
      "25:\tlearn: 0.4445749\ttotal: 22.3s\tremaining: 6m 45s\n",
      "26:\tlearn: 0.4421201\ttotal: 23.1s\tremaining: 6m 44s\n",
      "27:\tlearn: 0.4396229\ttotal: 23.9s\tremaining: 6m 43s\n",
      "28:\tlearn: 0.4370708\ttotal: 24.8s\tremaining: 6m 42s\n",
      "29:\tlearn: 0.4347835\ttotal: 25.6s\tremaining: 6m 40s\n",
      "30:\tlearn: 0.4330164\ttotal: 26.4s\tremaining: 6m 39s\n",
      "31:\tlearn: 0.4312905\ttotal: 27.3s\tremaining: 6m 38s\n",
      "32:\tlearn: 0.4293980\ttotal: 28.1s\tremaining: 6m 37s\n",
      "33:\tlearn: 0.4278330\ttotal: 28.9s\tremaining: 6m 36s\n",
      "34:\tlearn: 0.4257386\ttotal: 29.8s\tremaining: 6m 36s\n",
      "35:\tlearn: 0.4240391\ttotal: 30.7s\tremaining: 6m 35s\n",
      "36:\tlearn: 0.4218588\ttotal: 31.5s\tremaining: 6m 34s\n",
      "37:\tlearn: 0.4203401\ttotal: 32.3s\tremaining: 6m 33s\n",
      "38:\tlearn: 0.4186001\ttotal: 33.2s\tremaining: 6m 32s\n",
      "39:\tlearn: 0.4162954\ttotal: 34s\tremaining: 6m 31s\n",
      "40:\tlearn: 0.4137889\ttotal: 34.8s\tremaining: 6m 30s\n",
      "41:\tlearn: 0.4105608\ttotal: 35.8s\tremaining: 6m 30s\n",
      "42:\tlearn: 0.4087064\ttotal: 36.8s\tremaining: 6m 31s\n",
      "43:\tlearn: 0.4073481\ttotal: 37.9s\tremaining: 6m 32s\n",
      "44:\tlearn: 0.4052443\ttotal: 38.8s\tremaining: 6m 32s\n",
      "45:\tlearn: 0.4039316\ttotal: 39.8s\tremaining: 6m 32s\n",
      "46:\tlearn: 0.4027068\ttotal: 40.8s\tremaining: 6m 33s\n",
      "47:\tlearn: 0.4014743\ttotal: 41.8s\tremaining: 6m 33s\n",
      "48:\tlearn: 0.4002220\ttotal: 42.7s\tremaining: 6m 32s\n",
      "49:\tlearn: 0.3988730\ttotal: 43.6s\tremaining: 6m 32s\n",
      "50:\tlearn: 0.3976381\ttotal: 44.5s\tremaining: 6m 31s\n",
      "51:\tlearn: 0.3967267\ttotal: 45.3s\tremaining: 6m 30s\n",
      "52:\tlearn: 0.3952641\ttotal: 46.2s\tremaining: 6m 29s\n",
      "53:\tlearn: 0.3942347\ttotal: 47.1s\tremaining: 6m 28s\n",
      "54:\tlearn: 0.3930165\ttotal: 47.9s\tremaining: 6m 27s\n",
      "55:\tlearn: 0.3919363\ttotal: 48.8s\tremaining: 6m 27s\n",
      "56:\tlearn: 0.3905806\ttotal: 49.7s\tremaining: 6m 25s\n",
      "57:\tlearn: 0.3895129\ttotal: 50.6s\tremaining: 6m 25s\n",
      "58:\tlearn: 0.3887817\ttotal: 51.4s\tremaining: 6m 24s\n",
      "59:\tlearn: 0.3875960\ttotal: 52.2s\tremaining: 6m 22s\n",
      "60:\tlearn: 0.3862207\ttotal: 53s\tremaining: 6m 21s\n",
      "61:\tlearn: 0.3849283\ttotal: 53.9s\tremaining: 6m 20s\n",
      "62:\tlearn: 0.3840864\ttotal: 54.8s\tremaining: 6m 20s\n",
      "63:\tlearn: 0.3826475\ttotal: 55.9s\tremaining: 6m 20s\n",
      "64:\tlearn: 0.3814524\ttotal: 56.7s\tremaining: 6m 19s\n",
      "65:\tlearn: 0.3798965\ttotal: 57.6s\tremaining: 6m 18s\n",
      "66:\tlearn: 0.3788954\ttotal: 58.5s\tremaining: 6m 18s\n",
      "67:\tlearn: 0.3777132\ttotal: 59.4s\tremaining: 6m 17s\n",
      "68:\tlearn: 0.3765696\ttotal: 1m\tremaining: 6m 16s\n",
      "69:\tlearn: 0.3754607\ttotal: 1m 1s\tremaining: 6m 16s\n",
      "70:\tlearn: 0.3743302\ttotal: 1m 2s\tremaining: 6m 15s\n",
      "71:\tlearn: 0.3731424\ttotal: 1m 2s\tremaining: 6m 14s\n",
      "72:\tlearn: 0.3720492\ttotal: 1m 3s\tremaining: 6m 13s\n",
      "73:\tlearn: 0.3712174\ttotal: 1m 4s\tremaining: 6m 12s\n",
      "74:\tlearn: 0.3700959\ttotal: 1m 5s\tremaining: 6m 10s\n",
      "75:\tlearn: 0.3689101\ttotal: 1m 6s\tremaining: 6m 9s\n",
      "76:\tlearn: 0.3675555\ttotal: 1m 7s\tremaining: 6m 8s\n",
      "77:\tlearn: 0.3663372\ttotal: 1m 7s\tremaining: 6m 7s\n",
      "78:\tlearn: 0.3655659\ttotal: 1m 8s\tremaining: 6m 6s\n",
      "79:\tlearn: 0.3647852\ttotal: 1m 9s\tremaining: 6m 5s\n",
      "80:\tlearn: 0.3639479\ttotal: 1m 10s\tremaining: 6m 4s\n",
      "81:\tlearn: 0.3630963\ttotal: 1m 11s\tremaining: 6m 3s\n",
      "82:\tlearn: 0.3624299\ttotal: 1m 12s\tremaining: 6m 2s\n",
      "83:\tlearn: 0.3618166\ttotal: 1m 12s\tremaining: 6m 1s\n",
      "84:\tlearn: 0.3610543\ttotal: 1m 13s\tremaining: 6m\n",
      "85:\tlearn: 0.3605091\ttotal: 1m 14s\tremaining: 5m 59s\n",
      "86:\tlearn: 0.3590579\ttotal: 1m 15s\tremaining: 5m 57s\n",
      "87:\tlearn: 0.3582571\ttotal: 1m 16s\tremaining: 5m 56s\n",
      "88:\tlearn: 0.3575133\ttotal: 1m 17s\tremaining: 5m 55s\n",
      "89:\tlearn: 0.3568583\ttotal: 1m 17s\tremaining: 5m 54s\n",
      "90:\tlearn: 0.3559202\ttotal: 1m 18s\tremaining: 5m 53s\n",
      "91:\tlearn: 0.3550605\ttotal: 1m 19s\tremaining: 5m 52s\n",
      "92:\tlearn: 0.3541745\ttotal: 1m 20s\tremaining: 5m 51s\n",
      "93:\tlearn: 0.3531298\ttotal: 1m 21s\tremaining: 5m 50s\n",
      "94:\tlearn: 0.3522537\ttotal: 1m 22s\tremaining: 5m 49s\n",
      "95:\tlearn: 0.3513846\ttotal: 1m 22s\tremaining: 5m 48s\n",
      "96:\tlearn: 0.3506642\ttotal: 1m 23s\tremaining: 5m 48s\n",
      "97:\tlearn: 0.3496541\ttotal: 1m 24s\tremaining: 5m 46s\n",
      "98:\tlearn: 0.3474805\ttotal: 1m 25s\tremaining: 5m 45s\n",
      "99:\tlearn: 0.3463586\ttotal: 1m 26s\tremaining: 5m 45s\n",
      "100:\tlearn: 0.3454476\ttotal: 1m 27s\tremaining: 5m 44s\n",
      "101:\tlearn: 0.3447445\ttotal: 1m 27s\tremaining: 5m 42s\n",
      "102:\tlearn: 0.3438919\ttotal: 1m 28s\tremaining: 5m 41s\n",
      "103:\tlearn: 0.3431657\ttotal: 1m 29s\tremaining: 5m 41s\n",
      "104:\tlearn: 0.3421921\ttotal: 1m 30s\tremaining: 5m 40s\n",
      "105:\tlearn: 0.3414466\ttotal: 1m 31s\tremaining: 5m 39s\n",
      "106:\tlearn: 0.3406231\ttotal: 1m 32s\tremaining: 5m 38s\n",
      "107:\tlearn: 0.3395890\ttotal: 1m 32s\tremaining: 5m 37s\n",
      "108:\tlearn: 0.3388664\ttotal: 1m 33s\tremaining: 5m 36s\n",
      "109:\tlearn: 0.3381635\ttotal: 1m 34s\tremaining: 5m 35s\n",
      "110:\tlearn: 0.3373956\ttotal: 1m 35s\tremaining: 5m 34s\n",
      "111:\tlearn: 0.3362534\ttotal: 1m 36s\tremaining: 5m 33s\n",
      "112:\tlearn: 0.3355239\ttotal: 1m 37s\tremaining: 5m 32s\n",
      "113:\tlearn: 0.3346604\ttotal: 1m 37s\tremaining: 5m 31s\n",
      "114:\tlearn: 0.3338911\ttotal: 1m 38s\tremaining: 5m 30s\n",
      "115:\tlearn: 0.3326937\ttotal: 1m 39s\tremaining: 5m 29s\n",
      "116:\tlearn: 0.3320160\ttotal: 1m 40s\tremaining: 5m 28s\n",
      "117:\tlearn: 0.3309732\ttotal: 1m 41s\tremaining: 5m 27s\n",
      "118:\tlearn: 0.3302510\ttotal: 1m 42s\tremaining: 5m 26s\n",
      "119:\tlearn: 0.3292145\ttotal: 1m 42s\tremaining: 5m 25s\n",
      "120:\tlearn: 0.3283925\ttotal: 1m 43s\tremaining: 5m 24s\n",
      "121:\tlearn: 0.3276584\ttotal: 1m 44s\tremaining: 5m 23s\n",
      "122:\tlearn: 0.3269383\ttotal: 1m 45s\tremaining: 5m 22s\n",
      "123:\tlearn: 0.3263293\ttotal: 1m 46s\tremaining: 5m 21s\n",
      "124:\tlearn: 0.3256279\ttotal: 1m 47s\tremaining: 5m 21s\n",
      "125:\tlearn: 0.3246407\ttotal: 1m 47s\tremaining: 5m 20s\n",
      "126:\tlearn: 0.3240101\ttotal: 1m 48s\tremaining: 5m 19s\n",
      "127:\tlearn: 0.3234892\ttotal: 1m 49s\tremaining: 5m 18s\n",
      "128:\tlearn: 0.3227300\ttotal: 1m 50s\tremaining: 5m 17s\n",
      "129:\tlearn: 0.3221280\ttotal: 1m 51s\tremaining: 5m 16s\n",
      "130:\tlearn: 0.3207791\ttotal: 1m 51s\tremaining: 5m 15s\n",
      "131:\tlearn: 0.3201207\ttotal: 1m 52s\tremaining: 5m 14s\n",
      "132:\tlearn: 0.3195907\ttotal: 1m 53s\tremaining: 5m 13s\n",
      "133:\tlearn: 0.3190432\ttotal: 1m 54s\tremaining: 5m 12s\n",
      "134:\tlearn: 0.3183270\ttotal: 1m 55s\tremaining: 5m 11s\n",
      "135:\tlearn: 0.3177074\ttotal: 1m 56s\tremaining: 5m 10s\n",
      "136:\tlearn: 0.3170437\ttotal: 1m 56s\tremaining: 5m 9s\n",
      "137:\tlearn: 0.3162870\ttotal: 1m 57s\tremaining: 5m 9s\n",
      "138:\tlearn: 0.3154722\ttotal: 1m 58s\tremaining: 5m 8s\n",
      "139:\tlearn: 0.3148734\ttotal: 1m 59s\tremaining: 5m 7s\n",
      "140:\tlearn: 0.3143049\ttotal: 2m\tremaining: 5m 6s\n",
      "141:\tlearn: 0.3135024\ttotal: 2m 1s\tremaining: 5m 5s\n",
      "142:\tlearn: 0.3124833\ttotal: 2m 1s\tremaining: 5m 4s\n",
      "143:\tlearn: 0.3116835\ttotal: 2m 2s\tremaining: 5m 3s\n",
      "144:\tlearn: 0.3110638\ttotal: 2m 3s\tremaining: 5m 2s\n",
      "145:\tlearn: 0.3102268\ttotal: 2m 4s\tremaining: 5m 1s\n",
      "146:\tlearn: 0.3095564\ttotal: 2m 5s\tremaining: 5m\n",
      "147:\tlearn: 0.3090226\ttotal: 2m 6s\tremaining: 4m 59s\n",
      "148:\tlearn: 0.3084777\ttotal: 2m 6s\tremaining: 4m 58s\n",
      "149:\tlearn: 0.3079317\ttotal: 2m 7s\tremaining: 4m 57s\n",
      "150:\tlearn: 0.3073285\ttotal: 2m 8s\tremaining: 4m 57s\n",
      "151:\tlearn: 0.3067769\ttotal: 2m 9s\tremaining: 4m 56s\n",
      "152:\tlearn: 0.3062824\ttotal: 2m 10s\tremaining: 4m 55s\n",
      "153:\tlearn: 0.3055464\ttotal: 2m 11s\tremaining: 4m 54s\n",
      "154:\tlearn: 0.3048260\ttotal: 2m 11s\tremaining: 4m 53s\n",
      "155:\tlearn: 0.3042749\ttotal: 2m 12s\tremaining: 4m 52s\n",
      "156:\tlearn: 0.3037511\ttotal: 2m 13s\tremaining: 4m 51s\n",
      "157:\tlearn: 0.3030777\ttotal: 2m 14s\tremaining: 4m 50s\n",
      "158:\tlearn: 0.3025183\ttotal: 2m 15s\tremaining: 4m 49s\n",
      "159:\tlearn: 0.3020304\ttotal: 2m 15s\tremaining: 4m 48s\n",
      "160:\tlearn: 0.3014848\ttotal: 2m 16s\tremaining: 4m 48s\n",
      "161:\tlearn: 0.3010589\ttotal: 2m 17s\tremaining: 4m 47s\n",
      "162:\tlearn: 0.3006071\ttotal: 2m 18s\tremaining: 4m 46s\n",
      "163:\tlearn: 0.2999261\ttotal: 2m 19s\tremaining: 4m 45s\n",
      "164:\tlearn: 0.2994731\ttotal: 2m 20s\tremaining: 4m 44s\n",
      "165:\tlearn: 0.2988448\ttotal: 2m 20s\tremaining: 4m 43s\n",
      "166:\tlearn: 0.2983302\ttotal: 2m 21s\tremaining: 4m 42s\n",
      "167:\tlearn: 0.2978701\ttotal: 2m 22s\tremaining: 4m 41s\n",
      "168:\tlearn: 0.2973802\ttotal: 2m 23s\tremaining: 4m 40s\n",
      "169:\tlearn: 0.2969550\ttotal: 2m 24s\tremaining: 4m 40s\n",
      "170:\tlearn: 0.2961876\ttotal: 2m 25s\tremaining: 4m 39s\n",
      "171:\tlearn: 0.2956406\ttotal: 2m 25s\tremaining: 4m 38s\n",
      "172:\tlearn: 0.2950633\ttotal: 2m 26s\tremaining: 4m 37s\n",
      "173:\tlearn: 0.2945439\ttotal: 2m 27s\tremaining: 4m 36s\n",
      "174:\tlearn: 0.2940467\ttotal: 2m 28s\tremaining: 4m 35s\n",
      "175:\tlearn: 0.2935391\ttotal: 2m 29s\tremaining: 4m 34s\n",
      "176:\tlearn: 0.2930905\ttotal: 2m 30s\tremaining: 4m 33s\n",
      "177:\tlearn: 0.2926381\ttotal: 2m 30s\tremaining: 4m 33s\n",
      "178:\tlearn: 0.2921768\ttotal: 2m 31s\tremaining: 4m 32s\n",
      "179:\tlearn: 0.2916324\ttotal: 2m 32s\tremaining: 4m 31s\n",
      "180:\tlearn: 0.2911994\ttotal: 2m 33s\tremaining: 4m 30s\n",
      "181:\tlearn: 0.2908400\ttotal: 2m 34s\tremaining: 4m 29s\n",
      "182:\tlearn: 0.2903331\ttotal: 2m 35s\tremaining: 4m 28s\n",
      "183:\tlearn: 0.2898370\ttotal: 2m 35s\tremaining: 4m 27s\n",
      "184:\tlearn: 0.2894358\ttotal: 2m 36s\tremaining: 4m 26s\n",
      "185:\tlearn: 0.2889548\ttotal: 2m 37s\tremaining: 4m 25s\n",
      "186:\tlearn: 0.2885807\ttotal: 2m 38s\tremaining: 4m 25s\n",
      "187:\tlearn: 0.2881226\ttotal: 2m 39s\tremaining: 4m 24s\n",
      "188:\tlearn: 0.2877192\ttotal: 2m 40s\tremaining: 4m 23s\n",
      "189:\tlearn: 0.2871293\ttotal: 2m 40s\tremaining: 4m 22s\n",
      "190:\tlearn: 0.2866724\ttotal: 2m 41s\tremaining: 4m 21s\n",
      "191:\tlearn: 0.2860067\ttotal: 2m 42s\tremaining: 4m 20s\n",
      "192:\tlearn: 0.2856316\ttotal: 2m 43s\tremaining: 4m 19s\n",
      "193:\tlearn: 0.2851258\ttotal: 2m 44s\tremaining: 4m 19s\n",
      "194:\tlearn: 0.2845860\ttotal: 2m 45s\tremaining: 4m 18s\n",
      "195:\tlearn: 0.2841763\ttotal: 2m 45s\tremaining: 4m 17s\n",
      "196:\tlearn: 0.2837898\ttotal: 2m 46s\tremaining: 4m 16s\n",
      "197:\tlearn: 0.2834892\ttotal: 2m 47s\tremaining: 4m 15s\n",
      "198:\tlearn: 0.2830832\ttotal: 2m 48s\tremaining: 4m 14s\n",
      "199:\tlearn: 0.2826451\ttotal: 2m 49s\tremaining: 4m 13s\n",
      "200:\tlearn: 0.2822167\ttotal: 2m 50s\tremaining: 4m 12s\n",
      "201:\tlearn: 0.2818067\ttotal: 2m 50s\tremaining: 4m 12s\n",
      "202:\tlearn: 0.2813663\ttotal: 2m 51s\tremaining: 4m 11s\n",
      "203:\tlearn: 0.2810026\ttotal: 2m 52s\tremaining: 4m 10s\n",
      "204:\tlearn: 0.2805497\ttotal: 2m 53s\tremaining: 4m 9s\n",
      "205:\tlearn: 0.2800843\ttotal: 2m 54s\tremaining: 4m 8s\n",
      "206:\tlearn: 0.2798198\ttotal: 2m 55s\tremaining: 4m 7s\n",
      "207:\tlearn: 0.2794044\ttotal: 2m 55s\tremaining: 4m 6s\n",
      "208:\tlearn: 0.2790119\ttotal: 2m 56s\tremaining: 4m 5s\n",
      "209:\tlearn: 0.2786449\ttotal: 2m 57s\tremaining: 4m 5s\n",
      "210:\tlearn: 0.2782405\ttotal: 2m 58s\tremaining: 4m 4s\n",
      "211:\tlearn: 0.2776925\ttotal: 2m 59s\tremaining: 4m 3s\n",
      "212:\tlearn: 0.2767889\ttotal: 2m 59s\tremaining: 4m 2s\n",
      "213:\tlearn: 0.2762335\ttotal: 3m\tremaining: 4m 1s\n",
      "214:\tlearn: 0.2759384\ttotal: 3m 1s\tremaining: 4m\n",
      "215:\tlearn: 0.2746471\ttotal: 3m 2s\tremaining: 3m 59s\n",
      "216:\tlearn: 0.2743044\ttotal: 3m 3s\tremaining: 3m 58s\n",
      "217:\tlearn: 0.2738921\ttotal: 3m 4s\tremaining: 3m 58s\n",
      "218:\tlearn: 0.2733519\ttotal: 3m 4s\tremaining: 3m 57s\n",
      "219:\tlearn: 0.2729189\ttotal: 3m 5s\tremaining: 3m 56s\n",
      "220:\tlearn: 0.2724308\ttotal: 3m 6s\tremaining: 3m 55s\n",
      "221:\tlearn: 0.2720694\ttotal: 3m 7s\tremaining: 3m 54s\n",
      "222:\tlearn: 0.2716895\ttotal: 3m 8s\tremaining: 3m 53s\n",
      "223:\tlearn: 0.2714407\ttotal: 3m 9s\tremaining: 3m 52s\n",
      "224:\tlearn: 0.2710864\ttotal: 3m 9s\tremaining: 3m 52s\n",
      "225:\tlearn: 0.2706429\ttotal: 3m 10s\tremaining: 3m 51s\n",
      "226:\tlearn: 0.2702808\ttotal: 3m 11s\tremaining: 3m 50s\n",
      "227:\tlearn: 0.2700279\ttotal: 3m 12s\tremaining: 3m 49s\n",
      "228:\tlearn: 0.2696718\ttotal: 3m 13s\tremaining: 3m 48s\n",
      "229:\tlearn: 0.2686484\ttotal: 3m 13s\tremaining: 3m 47s\n",
      "230:\tlearn: 0.2681153\ttotal: 3m 14s\tremaining: 3m 46s\n",
      "231:\tlearn: 0.2676856\ttotal: 3m 15s\tremaining: 3m 46s\n",
      "232:\tlearn: 0.2672455\ttotal: 3m 16s\tremaining: 3m 45s\n",
      "233:\tlearn: 0.2669440\ttotal: 3m 17s\tremaining: 3m 44s\n",
      "234:\tlearn: 0.2666683\ttotal: 3m 18s\tremaining: 3m 43s\n",
      "235:\tlearn: 0.2662337\ttotal: 3m 18s\tremaining: 3m 42s\n",
      "236:\tlearn: 0.2657562\ttotal: 3m 19s\tremaining: 3m 41s\n",
      "237:\tlearn: 0.2653168\ttotal: 3m 20s\tremaining: 3m 40s\n",
      "238:\tlearn: 0.2649364\ttotal: 3m 21s\tremaining: 3m 39s\n",
      "239:\tlearn: 0.2646356\ttotal: 3m 22s\tremaining: 3m 39s\n",
      "240:\tlearn: 0.2642434\ttotal: 3m 23s\tremaining: 3m 38s\n",
      "241:\tlearn: 0.2638472\ttotal: 3m 23s\tremaining: 3m 37s\n",
      "242:\tlearn: 0.2635903\ttotal: 3m 24s\tremaining: 3m 36s\n",
      "243:\tlearn: 0.2632022\ttotal: 3m 25s\tremaining: 3m 35s\n",
      "244:\tlearn: 0.2628778\ttotal: 3m 26s\tremaining: 3m 34s\n",
      "245:\tlearn: 0.2625034\ttotal: 3m 27s\tremaining: 3m 33s\n",
      "246:\tlearn: 0.2621611\ttotal: 3m 28s\tremaining: 3m 33s\n",
      "247:\tlearn: 0.2617823\ttotal: 3m 28s\tremaining: 3m 32s\n",
      "248:\tlearn: 0.2613462\ttotal: 3m 29s\tremaining: 3m 31s\n",
      "249:\tlearn: 0.2608791\ttotal: 3m 30s\tremaining: 3m 30s\n",
      "250:\tlearn: 0.2605420\ttotal: 3m 31s\tremaining: 3m 29s\n",
      "251:\tlearn: 0.2602677\ttotal: 3m 32s\tremaining: 3m 28s\n",
      "252:\tlearn: 0.2600188\ttotal: 3m 33s\tremaining: 3m 28s\n",
      "253:\tlearn: 0.2596384\ttotal: 3m 33s\tremaining: 3m 27s\n",
      "254:\tlearn: 0.2594250\ttotal: 3m 34s\tremaining: 3m 26s\n",
      "255:\tlearn: 0.2590938\ttotal: 3m 35s\tremaining: 3m 25s\n",
      "256:\tlearn: 0.2588376\ttotal: 3m 36s\tremaining: 3m 24s\n",
      "257:\tlearn: 0.2585372\ttotal: 3m 37s\tremaining: 3m 23s\n",
      "258:\tlearn: 0.2583209\ttotal: 3m 38s\tremaining: 3m 22s\n",
      "259:\tlearn: 0.2581157\ttotal: 3m 38s\tremaining: 3m 21s\n",
      "260:\tlearn: 0.2576766\ttotal: 3m 39s\tremaining: 3m 21s\n",
      "261:\tlearn: 0.2575064\ttotal: 3m 40s\tremaining: 3m 20s\n",
      "262:\tlearn: 0.2571748\ttotal: 3m 41s\tremaining: 3m 19s\n",
      "263:\tlearn: 0.2568196\ttotal: 3m 42s\tremaining: 3m 18s\n",
      "264:\tlearn: 0.2564415\ttotal: 3m 42s\tremaining: 3m 17s\n",
      "265:\tlearn: 0.2561705\ttotal: 3m 43s\tremaining: 3m 16s\n",
      "266:\tlearn: 0.2559516\ttotal: 3m 44s\tremaining: 3m 15s\n",
      "267:\tlearn: 0.2556255\ttotal: 3m 45s\tremaining: 3m 15s\n",
      "268:\tlearn: 0.2550056\ttotal: 3m 46s\tremaining: 3m 14s\n",
      "269:\tlearn: 0.2545832\ttotal: 3m 47s\tremaining: 3m 13s\n",
      "270:\tlearn: 0.2543515\ttotal: 3m 47s\tremaining: 3m 12s\n",
      "271:\tlearn: 0.2534311\ttotal: 3m 48s\tremaining: 3m 11s\n",
      "272:\tlearn: 0.2530405\ttotal: 3m 49s\tremaining: 3m 10s\n",
      "273:\tlearn: 0.2527185\ttotal: 3m 50s\tremaining: 3m 10s\n",
      "274:\tlearn: 0.2525022\ttotal: 3m 51s\tremaining: 3m 9s\n",
      "275:\tlearn: 0.2521110\ttotal: 3m 52s\tremaining: 3m 8s\n",
      "276:\tlearn: 0.2518703\ttotal: 3m 53s\tremaining: 3m 7s\n",
      "277:\tlearn: 0.2515529\ttotal: 3m 53s\tremaining: 3m 6s\n",
      "278:\tlearn: 0.2511969\ttotal: 3m 54s\tremaining: 3m 5s\n",
      "279:\tlearn: 0.2508895\ttotal: 3m 55s\tremaining: 3m 5s\n",
      "280:\tlearn: 0.2504700\ttotal: 3m 56s\tremaining: 3m 4s\n",
      "281:\tlearn: 0.2502831\ttotal: 3m 57s\tremaining: 3m 3s\n",
      "282:\tlearn: 0.2500100\ttotal: 3m 58s\tremaining: 3m 2s\n",
      "283:\tlearn: 0.2496855\ttotal: 3m 58s\tremaining: 3m 1s\n",
      "284:\tlearn: 0.2493245\ttotal: 3m 59s\tremaining: 3m\n",
      "285:\tlearn: 0.2491662\ttotal: 4m\tremaining: 2m 59s\n",
      "286:\tlearn: 0.2488879\ttotal: 4m 1s\tremaining: 2m 59s\n",
      "287:\tlearn: 0.2486221\ttotal: 4m 2s\tremaining: 2m 58s\n",
      "288:\tlearn: 0.2483307\ttotal: 4m 3s\tremaining: 2m 57s\n",
      "289:\tlearn: 0.2480702\ttotal: 4m 3s\tremaining: 2m 56s\n",
      "290:\tlearn: 0.2478088\ttotal: 4m 5s\tremaining: 2m 56s\n",
      "291:\tlearn: 0.2473707\ttotal: 4m 6s\tremaining: 2m 55s\n",
      "292:\tlearn: 0.2471634\ttotal: 4m 7s\tremaining: 2m 54s\n",
      "293:\tlearn: 0.2468475\ttotal: 4m 8s\tremaining: 2m 54s\n",
      "294:\tlearn: 0.2465893\ttotal: 4m 9s\tremaining: 2m 53s\n",
      "295:\tlearn: 0.2462612\ttotal: 4m 10s\tremaining: 2m 52s\n",
      "296:\tlearn: 0.2461153\ttotal: 4m 10s\tremaining: 2m 51s\n",
      "297:\tlearn: 0.2458411\ttotal: 4m 11s\tremaining: 2m 50s\n",
      "298:\tlearn: 0.2455105\ttotal: 4m 12s\tremaining: 2m 49s\n",
      "299:\tlearn: 0.2450626\ttotal: 4m 13s\tremaining: 2m 48s\n",
      "300:\tlearn: 0.2448724\ttotal: 4m 14s\tremaining: 2m 48s\n",
      "301:\tlearn: 0.2445076\ttotal: 4m 15s\tremaining: 2m 47s\n",
      "302:\tlearn: 0.2442950\ttotal: 4m 16s\tremaining: 2m 46s\n",
      "303:\tlearn: 0.2440537\ttotal: 4m 17s\tremaining: 2m 45s\n",
      "304:\tlearn: 0.2438779\ttotal: 4m 18s\tremaining: 2m 45s\n",
      "305:\tlearn: 0.2436738\ttotal: 4m 18s\tremaining: 2m 44s\n",
      "306:\tlearn: 0.2433829\ttotal: 4m 19s\tremaining: 2m 43s\n",
      "307:\tlearn: 0.2430448\ttotal: 4m 20s\tremaining: 2m 42s\n",
      "308:\tlearn: 0.2427010\ttotal: 4m 21s\tremaining: 2m 41s\n",
      "309:\tlearn: 0.2424467\ttotal: 4m 22s\tremaining: 2m 40s\n",
      "310:\tlearn: 0.2421801\ttotal: 4m 23s\tremaining: 2m 39s\n",
      "311:\tlearn: 0.2418837\ttotal: 4m 24s\tremaining: 2m 39s\n",
      "312:\tlearn: 0.2416239\ttotal: 4m 24s\tremaining: 2m 38s\n",
      "313:\tlearn: 0.2414838\ttotal: 4m 25s\tremaining: 2m 37s\n",
      "314:\tlearn: 0.2411536\ttotal: 4m 26s\tremaining: 2m 36s\n",
      "315:\tlearn: 0.2408534\ttotal: 4m 27s\tremaining: 2m 35s\n",
      "316:\tlearn: 0.2406516\ttotal: 4m 28s\tremaining: 2m 34s\n",
      "317:\tlearn: 0.2404791\ttotal: 4m 29s\tremaining: 2m 34s\n",
      "318:\tlearn: 0.2403434\ttotal: 4m 30s\tremaining: 2m 33s\n",
      "319:\tlearn: 0.2400353\ttotal: 4m 31s\tremaining: 2m 32s\n",
      "320:\tlearn: 0.2397464\ttotal: 4m 32s\tremaining: 2m 32s\n",
      "321:\tlearn: 0.2394123\ttotal: 4m 33s\tremaining: 2m 31s\n",
      "322:\tlearn: 0.2392134\ttotal: 4m 34s\tremaining: 2m 30s\n",
      "323:\tlearn: 0.2388769\ttotal: 4m 35s\tremaining: 2m 29s\n",
      "324:\tlearn: 0.2385732\ttotal: 4m 36s\tremaining: 2m 28s\n",
      "325:\tlearn: 0.2381646\ttotal: 4m 37s\tremaining: 2m 28s\n",
      "326:\tlearn: 0.2378818\ttotal: 4m 38s\tremaining: 2m 27s\n",
      "327:\tlearn: 0.2376090\ttotal: 4m 39s\tremaining: 2m 26s\n",
      "328:\tlearn: 0.2373983\ttotal: 4m 40s\tremaining: 2m 25s\n",
      "329:\tlearn: 0.2370912\ttotal: 4m 41s\tremaining: 2m 25s\n",
      "330:\tlearn: 0.2367752\ttotal: 4m 42s\tremaining: 2m 24s\n",
      "331:\tlearn: 0.2365561\ttotal: 4m 44s\tremaining: 2m 23s\n",
      "332:\tlearn: 0.2362482\ttotal: 4m 45s\tremaining: 2m 23s\n",
      "333:\tlearn: 0.2359803\ttotal: 4m 46s\tremaining: 2m 22s\n",
      "334:\tlearn: 0.2356769\ttotal: 4m 47s\tremaining: 2m 21s\n",
      "335:\tlearn: 0.2354636\ttotal: 4m 48s\tremaining: 2m 20s\n",
      "336:\tlearn: 0.2352268\ttotal: 4m 49s\tremaining: 2m 20s\n",
      "337:\tlearn: 0.2350972\ttotal: 4m 50s\tremaining: 2m 19s\n",
      "338:\tlearn: 0.2348954\ttotal: 4m 51s\tremaining: 2m 18s\n",
      "339:\tlearn: 0.2346300\ttotal: 4m 52s\tremaining: 2m 17s\n",
      "340:\tlearn: 0.2344602\ttotal: 4m 53s\tremaining: 2m 16s\n",
      "341:\tlearn: 0.2341040\ttotal: 4m 54s\tremaining: 2m 15s\n",
      "342:\tlearn: 0.2339687\ttotal: 4m 55s\tremaining: 2m 15s\n",
      "343:\tlearn: 0.2335614\ttotal: 4m 56s\tremaining: 2m 14s\n",
      "344:\tlearn: 0.2334365\ttotal: 4m 56s\tremaining: 2m 13s\n",
      "345:\tlearn: 0.2332868\ttotal: 4m 57s\tremaining: 2m 12s\n",
      "346:\tlearn: 0.2329726\ttotal: 4m 58s\tremaining: 2m 11s\n",
      "347:\tlearn: 0.2327166\ttotal: 4m 59s\tremaining: 2m 10s\n",
      "348:\tlearn: 0.2323148\ttotal: 5m\tremaining: 2m 9s\n",
      "349:\tlearn: 0.2320787\ttotal: 5m 1s\tremaining: 2m 9s\n",
      "350:\tlearn: 0.2317830\ttotal: 5m 1s\tremaining: 2m 8s\n",
      "351:\tlearn: 0.2315006\ttotal: 5m 2s\tremaining: 2m 7s\n",
      "352:\tlearn: 0.2312713\ttotal: 5m 3s\tremaining: 2m 6s\n",
      "353:\tlearn: 0.2309538\ttotal: 5m 4s\tremaining: 2m 5s\n",
      "354:\tlearn: 0.2308032\ttotal: 5m 5s\tremaining: 2m 4s\n",
      "355:\tlearn: 0.2305854\ttotal: 5m 6s\tremaining: 2m 3s\n",
      "356:\tlearn: 0.2302915\ttotal: 5m 6s\tremaining: 2m 2s\n",
      "357:\tlearn: 0.2300980\ttotal: 5m 7s\tremaining: 2m 2s\n",
      "358:\tlearn: 0.2298390\ttotal: 5m 8s\tremaining: 2m 1s\n",
      "359:\tlearn: 0.2297166\ttotal: 5m 9s\tremaining: 2m\n",
      "360:\tlearn: 0.2295981\ttotal: 5m 10s\tremaining: 1m 59s\n",
      "361:\tlearn: 0.2293917\ttotal: 5m 10s\tremaining: 1m 58s\n",
      "362:\tlearn: 0.2290022\ttotal: 5m 11s\tremaining: 1m 57s\n",
      "363:\tlearn: 0.2287668\ttotal: 5m 12s\tremaining: 1m 56s\n",
      "364:\tlearn: 0.2285091\ttotal: 5m 13s\tremaining: 1m 56s\n",
      "365:\tlearn: 0.2283036\ttotal: 5m 14s\tremaining: 1m 55s\n",
      "366:\tlearn: 0.2281062\ttotal: 5m 15s\tremaining: 1m 54s\n",
      "367:\tlearn: 0.2279365\ttotal: 5m 16s\tremaining: 1m 53s\n",
      "368:\tlearn: 0.2276679\ttotal: 5m 17s\tremaining: 1m 52s\n",
      "369:\tlearn: 0.2275254\ttotal: 5m 18s\tremaining: 1m 51s\n",
      "370:\tlearn: 0.2273358\ttotal: 5m 19s\tremaining: 1m 51s\n",
      "371:\tlearn: 0.2270067\ttotal: 5m 20s\tremaining: 1m 50s\n",
      "372:\tlearn: 0.2266983\ttotal: 5m 21s\tremaining: 1m 49s\n",
      "373:\tlearn: 0.2265038\ttotal: 5m 21s\tremaining: 1m 48s\n",
      "374:\tlearn: 0.2263876\ttotal: 5m 22s\tremaining: 1m 47s\n",
      "375:\tlearn: 0.2261917\ttotal: 5m 23s\tremaining: 1m 46s\n",
      "376:\tlearn: 0.2260780\ttotal: 5m 24s\tremaining: 1m 45s\n",
      "377:\tlearn: 0.2256621\ttotal: 5m 25s\tremaining: 1m 44s\n",
      "378:\tlearn: 0.2255514\ttotal: 5m 25s\tremaining: 1m 44s\n",
      "379:\tlearn: 0.2254023\ttotal: 5m 26s\tremaining: 1m 43s\n",
      "380:\tlearn: 0.2251447\ttotal: 5m 27s\tremaining: 1m 42s\n",
      "381:\tlearn: 0.2249242\ttotal: 5m 28s\tremaining: 1m 41s\n",
      "382:\tlearn: 0.2248139\ttotal: 5m 29s\tremaining: 1m 40s\n",
      "383:\tlearn: 0.2245830\ttotal: 5m 30s\tremaining: 1m 39s\n",
      "384:\tlearn: 0.2243510\ttotal: 5m 30s\tremaining: 1m 38s\n",
      "385:\tlearn: 0.2242415\ttotal: 5m 31s\tremaining: 1m 37s\n",
      "386:\tlearn: 0.2240133\ttotal: 5m 32s\tremaining: 1m 37s\n",
      "387:\tlearn: 0.2237351\ttotal: 5m 33s\tremaining: 1m 36s\n",
      "388:\tlearn: 0.2235166\ttotal: 5m 34s\tremaining: 1m 35s\n",
      "389:\tlearn: 0.2233604\ttotal: 5m 35s\tremaining: 1m 34s\n",
      "390:\tlearn: 0.2230205\ttotal: 5m 35s\tremaining: 1m 33s\n",
      "391:\tlearn: 0.2227677\ttotal: 5m 36s\tremaining: 1m 32s\n",
      "392:\tlearn: 0.2225867\ttotal: 5m 37s\tremaining: 1m 31s\n",
      "393:\tlearn: 0.2223779\ttotal: 5m 38s\tremaining: 1m 31s\n",
      "394:\tlearn: 0.2221920\ttotal: 5m 39s\tremaining: 1m 30s\n",
      "395:\tlearn: 0.2219448\ttotal: 5m 40s\tremaining: 1m 29s\n",
      "396:\tlearn: 0.2218009\ttotal: 5m 40s\tremaining: 1m 28s\n",
      "397:\tlearn: 0.2212787\ttotal: 5m 41s\tremaining: 1m 27s\n",
      "398:\tlearn: 0.2211691\ttotal: 5m 42s\tremaining: 1m 26s\n",
      "399:\tlearn: 0.2209188\ttotal: 5m 43s\tremaining: 1m 25s\n",
      "400:\tlearn: 0.2207506\ttotal: 5m 44s\tremaining: 1m 25s\n",
      "401:\tlearn: 0.2206419\ttotal: 5m 45s\tremaining: 1m 24s\n",
      "402:\tlearn: 0.2203919\ttotal: 5m 46s\tremaining: 1m 23s\n",
      "403:\tlearn: 0.2200381\ttotal: 5m 47s\tremaining: 1m 22s\n",
      "404:\tlearn: 0.2199034\ttotal: 5m 48s\tremaining: 1m 21s\n",
      "405:\tlearn: 0.2196937\ttotal: 5m 49s\tremaining: 1m 20s\n",
      "406:\tlearn: 0.2192692\ttotal: 5m 50s\tremaining: 1m 20s\n",
      "407:\tlearn: 0.2191626\ttotal: 5m 51s\tremaining: 1m 19s\n",
      "408:\tlearn: 0.2190446\ttotal: 5m 52s\tremaining: 1m 18s\n",
      "409:\tlearn: 0.2189396\ttotal: 5m 53s\tremaining: 1m 17s\n",
      "410:\tlearn: 0.2186630\ttotal: 5m 54s\tremaining: 1m 16s\n",
      "411:\tlearn: 0.2184671\ttotal: 5m 55s\tremaining: 1m 15s\n",
      "412:\tlearn: 0.2183118\ttotal: 5m 55s\tremaining: 1m 14s\n",
      "413:\tlearn: 0.2179738\ttotal: 5m 56s\tremaining: 1m 14s\n",
      "414:\tlearn: 0.2178713\ttotal: 5m 57s\tremaining: 1m 13s\n",
      "415:\tlearn: 0.2177309\ttotal: 5m 58s\tremaining: 1m 12s\n",
      "416:\tlearn: 0.2174681\ttotal: 5m 59s\tremaining: 1m 11s\n",
      "417:\tlearn: 0.2172593\ttotal: 5m 59s\tremaining: 1m 10s\n",
      "418:\tlearn: 0.2171587\ttotal: 6m\tremaining: 1m 9s\n",
      "419:\tlearn: 0.2169542\ttotal: 6m 1s\tremaining: 1m 8s\n",
      "420:\tlearn: 0.2167196\ttotal: 6m 2s\tremaining: 1m 8s\n",
      "421:\tlearn: 0.2164323\ttotal: 6m 3s\tremaining: 1m 7s\n",
      "422:\tlearn: 0.2163132\ttotal: 6m 4s\tremaining: 1m 6s\n",
      "423:\tlearn: 0.2160693\ttotal: 6m 5s\tremaining: 1m 5s\n",
      "424:\tlearn: 0.2158755\ttotal: 6m 6s\tremaining: 1m 4s\n",
      "425:\tlearn: 0.2157751\ttotal: 6m 7s\tremaining: 1m 3s\n",
      "426:\tlearn: 0.2155764\ttotal: 6m 7s\tremaining: 1m 2s\n",
      "427:\tlearn: 0.2153595\ttotal: 6m 8s\tremaining: 1m 2s\n",
      "428:\tlearn: 0.2151752\ttotal: 6m 9s\tremaining: 1m 1s\n",
      "429:\tlearn: 0.2149287\ttotal: 6m 10s\tremaining: 1m\n",
      "430:\tlearn: 0.2146991\ttotal: 6m 11s\tremaining: 59.4s\n",
      "431:\tlearn: 0.2145807\ttotal: 6m 12s\tremaining: 58.6s\n",
      "432:\tlearn: 0.2142728\ttotal: 6m 12s\tremaining: 57.7s\n",
      "433:\tlearn: 0.2141734\ttotal: 6m 13s\tremaining: 56.8s\n",
      "434:\tlearn: 0.2140794\ttotal: 6m 14s\tremaining: 56s\n",
      "435:\tlearn: 0.2138108\ttotal: 6m 15s\tremaining: 55.1s\n",
      "436:\tlearn: 0.2135713\ttotal: 6m 16s\tremaining: 54.2s\n",
      "437:\tlearn: 0.2134396\ttotal: 6m 16s\tremaining: 53.4s\n",
      "438:\tlearn: 0.2131894\ttotal: 6m 17s\tremaining: 52.5s\n",
      "439:\tlearn: 0.2130600\ttotal: 6m 18s\tremaining: 51.6s\n",
      "440:\tlearn: 0.2128032\ttotal: 6m 19s\tremaining: 50.8s\n",
      "441:\tlearn: 0.2125895\ttotal: 6m 20s\tremaining: 49.9s\n",
      "442:\tlearn: 0.2123380\ttotal: 6m 21s\tremaining: 49s\n",
      "443:\tlearn: 0.2121135\ttotal: 6m 21s\tremaining: 48.2s\n",
      "444:\tlearn: 0.2119739\ttotal: 6m 22s\tremaining: 47.3s\n",
      "445:\tlearn: 0.2115209\ttotal: 6m 23s\tremaining: 46.4s\n",
      "446:\tlearn: 0.2112724\ttotal: 6m 24s\tremaining: 45.6s\n",
      "447:\tlearn: 0.2110044\ttotal: 6m 25s\tremaining: 44.7s\n",
      "448:\tlearn: 0.2108001\ttotal: 6m 26s\tremaining: 43.8s\n",
      "449:\tlearn: 0.2105062\ttotal: 6m 26s\tremaining: 43s\n",
      "450:\tlearn: 0.2104082\ttotal: 6m 27s\tremaining: 42.1s\n",
      "451:\tlearn: 0.2101374\ttotal: 6m 28s\tremaining: 41.3s\n",
      "452:\tlearn: 0.2100137\ttotal: 6m 29s\tremaining: 40.4s\n",
      "453:\tlearn: 0.2098618\ttotal: 6m 30s\tremaining: 39.5s\n",
      "454:\tlearn: 0.2096013\ttotal: 6m 30s\tremaining: 38.7s\n",
      "455:\tlearn: 0.2095055\ttotal: 6m 31s\tremaining: 37.8s\n",
      "456:\tlearn: 0.2094076\ttotal: 6m 32s\tremaining: 36.9s\n",
      "457:\tlearn: 0.2093102\ttotal: 6m 33s\tremaining: 36.1s\n",
      "458:\tlearn: 0.2092130\ttotal: 6m 34s\tremaining: 35.2s\n",
      "459:\tlearn: 0.2091151\ttotal: 6m 35s\tremaining: 34.4s\n",
      "460:\tlearn: 0.2089246\ttotal: 6m 36s\tremaining: 33.5s\n",
      "461:\tlearn: 0.2088171\ttotal: 6m 37s\tremaining: 32.7s\n",
      "462:\tlearn: 0.2085499\ttotal: 6m 38s\tremaining: 31.8s\n",
      "463:\tlearn: 0.2084517\ttotal: 6m 39s\tremaining: 31s\n",
      "464:\tlearn: 0.2083566\ttotal: 6m 39s\tremaining: 30.1s\n",
      "465:\tlearn: 0.2082595\ttotal: 6m 40s\tremaining: 29.2s\n",
      "466:\tlearn: 0.2080626\ttotal: 6m 41s\tremaining: 28.4s\n",
      "467:\tlearn: 0.2079289\ttotal: 6m 42s\tremaining: 27.5s\n",
      "468:\tlearn: 0.2078326\ttotal: 6m 43s\tremaining: 26.6s\n",
      "469:\tlearn: 0.2077373\ttotal: 6m 44s\tremaining: 25.8s\n",
      "470:\tlearn: 0.2075240\ttotal: 6m 45s\tremaining: 24.9s\n",
      "471:\tlearn: 0.2074313\ttotal: 6m 45s\tremaining: 24.1s\n",
      "472:\tlearn: 0.2072367\ttotal: 6m 46s\tremaining: 23.2s\n",
      "473:\tlearn: 0.2069711\ttotal: 6m 47s\tremaining: 22.4s\n",
      "474:\tlearn: 0.2068622\ttotal: 6m 48s\tremaining: 21.5s\n",
      "475:\tlearn: 0.2067472\ttotal: 6m 49s\tremaining: 20.7s\n",
      "476:\tlearn: 0.2064898\ttotal: 6m 50s\tremaining: 19.8s\n",
      "477:\tlearn: 0.2062795\ttotal: 6m 51s\tremaining: 18.9s\n",
      "478:\tlearn: 0.2060668\ttotal: 6m 52s\tremaining: 18.1s\n",
      "479:\tlearn: 0.2058432\ttotal: 6m 53s\tremaining: 17.2s\n",
      "480:\tlearn: 0.2057529\ttotal: 6m 54s\tremaining: 16.4s\n",
      "481:\tlearn: 0.2055732\ttotal: 6m 55s\tremaining: 15.5s\n",
      "482:\tlearn: 0.2054808\ttotal: 6m 55s\tremaining: 14.6s\n",
      "483:\tlearn: 0.2053023\ttotal: 6m 56s\tremaining: 13.8s\n",
      "484:\tlearn: 0.2050564\ttotal: 6m 57s\tremaining: 12.9s\n",
      "485:\tlearn: 0.2049204\ttotal: 6m 58s\tremaining: 12.1s\n",
      "486:\tlearn: 0.2048327\ttotal: 6m 59s\tremaining: 11.2s\n",
      "487:\tlearn: 0.2041689\ttotal: 7m\tremaining: 10.3s\n",
      "488:\tlearn: 0.2039925\ttotal: 7m\tremaining: 9.47s\n",
      "489:\tlearn: 0.2037953\ttotal: 7m 1s\tremaining: 8.61s\n",
      "490:\tlearn: 0.2036382\ttotal: 7m 2s\tremaining: 7.75s\n",
      "491:\tlearn: 0.2034601\ttotal: 7m 3s\tremaining: 6.88s\n",
      "492:\tlearn: 0.2031705\ttotal: 7m 4s\tremaining: 6.02s\n",
      "493:\tlearn: 0.2029548\ttotal: 7m 5s\tremaining: 5.16s\n",
      "494:\tlearn: 0.2028402\ttotal: 7m 6s\tremaining: 4.3s\n",
      "495:\tlearn: 0.2027513\ttotal: 7m 6s\tremaining: 3.44s\n",
      "496:\tlearn: 0.2025798\ttotal: 7m 7s\tremaining: 2.58s\n",
      "497:\tlearn: 0.2023451\ttotal: 7m 8s\tremaining: 1.72s\n",
      "498:\tlearn: 0.2021465\ttotal: 7m 9s\tremaining: 860ms\n",
      "499:\tlearn: 0.2019952\ttotal: 7m 10s\tremaining: 0us\n",
      "[CV 3/5] END auto_class_weights=Balanced, iterations=500, random_state=12345;, score=0.746 total time= 7.3min\n",
      "Learning rate set to 0.12034\n",
      "0:\tlearn: 0.6410036\ttotal: 1.01s\tremaining: 8m 24s\n",
      "1:\tlearn: 0.6061101\ttotal: 1.98s\tremaining: 8m 14s\n",
      "2:\tlearn: 0.5790573\ttotal: 2.9s\tremaining: 8m 1s\n",
      "3:\tlearn: 0.5607953\ttotal: 3.84s\tremaining: 7m 56s\n",
      "4:\tlearn: 0.5476493\ttotal: 4.76s\tremaining: 7m 50s\n",
      "5:\tlearn: 0.5382985\ttotal: 5.63s\tremaining: 7m 43s\n",
      "6:\tlearn: 0.5301421\ttotal: 6.5s\tremaining: 7m 37s\n",
      "7:\tlearn: 0.5195442\ttotal: 7.35s\tremaining: 7m 32s\n",
      "8:\tlearn: 0.5146679\ttotal: 8.21s\tremaining: 7m 27s\n",
      "9:\tlearn: 0.5089310\ttotal: 9.1s\tremaining: 7m 25s\n",
      "10:\tlearn: 0.5042129\ttotal: 10s\tremaining: 7m 24s\n",
      "11:\tlearn: 0.4988497\ttotal: 10.9s\tremaining: 7m 21s\n",
      "12:\tlearn: 0.4939259\ttotal: 11.7s\tremaining: 7m 19s\n",
      "13:\tlearn: 0.4899433\ttotal: 12.6s\tremaining: 7m 16s\n",
      "14:\tlearn: 0.4820398\ttotal: 13.5s\tremaining: 7m 15s\n",
      "15:\tlearn: 0.4767125\ttotal: 14.4s\tremaining: 7m 14s\n",
      "16:\tlearn: 0.4731737\ttotal: 15.5s\tremaining: 7m 20s\n",
      "17:\tlearn: 0.4682899\ttotal: 17.3s\tremaining: 7m 42s\n",
      "18:\tlearn: 0.4645617\ttotal: 18.6s\tremaining: 7m 50s\n",
      "19:\tlearn: 0.4624960\ttotal: 19.5s\tremaining: 7m 47s\n",
      "20:\tlearn: 0.4585759\ttotal: 20.4s\tremaining: 7m 46s\n",
      "21:\tlearn: 0.4552668\ttotal: 21.4s\tremaining: 7m 44s\n",
      "22:\tlearn: 0.4523612\ttotal: 22.3s\tremaining: 7m 41s\n",
      "23:\tlearn: 0.4480331\ttotal: 23.3s\tremaining: 7m 41s\n",
      "24:\tlearn: 0.4455636\ttotal: 24.3s\tremaining: 7m 42s\n",
      "25:\tlearn: 0.4430534\ttotal: 25.3s\tremaining: 7m 41s\n",
      "26:\tlearn: 0.4404353\ttotal: 26.7s\tremaining: 7m 48s\n",
      "27:\tlearn: 0.4379686\ttotal: 28.5s\tremaining: 7m 59s\n",
      "28:\tlearn: 0.4357868\ttotal: 29.7s\tremaining: 8m 2s\n",
      "29:\tlearn: 0.4333506\ttotal: 30.7s\tremaining: 8m 1s\n",
      "30:\tlearn: 0.4299955\ttotal: 31.7s\tremaining: 7m 58s\n",
      "31:\tlearn: 0.4271126\ttotal: 32.6s\tremaining: 7m 57s\n",
      "32:\tlearn: 0.4260526\ttotal: 33.7s\tremaining: 7m 56s\n",
      "33:\tlearn: 0.4243323\ttotal: 34.9s\tremaining: 7m 57s\n",
      "34:\tlearn: 0.4227634\ttotal: 36s\tremaining: 7m 58s\n",
      "35:\tlearn: 0.4211084\ttotal: 37.1s\tremaining: 7m 57s\n",
      "36:\tlearn: 0.4191475\ttotal: 38.1s\tremaining: 7m 56s\n",
      "37:\tlearn: 0.4178370\ttotal: 38.9s\tremaining: 7m 53s\n",
      "38:\tlearn: 0.4159401\ttotal: 40.4s\tremaining: 7m 58s\n",
      "39:\tlearn: 0.4136961\ttotal: 42.4s\tremaining: 8m 7s\n",
      "40:\tlearn: 0.4120744\ttotal: 44.2s\tremaining: 8m 14s\n",
      "41:\tlearn: 0.4108986\ttotal: 45.6s\tremaining: 8m 16s\n",
      "42:\tlearn: 0.4093296\ttotal: 47s\tremaining: 8m 19s\n",
      "43:\tlearn: 0.4079853\ttotal: 48.4s\tremaining: 8m 21s\n",
      "44:\tlearn: 0.4069075\ttotal: 49.6s\tremaining: 8m 21s\n",
      "45:\tlearn: 0.4054639\ttotal: 50.9s\tremaining: 8m 22s\n",
      "46:\tlearn: 0.4044361\ttotal: 52s\tremaining: 8m 20s\n",
      "47:\tlearn: 0.4027727\ttotal: 53.3s\tremaining: 8m 21s\n",
      "48:\tlearn: 0.4017686\ttotal: 54.7s\tremaining: 8m 23s\n",
      "49:\tlearn: 0.4003913\ttotal: 56s\tremaining: 8m 23s\n",
      "50:\tlearn: 0.3993095\ttotal: 57.3s\tremaining: 8m 24s\n",
      "51:\tlearn: 0.3978603\ttotal: 58.5s\tremaining: 8m 24s\n",
      "52:\tlearn: 0.3968287\ttotal: 59.8s\tremaining: 8m 24s\n",
      "53:\tlearn: 0.3960806\ttotal: 1m 1s\tremaining: 8m 24s\n",
      "54:\tlearn: 0.3952685\ttotal: 1m 2s\tremaining: 8m 24s\n",
      "55:\tlearn: 0.3943936\ttotal: 1m 3s\tremaining: 8m 24s\n",
      "56:\tlearn: 0.3932768\ttotal: 1m 4s\tremaining: 8m 25s\n",
      "57:\tlearn: 0.3913071\ttotal: 1m 6s\tremaining: 8m 25s\n",
      "58:\tlearn: 0.3899872\ttotal: 1m 7s\tremaining: 8m 26s\n",
      "59:\tlearn: 0.3883580\ttotal: 1m 9s\tremaining: 8m 26s\n",
      "60:\tlearn: 0.3871968\ttotal: 1m 10s\tremaining: 8m 26s\n",
      "61:\tlearn: 0.3856533\ttotal: 1m 11s\tremaining: 8m 26s\n",
      "62:\tlearn: 0.3847049\ttotal: 1m 12s\tremaining: 8m 25s\n",
      "63:\tlearn: 0.3835899\ttotal: 1m 14s\tremaining: 8m 25s\n",
      "64:\tlearn: 0.3827018\ttotal: 1m 15s\tremaining: 8m 24s\n",
      "65:\tlearn: 0.3820527\ttotal: 1m 16s\tremaining: 8m 24s\n",
      "66:\tlearn: 0.3812098\ttotal: 1m 18s\tremaining: 8m 25s\n",
      "67:\tlearn: 0.3800457\ttotal: 1m 19s\tremaining: 8m 24s\n",
      "68:\tlearn: 0.3788217\ttotal: 1m 20s\tremaining: 8m 24s\n",
      "69:\tlearn: 0.3778859\ttotal: 1m 22s\tremaining: 8m 24s\n",
      "70:\tlearn: 0.3768122\ttotal: 1m 23s\tremaining: 8m 24s\n",
      "71:\tlearn: 0.3760797\ttotal: 1m 24s\tremaining: 8m 22s\n",
      "72:\tlearn: 0.3752144\ttotal: 1m 25s\tremaining: 8m 20s\n",
      "73:\tlearn: 0.3744174\ttotal: 1m 26s\tremaining: 8m 18s\n",
      "74:\tlearn: 0.3724503\ttotal: 1m 27s\tremaining: 8m 15s\n",
      "75:\tlearn: 0.3715573\ttotal: 1m 28s\tremaining: 8m 12s\n",
      "76:\tlearn: 0.3704889\ttotal: 1m 29s\tremaining: 8m 10s\n",
      "77:\tlearn: 0.3695933\ttotal: 1m 30s\tremaining: 8m 7s\n",
      "78:\tlearn: 0.3687918\ttotal: 1m 30s\tremaining: 8m 4s\n",
      "79:\tlearn: 0.3673478\ttotal: 1m 31s\tremaining: 8m 2s\n",
      "80:\tlearn: 0.3665805\ttotal: 1m 32s\tremaining: 7m 59s\n",
      "81:\tlearn: 0.3655595\ttotal: 1m 33s\tremaining: 7m 57s\n",
      "82:\tlearn: 0.3646666\ttotal: 1m 34s\tremaining: 7m 54s\n",
      "83:\tlearn: 0.3638922\ttotal: 1m 35s\tremaining: 7m 52s\n",
      "84:\tlearn: 0.3630190\ttotal: 1m 36s\tremaining: 7m 49s\n",
      "85:\tlearn: 0.3621110\ttotal: 1m 37s\tremaining: 7m 47s\n",
      "86:\tlearn: 0.3613940\ttotal: 1m 38s\tremaining: 7m 45s\n",
      "87:\tlearn: 0.3605570\ttotal: 1m 39s\tremaining: 7m 44s\n",
      "88:\tlearn: 0.3597036\ttotal: 1m 40s\tremaining: 7m 42s\n",
      "89:\tlearn: 0.3589689\ttotal: 1m 41s\tremaining: 7m 41s\n",
      "90:\tlearn: 0.3580917\ttotal: 1m 43s\tremaining: 7m 43s\n",
      "91:\tlearn: 0.3568957\ttotal: 1m 44s\tremaining: 7m 45s\n",
      "92:\tlearn: 0.3560889\ttotal: 1m 46s\tremaining: 7m 46s\n",
      "93:\tlearn: 0.3551223\ttotal: 1m 47s\tremaining: 7m 46s\n",
      "94:\tlearn: 0.3538717\ttotal: 1m 49s\tremaining: 7m 45s\n",
      "95:\tlearn: 0.3530164\ttotal: 1m 50s\tremaining: 7m 45s\n",
      "96:\tlearn: 0.3521591\ttotal: 1m 52s\tremaining: 7m 45s\n",
      "97:\tlearn: 0.3513526\ttotal: 1m 53s\tremaining: 7m 44s\n",
      "98:\tlearn: 0.3500506\ttotal: 1m 54s\tremaining: 7m 43s\n",
      "99:\tlearn: 0.3486197\ttotal: 1m 55s\tremaining: 7m 43s\n",
      "100:\tlearn: 0.3471684\ttotal: 1m 57s\tremaining: 7m 43s\n",
      "101:\tlearn: 0.3457704\ttotal: 1m 58s\tremaining: 7m 43s\n",
      "102:\tlearn: 0.3438683\ttotal: 2m\tremaining: 7m 43s\n",
      "103:\tlearn: 0.3428719\ttotal: 2m 1s\tremaining: 7m 42s\n",
      "104:\tlearn: 0.3420753\ttotal: 2m 2s\tremaining: 7m 41s\n",
      "105:\tlearn: 0.3409754\ttotal: 2m 4s\tremaining: 7m 40s\n",
      "106:\tlearn: 0.3400671\ttotal: 2m 5s\tremaining: 7m 40s\n",
      "107:\tlearn: 0.3392764\ttotal: 2m 6s\tremaining: 7m 40s\n",
      "108:\tlearn: 0.3385152\ttotal: 2m 8s\tremaining: 7m 39s\n",
      "109:\tlearn: 0.3377626\ttotal: 2m 9s\tremaining: 7m 39s\n",
      "110:\tlearn: 0.3369901\ttotal: 2m 10s\tremaining: 7m 38s\n",
      "111:\tlearn: 0.3362186\ttotal: 2m 12s\tremaining: 7m 37s\n",
      "112:\tlearn: 0.3355045\ttotal: 2m 13s\tremaining: 7m 36s\n",
      "113:\tlearn: 0.3348067\ttotal: 2m 14s\tremaining: 7m 34s\n",
      "114:\tlearn: 0.3339953\ttotal: 2m 15s\tremaining: 7m 32s\n",
      "115:\tlearn: 0.3332036\ttotal: 2m 16s\tremaining: 7m 30s\n",
      "116:\tlearn: 0.3323565\ttotal: 2m 17s\tremaining: 7m 28s\n",
      "117:\tlearn: 0.3315928\ttotal: 2m 18s\tremaining: 7m 27s\n",
      "118:\tlearn: 0.3307129\ttotal: 2m 19s\tremaining: 7m 27s\n",
      "119:\tlearn: 0.3298069\ttotal: 2m 20s\tremaining: 7m 26s\n",
      "120:\tlearn: 0.3289945\ttotal: 2m 22s\tremaining: 7m 25s\n",
      "121:\tlearn: 0.3283240\ttotal: 2m 23s\tremaining: 7m 24s\n",
      "122:\tlearn: 0.3276194\ttotal: 2m 24s\tremaining: 7m 23s\n",
      "123:\tlearn: 0.3268110\ttotal: 2m 26s\tremaining: 7m 22s\n",
      "124:\tlearn: 0.3261387\ttotal: 2m 27s\tremaining: 7m 21s\n",
      "125:\tlearn: 0.3254939\ttotal: 2m 28s\tremaining: 7m 20s\n",
      "126:\tlearn: 0.3248574\ttotal: 2m 29s\tremaining: 7m 19s\n",
      "127:\tlearn: 0.3231599\ttotal: 2m 30s\tremaining: 7m 18s\n",
      "128:\tlearn: 0.3224646\ttotal: 2m 32s\tremaining: 7m 17s\n",
      "129:\tlearn: 0.3218974\ttotal: 2m 33s\tremaining: 7m 16s\n",
      "130:\tlearn: 0.3211777\ttotal: 2m 34s\tremaining: 7m 15s\n",
      "131:\tlearn: 0.3204733\ttotal: 2m 35s\tremaining: 7m 14s\n",
      "132:\tlearn: 0.3197830\ttotal: 2m 36s\tremaining: 7m 12s\n",
      "133:\tlearn: 0.3191909\ttotal: 2m 37s\tremaining: 7m 10s\n",
      "134:\tlearn: 0.3184400\ttotal: 2m 38s\tremaining: 7m 8s\n",
      "135:\tlearn: 0.3172387\ttotal: 2m 39s\tremaining: 7m 7s\n",
      "136:\tlearn: 0.3165006\ttotal: 2m 41s\tremaining: 7m 6s\n",
      "137:\tlearn: 0.3159613\ttotal: 2m 42s\tremaining: 7m 7s\n",
      "138:\tlearn: 0.3154234\ttotal: 2m 44s\tremaining: 7m 8s\n",
      "139:\tlearn: 0.3147358\ttotal: 2m 46s\tremaining: 7m 8s\n",
      "140:\tlearn: 0.3140654\ttotal: 2m 48s\tremaining: 7m 8s\n",
      "141:\tlearn: 0.3135583\ttotal: 2m 49s\tremaining: 7m 7s\n",
      "142:\tlearn: 0.3129485\ttotal: 2m 50s\tremaining: 7m 6s\n",
      "143:\tlearn: 0.3124032\ttotal: 2m 52s\tremaining: 7m 6s\n",
      "144:\tlearn: 0.3117612\ttotal: 2m 54s\tremaining: 7m 6s\n",
      "145:\tlearn: 0.3112235\ttotal: 2m 55s\tremaining: 7m 5s\n",
      "146:\tlearn: 0.3105694\ttotal: 2m 56s\tremaining: 7m 4s\n",
      "147:\tlearn: 0.3099427\ttotal: 2m 58s\tremaining: 7m 3s\n",
      "148:\tlearn: 0.3092336\ttotal: 2m 59s\tremaining: 7m 2s\n",
      "149:\tlearn: 0.3086434\ttotal: 3m\tremaining: 7m\n",
      "150:\tlearn: 0.3081304\ttotal: 3m 1s\tremaining: 6m 59s\n",
      "151:\tlearn: 0.3070736\ttotal: 3m 2s\tremaining: 6m 57s\n",
      "152:\tlearn: 0.3065568\ttotal: 3m 3s\tremaining: 6m 55s\n",
      "153:\tlearn: 0.3057275\ttotal: 3m 4s\tremaining: 6m 54s\n",
      "154:\tlearn: 0.3051956\ttotal: 3m 5s\tremaining: 6m 52s\n",
      "155:\tlearn: 0.3047159\ttotal: 3m 6s\tremaining: 6m 50s\n",
      "156:\tlearn: 0.3041660\ttotal: 3m 7s\tremaining: 6m 48s\n",
      "157:\tlearn: 0.3035743\ttotal: 3m 8s\tremaining: 6m 47s\n",
      "158:\tlearn: 0.3031153\ttotal: 3m 9s\tremaining: 6m 45s\n",
      "159:\tlearn: 0.3025655\ttotal: 3m 10s\tremaining: 6m 43s\n",
      "160:\tlearn: 0.3020477\ttotal: 3m 11s\tremaining: 6m 42s\n",
      "161:\tlearn: 0.3014480\ttotal: 3m 12s\tremaining: 6m 42s\n",
      "162:\tlearn: 0.3009602\ttotal: 3m 14s\tremaining: 6m 41s\n",
      "163:\tlearn: 0.3003836\ttotal: 3m 15s\tremaining: 6m 40s\n",
      "164:\tlearn: 0.2998280\ttotal: 3m 16s\tremaining: 6m 39s\n",
      "165:\tlearn: 0.2993057\ttotal: 3m 17s\tremaining: 6m 37s\n",
      "166:\tlearn: 0.2988458\ttotal: 3m 18s\tremaining: 6m 35s\n",
      "167:\tlearn: 0.2980362\ttotal: 3m 19s\tremaining: 6m 34s\n",
      "168:\tlearn: 0.2969662\ttotal: 3m 20s\tremaining: 6m 32s\n",
      "169:\tlearn: 0.2964697\ttotal: 3m 21s\tremaining: 6m 30s\n",
      "170:\tlearn: 0.2957601\ttotal: 3m 22s\tremaining: 6m 29s\n",
      "171:\tlearn: 0.2952816\ttotal: 3m 23s\tremaining: 6m 27s\n",
      "172:\tlearn: 0.2949398\ttotal: 3m 24s\tremaining: 6m 25s\n",
      "173:\tlearn: 0.2944514\ttotal: 3m 25s\tremaining: 6m 24s\n",
      "174:\tlearn: 0.2938382\ttotal: 3m 25s\tremaining: 6m 22s\n",
      "175:\tlearn: 0.2934988\ttotal: 3m 26s\tremaining: 6m 20s\n",
      "176:\tlearn: 0.2929383\ttotal: 3m 27s\tremaining: 6m 19s\n",
      "177:\tlearn: 0.2924242\ttotal: 3m 28s\tremaining: 6m 17s\n",
      "178:\tlearn: 0.2919835\ttotal: 3m 29s\tremaining: 6m 16s\n",
      "179:\tlearn: 0.2915029\ttotal: 3m 30s\tremaining: 6m 14s\n",
      "180:\tlearn: 0.2910322\ttotal: 3m 31s\tremaining: 6m 13s\n",
      "181:\tlearn: 0.2906224\ttotal: 3m 33s\tremaining: 6m 12s\n",
      "182:\tlearn: 0.2900815\ttotal: 3m 34s\tremaining: 6m 12s\n",
      "183:\tlearn: 0.2895952\ttotal: 3m 36s\tremaining: 6m 11s\n",
      "184:\tlearn: 0.2892331\ttotal: 3m 37s\tremaining: 6m 10s\n",
      "185:\tlearn: 0.2888738\ttotal: 3m 38s\tremaining: 6m 9s\n",
      "186:\tlearn: 0.2883532\ttotal: 3m 39s\tremaining: 6m 7s\n",
      "187:\tlearn: 0.2879906\ttotal: 3m 41s\tremaining: 6m 6s\n",
      "188:\tlearn: 0.2874754\ttotal: 3m 42s\tremaining: 6m 6s\n",
      "189:\tlearn: 0.2870634\ttotal: 3m 43s\tremaining: 6m 4s\n",
      "190:\tlearn: 0.2864802\ttotal: 3m 45s\tremaining: 6m 4s\n",
      "191:\tlearn: 0.2861543\ttotal: 3m 46s\tremaining: 6m 3s\n",
      "192:\tlearn: 0.2857366\ttotal: 3m 48s\tremaining: 6m 2s\n",
      "193:\tlearn: 0.2851704\ttotal: 3m 49s\tremaining: 6m 1s\n",
      "194:\tlearn: 0.2846206\ttotal: 3m 50s\tremaining: 6m\n",
      "195:\tlearn: 0.2840875\ttotal: 3m 51s\tremaining: 5m 59s\n",
      "196:\tlearn: 0.2837421\ttotal: 3m 53s\tremaining: 5m 58s\n",
      "197:\tlearn: 0.2832035\ttotal: 3m 54s\tremaining: 5m 57s\n",
      "198:\tlearn: 0.2827424\ttotal: 3m 55s\tremaining: 5m 56s\n",
      "199:\tlearn: 0.2823762\ttotal: 3m 56s\tremaining: 5m 55s\n",
      "200:\tlearn: 0.2819466\ttotal: 3m 57s\tremaining: 5m 53s\n",
      "201:\tlearn: 0.2815411\ttotal: 3m 59s\tremaining: 5m 53s\n",
      "202:\tlearn: 0.2810850\ttotal: 4m\tremaining: 5m 52s\n",
      "203:\tlearn: 0.2806244\ttotal: 4m 1s\tremaining: 5m 50s\n",
      "204:\tlearn: 0.2801699\ttotal: 4m 3s\tremaining: 5m 49s\n",
      "205:\tlearn: 0.2797825\ttotal: 4m 4s\tremaining: 5m 48s\n",
      "206:\tlearn: 0.2793042\ttotal: 4m 5s\tremaining: 5m 47s\n",
      "207:\tlearn: 0.2790143\ttotal: 4m 6s\tremaining: 5m 45s\n",
      "208:\tlearn: 0.2786112\ttotal: 4m 7s\tremaining: 5m 44s\n",
      "209:\tlearn: 0.2781226\ttotal: 4m 8s\tremaining: 5m 42s\n",
      "210:\tlearn: 0.2777403\ttotal: 4m 9s\tremaining: 5m 41s\n",
      "211:\tlearn: 0.2772535\ttotal: 4m 10s\tremaining: 5m 39s\n",
      "212:\tlearn: 0.2768985\ttotal: 4m 11s\tremaining: 5m 38s\n",
      "213:\tlearn: 0.2764982\ttotal: 4m 11s\tremaining: 5m 36s\n",
      "214:\tlearn: 0.2761359\ttotal: 4m 12s\tremaining: 5m 35s\n",
      "215:\tlearn: 0.2757942\ttotal: 4m 13s\tremaining: 5m 33s\n",
      "216:\tlearn: 0.2753624\ttotal: 4m 14s\tremaining: 5m 32s\n",
      "217:\tlearn: 0.2750621\ttotal: 4m 15s\tremaining: 5m 30s\n",
      "218:\tlearn: 0.2747279\ttotal: 4m 16s\tremaining: 5m 29s\n",
      "219:\tlearn: 0.2743036\ttotal: 4m 17s\tremaining: 5m 27s\n",
      "220:\tlearn: 0.2740490\ttotal: 4m 18s\tremaining: 5m 26s\n",
      "221:\tlearn: 0.2737026\ttotal: 4m 19s\tremaining: 5m 24s\n",
      "222:\tlearn: 0.2732378\ttotal: 4m 20s\tremaining: 5m 23s\n",
      "223:\tlearn: 0.2728299\ttotal: 4m 21s\tremaining: 5m 22s\n",
      "224:\tlearn: 0.2716491\ttotal: 4m 22s\tremaining: 5m 20s\n",
      "225:\tlearn: 0.2713657\ttotal: 4m 23s\tremaining: 5m 19s\n",
      "226:\tlearn: 0.2710582\ttotal: 4m 24s\tremaining: 5m 17s\n",
      "227:\tlearn: 0.2707205\ttotal: 4m 25s\tremaining: 5m 16s\n",
      "228:\tlearn: 0.2703105\ttotal: 4m 26s\tremaining: 5m 15s\n",
      "229:\tlearn: 0.2698166\ttotal: 4m 27s\tremaining: 5m 13s\n",
      "230:\tlearn: 0.2694870\ttotal: 4m 28s\tremaining: 5m 12s\n",
      "231:\tlearn: 0.2691359\ttotal: 4m 28s\tremaining: 5m 10s\n",
      "232:\tlearn: 0.2687314\ttotal: 4m 29s\tremaining: 5m 9s\n",
      "233:\tlearn: 0.2684453\ttotal: 4m 30s\tremaining: 5m 7s\n",
      "234:\tlearn: 0.2680979\ttotal: 4m 31s\tremaining: 5m 6s\n",
      "235:\tlearn: 0.2677386\ttotal: 4m 32s\tremaining: 5m 5s\n",
      "236:\tlearn: 0.2673625\ttotal: 4m 33s\tremaining: 5m 3s\n",
      "237:\tlearn: 0.2670374\ttotal: 4m 35s\tremaining: 5m 2s\n",
      "238:\tlearn: 0.2666739\ttotal: 4m 35s\tremaining: 5m 1s\n",
      "239:\tlearn: 0.2663111\ttotal: 4m 36s\tremaining: 5m\n",
      "240:\tlearn: 0.2660855\ttotal: 4m 38s\tremaining: 4m 58s\n",
      "241:\tlearn: 0.2658655\ttotal: 4m 39s\tremaining: 4m 57s\n",
      "242:\tlearn: 0.2655922\ttotal: 4m 39s\tremaining: 4m 56s\n",
      "243:\tlearn: 0.2650584\ttotal: 4m 40s\tremaining: 4m 54s\n",
      "244:\tlearn: 0.2646951\ttotal: 4m 41s\tremaining: 4m 53s\n",
      "245:\tlearn: 0.2644310\ttotal: 4m 42s\tremaining: 4m 51s\n",
      "246:\tlearn: 0.2641531\ttotal: 4m 43s\tremaining: 4m 50s\n",
      "247:\tlearn: 0.2638407\ttotal: 4m 44s\tremaining: 4m 48s\n",
      "248:\tlearn: 0.2634708\ttotal: 4m 45s\tremaining: 4m 47s\n",
      "249:\tlearn: 0.2631071\ttotal: 4m 46s\tremaining: 4m 46s\n",
      "250:\tlearn: 0.2627358\ttotal: 4m 46s\tremaining: 4m 44s\n",
      "251:\tlearn: 0.2621734\ttotal: 4m 47s\tremaining: 4m 43s\n",
      "252:\tlearn: 0.2618091\ttotal: 4m 48s\tremaining: 4m 41s\n",
      "253:\tlearn: 0.2613953\ttotal: 4m 49s\tremaining: 4m 40s\n",
      "254:\tlearn: 0.2610272\ttotal: 4m 50s\tremaining: 4m 38s\n",
      "255:\tlearn: 0.2608417\ttotal: 4m 51s\tremaining: 4m 37s\n",
      "256:\tlearn: 0.2604561\ttotal: 4m 52s\tremaining: 4m 36s\n",
      "257:\tlearn: 0.2600213\ttotal: 4m 53s\tremaining: 4m 34s\n",
      "258:\tlearn: 0.2598164\ttotal: 4m 53s\tremaining: 4m 33s\n",
      "259:\tlearn: 0.2595740\ttotal: 4m 54s\tremaining: 4m 32s\n",
      "260:\tlearn: 0.2590923\ttotal: 4m 55s\tremaining: 4m 30s\n",
      "261:\tlearn: 0.2587214\ttotal: 4m 56s\tremaining: 4m 29s\n",
      "262:\tlearn: 0.2582896\ttotal: 4m 57s\tremaining: 4m 27s\n",
      "263:\tlearn: 0.2579391\ttotal: 4m 58s\tremaining: 4m 26s\n",
      "264:\tlearn: 0.2576656\ttotal: 4m 59s\tremaining: 4m 25s\n",
      "265:\tlearn: 0.2573031\ttotal: 4m 59s\tremaining: 4m 23s\n",
      "266:\tlearn: 0.2568763\ttotal: 5m\tremaining: 4m 22s\n",
      "267:\tlearn: 0.2566078\ttotal: 5m 1s\tremaining: 4m 21s\n",
      "268:\tlearn: 0.2563157\ttotal: 5m 2s\tremaining: 4m 19s\n",
      "269:\tlearn: 0.2561306\ttotal: 5m 3s\tremaining: 4m 18s\n",
      "270:\tlearn: 0.2558790\ttotal: 5m 4s\tremaining: 4m 16s\n",
      "271:\tlearn: 0.2555196\ttotal: 5m 4s\tremaining: 4m 15s\n",
      "272:\tlearn: 0.2552639\ttotal: 5m 5s\tremaining: 4m 14s\n",
      "273:\tlearn: 0.2549620\ttotal: 5m 6s\tremaining: 4m 12s\n",
      "274:\tlearn: 0.2546328\ttotal: 5m 7s\tremaining: 4m 11s\n",
      "275:\tlearn: 0.2544633\ttotal: 5m 8s\tremaining: 4m 10s\n",
      "276:\tlearn: 0.2541623\ttotal: 5m 9s\tremaining: 4m 9s\n",
      "277:\tlearn: 0.2537590\ttotal: 5m 10s\tremaining: 4m 8s\n",
      "278:\tlearn: 0.2534925\ttotal: 5m 11s\tremaining: 4m 6s\n",
      "279:\tlearn: 0.2531997\ttotal: 5m 12s\tremaining: 4m 5s\n",
      "280:\tlearn: 0.2528843\ttotal: 5m 13s\tremaining: 4m 4s\n",
      "281:\tlearn: 0.2526013\ttotal: 5m 14s\tremaining: 4m 2s\n",
      "282:\tlearn: 0.2522717\ttotal: 5m 15s\tremaining: 4m 1s\n",
      "283:\tlearn: 0.2519237\ttotal: 5m 16s\tremaining: 4m\n",
      "284:\tlearn: 0.2517336\ttotal: 5m 17s\tremaining: 3m 59s\n",
      "285:\tlearn: 0.2513951\ttotal: 5m 18s\tremaining: 3m 58s\n",
      "286:\tlearn: 0.2512416\ttotal: 5m 19s\tremaining: 3m 56s\n",
      "287:\tlearn: 0.2508839\ttotal: 5m 20s\tremaining: 3m 55s\n",
      "288:\tlearn: 0.2505233\ttotal: 5m 21s\tremaining: 3m 54s\n",
      "289:\tlearn: 0.2503097\ttotal: 5m 22s\tremaining: 3m 53s\n",
      "290:\tlearn: 0.2500162\ttotal: 5m 23s\tremaining: 3m 52s\n",
      "291:\tlearn: 0.2494032\ttotal: 5m 24s\tremaining: 3m 51s\n",
      "292:\tlearn: 0.2490457\ttotal: 5m 25s\tremaining: 3m 49s\n",
      "293:\tlearn: 0.2487664\ttotal: 5m 26s\tremaining: 3m 48s\n",
      "294:\tlearn: 0.2486177\ttotal: 5m 27s\tremaining: 3m 47s\n",
      "295:\tlearn: 0.2482994\ttotal: 5m 28s\tremaining: 3m 46s\n",
      "296:\tlearn: 0.2480070\ttotal: 5m 29s\tremaining: 3m 45s\n",
      "297:\tlearn: 0.2476871\ttotal: 5m 30s\tremaining: 3m 43s\n",
      "298:\tlearn: 0.2473834\ttotal: 5m 31s\tremaining: 3m 42s\n",
      "299:\tlearn: 0.2470912\ttotal: 5m 32s\tremaining: 3m 41s\n",
      "300:\tlearn: 0.2467937\ttotal: 5m 33s\tremaining: 3m 40s\n",
      "301:\tlearn: 0.2466352\ttotal: 5m 33s\tremaining: 3m 38s\n",
      "302:\tlearn: 0.2463104\ttotal: 5m 34s\tremaining: 3m 37s\n",
      "303:\tlearn: 0.2460071\ttotal: 5m 35s\tremaining: 3m 36s\n",
      "304:\tlearn: 0.2457838\ttotal: 5m 36s\tremaining: 3m 35s\n",
      "305:\tlearn: 0.2456132\ttotal: 5m 37s\tremaining: 3m 33s\n",
      "306:\tlearn: 0.2452747\ttotal: 5m 38s\tremaining: 3m 32s\n",
      "307:\tlearn: 0.2450018\ttotal: 5m 39s\tremaining: 3m 31s\n",
      "308:\tlearn: 0.2448181\ttotal: 5m 39s\tremaining: 3m 30s\n",
      "309:\tlearn: 0.2445611\ttotal: 5m 40s\tremaining: 3m 28s\n",
      "310:\tlearn: 0.2441978\ttotal: 5m 41s\tremaining: 3m 27s\n",
      "311:\tlearn: 0.2438444\ttotal: 5m 42s\tremaining: 3m 26s\n",
      "312:\tlearn: 0.2435514\ttotal: 5m 43s\tremaining: 3m 25s\n",
      "313:\tlearn: 0.2432936\ttotal: 5m 44s\tremaining: 3m 23s\n",
      "314:\tlearn: 0.2431536\ttotal: 5m 44s\tremaining: 3m 22s\n",
      "315:\tlearn: 0.2429322\ttotal: 5m 45s\tremaining: 3m 21s\n",
      "316:\tlearn: 0.2426388\ttotal: 5m 46s\tremaining: 3m 20s\n",
      "317:\tlearn: 0.2423275\ttotal: 5m 47s\tremaining: 3m 18s\n",
      "318:\tlearn: 0.2421322\ttotal: 5m 48s\tremaining: 3m 17s\n",
      "319:\tlearn: 0.2419609\ttotal: 5m 49s\tremaining: 3m 16s\n",
      "320:\tlearn: 0.2416028\ttotal: 5m 49s\tremaining: 3m 15s\n",
      "321:\tlearn: 0.2413395\ttotal: 5m 50s\tremaining: 3m 13s\n",
      "322:\tlearn: 0.2408099\ttotal: 5m 51s\tremaining: 3m 12s\n",
      "323:\tlearn: 0.2405537\ttotal: 5m 52s\tremaining: 3m 11s\n",
      "324:\tlearn: 0.2403189\ttotal: 5m 53s\tremaining: 3m 10s\n",
      "325:\tlearn: 0.2401840\ttotal: 5m 54s\tremaining: 3m 9s\n",
      "326:\tlearn: 0.2399509\ttotal: 5m 54s\tremaining: 3m 7s\n",
      "327:\tlearn: 0.2394079\ttotal: 5m 55s\tremaining: 3m 6s\n",
      "328:\tlearn: 0.2391712\ttotal: 5m 56s\tremaining: 3m 5s\n",
      "329:\tlearn: 0.2389537\ttotal: 5m 57s\tremaining: 3m 4s\n",
      "330:\tlearn: 0.2386399\ttotal: 5m 58s\tremaining: 3m 2s\n",
      "331:\tlearn: 0.2384760\ttotal: 5m 59s\tremaining: 3m 1s\n",
      "332:\tlearn: 0.2380667\ttotal: 6m\tremaining: 3m\n",
      "333:\tlearn: 0.2375431\ttotal: 6m\tremaining: 2m 59s\n",
      "334:\tlearn: 0.2372909\ttotal: 6m 1s\tremaining: 2m 58s\n",
      "335:\tlearn: 0.2371614\ttotal: 6m 2s\tremaining: 2m 56s\n",
      "336:\tlearn: 0.2369800\ttotal: 6m 3s\tremaining: 2m 55s\n",
      "337:\tlearn: 0.2367546\ttotal: 6m 4s\tremaining: 2m 54s\n",
      "338:\tlearn: 0.2364577\ttotal: 6m 4s\tremaining: 2m 53s\n",
      "339:\tlearn: 0.2361503\ttotal: 6m 5s\tremaining: 2m 52s\n",
      "340:\tlearn: 0.2359416\ttotal: 6m 6s\tremaining: 2m 50s\n",
      "341:\tlearn: 0.2356715\ttotal: 6m 7s\tremaining: 2m 49s\n",
      "342:\tlearn: 0.2353664\ttotal: 6m 8s\tremaining: 2m 48s\n",
      "343:\tlearn: 0.2351807\ttotal: 6m 9s\tremaining: 2m 47s\n",
      "344:\tlearn: 0.2349838\ttotal: 6m 10s\tremaining: 2m 46s\n",
      "345:\tlearn: 0.2348558\ttotal: 6m 11s\tremaining: 2m 45s\n",
      "346:\tlearn: 0.2346601\ttotal: 6m 12s\tremaining: 2m 44s\n",
      "347:\tlearn: 0.2343988\ttotal: 6m 13s\tremaining: 2m 43s\n",
      "348:\tlearn: 0.2342741\ttotal: 6m 14s\tremaining: 2m 42s\n",
      "349:\tlearn: 0.2340232\ttotal: 6m 15s\tremaining: 2m 40s\n",
      "350:\tlearn: 0.2338002\ttotal: 6m 16s\tremaining: 2m 39s\n",
      "351:\tlearn: 0.2335706\ttotal: 6m 17s\tremaining: 2m 38s\n",
      "352:\tlearn: 0.2333151\ttotal: 6m 17s\tremaining: 2m 37s\n",
      "353:\tlearn: 0.2331981\ttotal: 6m 18s\tremaining: 2m 36s\n",
      "354:\tlearn: 0.2329484\ttotal: 6m 19s\tremaining: 2m 34s\n",
      "355:\tlearn: 0.2326665\ttotal: 6m 20s\tremaining: 2m 33s\n",
      "356:\tlearn: 0.2325022\ttotal: 6m 21s\tremaining: 2m 32s\n",
      "357:\tlearn: 0.2320703\ttotal: 6m 22s\tremaining: 2m 31s\n",
      "358:\tlearn: 0.2318642\ttotal: 6m 22s\tremaining: 2m 30s\n",
      "359:\tlearn: 0.2315530\ttotal: 6m 23s\tremaining: 2m 29s\n",
      "360:\tlearn: 0.2313780\ttotal: 6m 24s\tremaining: 2m 28s\n",
      "361:\tlearn: 0.2310866\ttotal: 6m 25s\tremaining: 2m 26s\n",
      "362:\tlearn: 0.2309514\ttotal: 6m 26s\tremaining: 2m 25s\n",
      "363:\tlearn: 0.2307790\ttotal: 6m 27s\tremaining: 2m 24s\n",
      "364:\tlearn: 0.2303573\ttotal: 6m 27s\tremaining: 2m 23s\n",
      "365:\tlearn: 0.2301428\ttotal: 6m 28s\tremaining: 2m 22s\n",
      "366:\tlearn: 0.2299598\ttotal: 6m 29s\tremaining: 2m 21s\n",
      "367:\tlearn: 0.2297048\ttotal: 6m 30s\tremaining: 2m 20s\n",
      "368:\tlearn: 0.2295067\ttotal: 6m 31s\tremaining: 2m 18s\n",
      "369:\tlearn: 0.2292457\ttotal: 6m 32s\tremaining: 2m 17s\n",
      "370:\tlearn: 0.2290543\ttotal: 6m 32s\tremaining: 2m 16s\n",
      "371:\tlearn: 0.2287416\ttotal: 6m 33s\tremaining: 2m 15s\n",
      "372:\tlearn: 0.2284970\ttotal: 6m 34s\tremaining: 2m 14s\n",
      "373:\tlearn: 0.2282697\ttotal: 6m 35s\tremaining: 2m 13s\n",
      "374:\tlearn: 0.2280006\ttotal: 6m 36s\tremaining: 2m 12s\n",
      "375:\tlearn: 0.2276138\ttotal: 6m 37s\tremaining: 2m 10s\n",
      "376:\tlearn: 0.2274543\ttotal: 6m 37s\tremaining: 2m 9s\n",
      "377:\tlearn: 0.2273366\ttotal: 6m 38s\tremaining: 2m 8s\n",
      "378:\tlearn: 0.2272021\ttotal: 6m 39s\tremaining: 2m 7s\n",
      "379:\tlearn: 0.2269492\ttotal: 6m 40s\tremaining: 2m 6s\n",
      "380:\tlearn: 0.2267546\ttotal: 6m 41s\tremaining: 2m 5s\n",
      "381:\tlearn: 0.2264881\ttotal: 6m 42s\tremaining: 2m 4s\n",
      "382:\tlearn: 0.2263752\ttotal: 6m 42s\tremaining: 2m 3s\n",
      "383:\tlearn: 0.2261119\ttotal: 6m 43s\tremaining: 2m 1s\n",
      "384:\tlearn: 0.2258916\ttotal: 6m 44s\tremaining: 2m\n",
      "385:\tlearn: 0.2256171\ttotal: 6m 45s\tremaining: 1m 59s\n",
      "386:\tlearn: 0.2252319\ttotal: 6m 46s\tremaining: 1m 58s\n",
      "387:\tlearn: 0.2249803\ttotal: 6m 47s\tremaining: 1m 57s\n",
      "388:\tlearn: 0.2247938\ttotal: 6m 47s\tremaining: 1m 56s\n",
      "389:\tlearn: 0.2246256\ttotal: 6m 48s\tremaining: 1m 55s\n",
      "390:\tlearn: 0.2244521\ttotal: 6m 49s\tremaining: 1m 54s\n",
      "391:\tlearn: 0.2242003\ttotal: 6m 50s\tremaining: 1m 53s\n",
      "392:\tlearn: 0.2239652\ttotal: 6m 51s\tremaining: 1m 51s\n",
      "393:\tlearn: 0.2237170\ttotal: 6m 52s\tremaining: 1m 50s\n",
      "394:\tlearn: 0.2236083\ttotal: 6m 53s\tremaining: 1m 49s\n",
      "395:\tlearn: 0.2234761\ttotal: 6m 53s\tremaining: 1m 48s\n",
      "396:\tlearn: 0.2232830\ttotal: 6m 54s\tremaining: 1m 47s\n",
      "397:\tlearn: 0.2231424\ttotal: 6m 55s\tremaining: 1m 46s\n",
      "398:\tlearn: 0.2229407\ttotal: 6m 56s\tremaining: 1m 45s\n",
      "399:\tlearn: 0.2227232\ttotal: 6m 57s\tremaining: 1m 44s\n",
      "400:\tlearn: 0.2226168\ttotal: 6m 58s\tremaining: 1m 43s\n",
      "401:\tlearn: 0.2224781\ttotal: 6m 58s\tremaining: 1m 42s\n",
      "402:\tlearn: 0.2221992\ttotal: 6m 59s\tremaining: 1m 41s\n",
      "403:\tlearn: 0.2218160\ttotal: 7m\tremaining: 1m 39s\n",
      "404:\tlearn: 0.2215364\ttotal: 7m 1s\tremaining: 1m 38s\n",
      "405:\tlearn: 0.2213908\ttotal: 7m 2s\tremaining: 1m 37s\n",
      "406:\tlearn: 0.2211577\ttotal: 7m 3s\tremaining: 1m 36s\n",
      "407:\tlearn: 0.2210564\ttotal: 7m 3s\tremaining: 1m 35s\n",
      "408:\tlearn: 0.2209404\ttotal: 7m 4s\tremaining: 1m 34s\n",
      "409:\tlearn: 0.2206876\ttotal: 7m 5s\tremaining: 1m 33s\n",
      "410:\tlearn: 0.2204335\ttotal: 7m 6s\tremaining: 1m 32s\n",
      "411:\tlearn: 0.2201313\ttotal: 7m 7s\tremaining: 1m 31s\n",
      "412:\tlearn: 0.2198892\ttotal: 7m 8s\tremaining: 1m 30s\n",
      "413:\tlearn: 0.2196721\ttotal: 7m 9s\tremaining: 1m 29s\n",
      "414:\tlearn: 0.2195697\ttotal: 7m 9s\tremaining: 1m 28s\n",
      "415:\tlearn: 0.2194051\ttotal: 7m 10s\tremaining: 1m 26s\n",
      "416:\tlearn: 0.2190792\ttotal: 7m 11s\tremaining: 1m 25s\n",
      "417:\tlearn: 0.2188726\ttotal: 7m 12s\tremaining: 1m 24s\n",
      "418:\tlearn: 0.2187077\ttotal: 7m 13s\tremaining: 1m 23s\n",
      "419:\tlearn: 0.2184165\ttotal: 7m 14s\tremaining: 1m 22s\n",
      "420:\tlearn: 0.2181942\ttotal: 7m 14s\tremaining: 1m 21s\n",
      "421:\tlearn: 0.2179419\ttotal: 7m 15s\tremaining: 1m 20s\n",
      "422:\tlearn: 0.2178382\ttotal: 7m 16s\tremaining: 1m 19s\n",
      "423:\tlearn: 0.2175888\ttotal: 7m 17s\tremaining: 1m 18s\n",
      "424:\tlearn: 0.2172926\ttotal: 7m 18s\tremaining: 1m 17s\n",
      "425:\tlearn: 0.2171422\ttotal: 7m 19s\tremaining: 1m 16s\n",
      "426:\tlearn: 0.2169089\ttotal: 7m 19s\tremaining: 1m 15s\n",
      "427:\tlearn: 0.2168053\ttotal: 7m 20s\tremaining: 1m 14s\n",
      "428:\tlearn: 0.2165191\ttotal: 7m 21s\tremaining: 1m 13s\n",
      "429:\tlearn: 0.2163164\ttotal: 7m 22s\tremaining: 1m 12s\n",
      "430:\tlearn: 0.2160692\ttotal: 7m 23s\tremaining: 1m 10s\n",
      "431:\tlearn: 0.2157785\ttotal: 7m 24s\tremaining: 1m 9s\n",
      "432:\tlearn: 0.2156817\ttotal: 7m 24s\tremaining: 1m 8s\n",
      "433:\tlearn: 0.2154823\ttotal: 7m 25s\tremaining: 1m 7s\n",
      "434:\tlearn: 0.2153825\ttotal: 7m 26s\tremaining: 1m 6s\n",
      "435:\tlearn: 0.2152814\ttotal: 7m 27s\tremaining: 1m 5s\n",
      "436:\tlearn: 0.2150536\ttotal: 7m 28s\tremaining: 1m 4s\n",
      "437:\tlearn: 0.2148731\ttotal: 7m 29s\tremaining: 1m 3s\n",
      "438:\tlearn: 0.2147785\ttotal: 7m 30s\tremaining: 1m 2s\n",
      "439:\tlearn: 0.2146234\ttotal: 7m 30s\tremaining: 1m 1s\n",
      "440:\tlearn: 0.2143809\ttotal: 7m 31s\tremaining: 1m\n",
      "441:\tlearn: 0.2142566\ttotal: 7m 32s\tremaining: 59.4s\n",
      "442:\tlearn: 0.2140546\ttotal: 7m 33s\tremaining: 58.3s\n",
      "443:\tlearn: 0.2137883\ttotal: 7m 34s\tremaining: 57.3s\n",
      "444:\tlearn: 0.2136501\ttotal: 7m 35s\tremaining: 56.2s\n",
      "445:\tlearn: 0.2135534\ttotal: 7m 35s\tremaining: 55.2s\n",
      "446:\tlearn: 0.2134069\ttotal: 7m 36s\tremaining: 54.1s\n",
      "447:\tlearn: 0.2131608\ttotal: 7m 37s\tremaining: 53.1s\n",
      "448:\tlearn: 0.2128632\ttotal: 7m 38s\tremaining: 52.1s\n",
      "449:\tlearn: 0.2126211\ttotal: 7m 39s\tremaining: 51s\n",
      "450:\tlearn: 0.2125231\ttotal: 7m 40s\tremaining: 50s\n",
      "451:\tlearn: 0.2124283\ttotal: 7m 40s\tremaining: 48.9s\n",
      "452:\tlearn: 0.2122549\ttotal: 7m 41s\tremaining: 47.9s\n",
      "453:\tlearn: 0.2120470\ttotal: 7m 42s\tremaining: 46.9s\n",
      "454:\tlearn: 0.2119178\ttotal: 7m 43s\tremaining: 45.8s\n",
      "455:\tlearn: 0.2116839\ttotal: 7m 44s\tremaining: 44.8s\n",
      "456:\tlearn: 0.2115859\ttotal: 7m 45s\tremaining: 43.8s\n",
      "457:\tlearn: 0.2112046\ttotal: 7m 45s\tremaining: 42.7s\n",
      "458:\tlearn: 0.2111071\ttotal: 7m 46s\tremaining: 41.7s\n",
      "459:\tlearn: 0.2110113\ttotal: 7m 47s\tremaining: 40.7s\n",
      "460:\tlearn: 0.2109156\ttotal: 7m 48s\tremaining: 39.6s\n",
      "461:\tlearn: 0.2107529\ttotal: 7m 49s\tremaining: 38.6s\n",
      "462:\tlearn: 0.2105109\ttotal: 7m 50s\tremaining: 37.6s\n",
      "463:\tlearn: 0.2104132\ttotal: 7m 50s\tremaining: 36.5s\n",
      "464:\tlearn: 0.2103156\ttotal: 7m 51s\tremaining: 35.5s\n",
      "465:\tlearn: 0.2102217\ttotal: 7m 52s\tremaining: 34.5s\n",
      "466:\tlearn: 0.2100156\ttotal: 7m 53s\tremaining: 33.5s\n",
      "467:\tlearn: 0.2098098\ttotal: 7m 54s\tremaining: 32.4s\n",
      "468:\tlearn: 0.2097138\ttotal: 7m 55s\tremaining: 31.4s\n",
      "469:\tlearn: 0.2095848\ttotal: 7m 55s\tremaining: 30.4s\n",
      "470:\tlearn: 0.2094895\ttotal: 7m 56s\tremaining: 29.4s\n",
      "471:\tlearn: 0.2093339\ttotal: 7m 57s\tremaining: 28.3s\n",
      "472:\tlearn: 0.2091312\ttotal: 7m 58s\tremaining: 27.3s\n",
      "473:\tlearn: 0.2090406\ttotal: 7m 59s\tremaining: 26.3s\n",
      "474:\tlearn: 0.2088116\ttotal: 8m\tremaining: 25.3s\n",
      "475:\tlearn: 0.2085951\ttotal: 8m\tremaining: 24.2s\n",
      "476:\tlearn: 0.2083982\ttotal: 8m 1s\tremaining: 23.2s\n",
      "477:\tlearn: 0.2082487\ttotal: 8m 2s\tremaining: 22.2s\n",
      "478:\tlearn: 0.2080531\ttotal: 8m 3s\tremaining: 21.2s\n",
      "479:\tlearn: 0.2079636\ttotal: 8m 4s\tremaining: 20.2s\n",
      "480:\tlearn: 0.2077657\ttotal: 8m 5s\tremaining: 19.2s\n",
      "481:\tlearn: 0.2076481\ttotal: 8m 5s\tremaining: 18.1s\n",
      "482:\tlearn: 0.2074756\ttotal: 8m 6s\tremaining: 17.1s\n",
      "483:\tlearn: 0.2073107\ttotal: 8m 7s\tremaining: 16.1s\n",
      "484:\tlearn: 0.2071261\ttotal: 8m 8s\tremaining: 15.1s\n",
      "485:\tlearn: 0.2069619\ttotal: 8m 9s\tremaining: 14.1s\n",
      "486:\tlearn: 0.2066799\ttotal: 8m 10s\tremaining: 13.1s\n",
      "487:\tlearn: 0.2065886\ttotal: 8m 10s\tremaining: 12.1s\n",
      "488:\tlearn: 0.2063382\ttotal: 8m 11s\tremaining: 11.1s\n",
      "489:\tlearn: 0.2062011\ttotal: 8m 12s\tremaining: 10.1s\n",
      "490:\tlearn: 0.2061118\ttotal: 8m 13s\tremaining: 9.04s\n",
      "491:\tlearn: 0.2058992\ttotal: 8m 14s\tremaining: 8.04s\n",
      "492:\tlearn: 0.2056932\ttotal: 8m 15s\tremaining: 7.03s\n",
      "493:\tlearn: 0.2054760\ttotal: 8m 16s\tremaining: 6.02s\n",
      "494:\tlearn: 0.2053877\ttotal: 8m 16s\tremaining: 5.02s\n",
      "495:\tlearn: 0.2051902\ttotal: 8m 17s\tremaining: 4.01s\n",
      "496:\tlearn: 0.2050995\ttotal: 8m 18s\tremaining: 3.01s\n",
      "497:\tlearn: 0.2049826\ttotal: 8m 19s\tremaining: 2s\n",
      "498:\tlearn: 0.2047648\ttotal: 8m 20s\tremaining: 1s\n",
      "499:\tlearn: 0.2045147\ttotal: 8m 21s\tremaining: 0us\n",
      "[CV 4/5] END auto_class_weights=Balanced, iterations=500, random_state=12345;, score=0.748 total time= 8.5min\n",
      "Learning rate set to 0.12034\n",
      "0:\tlearn: 0.6410563\ttotal: 894ms\tremaining: 7m 26s\n",
      "1:\tlearn: 0.6039615\ttotal: 1.75s\tremaining: 7m 16s\n",
      "2:\tlearn: 0.5764136\ttotal: 2.61s\tremaining: 7m 12s\n",
      "3:\tlearn: 0.5630498\ttotal: 3.49s\tremaining: 7m 13s\n",
      "4:\tlearn: 0.5458049\ttotal: 4.35s\tremaining: 7m 10s\n",
      "5:\tlearn: 0.5384863\ttotal: 5.21s\tremaining: 7m 8s\n",
      "6:\tlearn: 0.5316855\ttotal: 6.07s\tremaining: 7m 7s\n",
      "7:\tlearn: 0.5238080\ttotal: 6.92s\tremaining: 7m 5s\n",
      "8:\tlearn: 0.5166215\ttotal: 7.77s\tremaining: 7m 4s\n",
      "9:\tlearn: 0.5102989\ttotal: 8.62s\tremaining: 7m 2s\n",
      "10:\tlearn: 0.5035095\ttotal: 9.46s\tremaining: 7m\n",
      "11:\tlearn: 0.4976570\ttotal: 10.3s\tremaining: 6m 59s\n",
      "12:\tlearn: 0.4915170\ttotal: 11.2s\tremaining: 6m 58s\n",
      "13:\tlearn: 0.4852245\ttotal: 12s\tremaining: 6m 57s\n",
      "14:\tlearn: 0.4795733\ttotal: 12.9s\tremaining: 6m 55s\n",
      "15:\tlearn: 0.4758106\ttotal: 13.7s\tremaining: 6m 55s\n",
      "16:\tlearn: 0.4718179\ttotal: 14.6s\tremaining: 6m 54s\n",
      "17:\tlearn: 0.4670724\ttotal: 15.4s\tremaining: 6m 53s\n",
      "18:\tlearn: 0.4637905\ttotal: 16.3s\tremaining: 6m 52s\n",
      "19:\tlearn: 0.4604334\ttotal: 17.1s\tremaining: 6m 51s\n",
      "20:\tlearn: 0.4582183\ttotal: 18s\tremaining: 6m 50s\n",
      "21:\tlearn: 0.4551552\ttotal: 18.8s\tremaining: 6m 49s\n",
      "22:\tlearn: 0.4535803\ttotal: 19.7s\tremaining: 6m 48s\n",
      "23:\tlearn: 0.4507815\ttotal: 20.6s\tremaining: 6m 47s\n",
      "24:\tlearn: 0.4476606\ttotal: 21.4s\tremaining: 6m 46s\n",
      "25:\tlearn: 0.4452461\ttotal: 22.2s\tremaining: 6m 45s\n",
      "26:\tlearn: 0.4433487\ttotal: 23.1s\tremaining: 6m 44s\n",
      "27:\tlearn: 0.4409376\ttotal: 23.9s\tremaining: 6m 43s\n",
      "28:\tlearn: 0.4384942\ttotal: 24.8s\tremaining: 6m 42s\n",
      "29:\tlearn: 0.4362595\ttotal: 25.6s\tremaining: 6m 41s\n",
      "30:\tlearn: 0.4343859\ttotal: 26.5s\tremaining: 6m 40s\n",
      "31:\tlearn: 0.4315031\ttotal: 27.3s\tremaining: 6m 39s\n",
      "32:\tlearn: 0.4289523\ttotal: 28.2s\tremaining: 6m 38s\n",
      "33:\tlearn: 0.4275220\ttotal: 29s\tremaining: 6m 37s\n",
      "34:\tlearn: 0.4248133\ttotal: 29.9s\tremaining: 6m 36s\n",
      "35:\tlearn: 0.4232252\ttotal: 30.7s\tremaining: 6m 35s\n",
      "36:\tlearn: 0.4214729\ttotal: 31.5s\tremaining: 6m 34s\n",
      "37:\tlearn: 0.4193537\ttotal: 32.4s\tremaining: 6m 33s\n",
      "38:\tlearn: 0.4174843\ttotal: 33.2s\tremaining: 6m 32s\n",
      "39:\tlearn: 0.4160104\ttotal: 34.1s\tremaining: 6m 32s\n",
      "40:\tlearn: 0.4148941\ttotal: 34.9s\tremaining: 6m 31s\n",
      "41:\tlearn: 0.4133730\ttotal: 35.8s\tremaining: 6m 30s\n",
      "42:\tlearn: 0.4113841\ttotal: 36.6s\tremaining: 6m 29s\n",
      "43:\tlearn: 0.4095328\ttotal: 37.5s\tremaining: 6m 28s\n",
      "44:\tlearn: 0.4081526\ttotal: 38.3s\tremaining: 6m 27s\n",
      "45:\tlearn: 0.4060640\ttotal: 39.1s\tremaining: 6m 26s\n",
      "46:\tlearn: 0.4040417\ttotal: 40s\tremaining: 6m 25s\n",
      "47:\tlearn: 0.4024040\ttotal: 40.9s\tremaining: 6m 24s\n",
      "48:\tlearn: 0.4013204\ttotal: 41.7s\tremaining: 6m 23s\n",
      "49:\tlearn: 0.4003971\ttotal: 42.5s\tremaining: 6m 22s\n",
      "50:\tlearn: 0.3982262\ttotal: 43.4s\tremaining: 6m 21s\n",
      "51:\tlearn: 0.3968724\ttotal: 44.2s\tremaining: 6m 21s\n",
      "52:\tlearn: 0.3954283\ttotal: 45.1s\tremaining: 6m 20s\n",
      "53:\tlearn: 0.3937598\ttotal: 45.9s\tremaining: 6m 19s\n",
      "54:\tlearn: 0.3919228\ttotal: 46.7s\tremaining: 6m 18s\n",
      "55:\tlearn: 0.3907527\ttotal: 47.6s\tremaining: 6m 17s\n",
      "56:\tlearn: 0.3895525\ttotal: 48.4s\tremaining: 6m 16s\n",
      "57:\tlearn: 0.3886867\ttotal: 49.3s\tremaining: 6m 15s\n",
      "58:\tlearn: 0.3876805\ttotal: 50.1s\tremaining: 6m 14s\n",
      "59:\tlearn: 0.3866257\ttotal: 51s\tremaining: 6m 13s\n",
      "60:\tlearn: 0.3858260\ttotal: 51.9s\tremaining: 6m 13s\n",
      "61:\tlearn: 0.3848390\ttotal: 52.8s\tremaining: 6m 13s\n",
      "62:\tlearn: 0.3838135\ttotal: 53.8s\tremaining: 6m 13s\n",
      "63:\tlearn: 0.3829415\ttotal: 54.7s\tremaining: 6m 12s\n",
      "64:\tlearn: 0.3822071\ttotal: 55.9s\tremaining: 6m 13s\n",
      "65:\tlearn: 0.3808127\ttotal: 57.1s\tremaining: 6m 15s\n",
      "66:\tlearn: 0.3797057\ttotal: 58.6s\tremaining: 6m 18s\n",
      "67:\tlearn: 0.3789044\ttotal: 60s\tremaining: 6m 21s\n",
      "68:\tlearn: 0.3779723\ttotal: 1m 1s\tremaining: 6m 23s\n",
      "69:\tlearn: 0.3774083\ttotal: 1m 2s\tremaining: 6m 25s\n",
      "70:\tlearn: 0.3765314\ttotal: 1m 3s\tremaining: 6m 25s\n",
      "71:\tlearn: 0.3758968\ttotal: 1m 4s\tremaining: 6m 25s\n",
      "72:\tlearn: 0.3745926\ttotal: 1m 6s\tremaining: 6m 26s\n",
      "73:\tlearn: 0.3739076\ttotal: 1m 7s\tremaining: 6m 26s\n",
      "74:\tlearn: 0.3725946\ttotal: 1m 8s\tremaining: 6m 26s\n",
      "75:\tlearn: 0.3717047\ttotal: 1m 9s\tremaining: 6m 29s\n",
      "76:\tlearn: 0.3708188\ttotal: 1m 11s\tremaining: 6m 31s\n",
      "77:\tlearn: 0.3695728\ttotal: 1m 12s\tremaining: 6m 32s\n",
      "78:\tlearn: 0.3688054\ttotal: 1m 13s\tremaining: 6m 32s\n",
      "79:\tlearn: 0.3678545\ttotal: 1m 14s\tremaining: 6m 32s\n",
      "80:\tlearn: 0.3670920\ttotal: 1m 15s\tremaining: 6m 32s\n",
      "81:\tlearn: 0.3661164\ttotal: 1m 16s\tremaining: 6m 31s\n",
      "82:\tlearn: 0.3651418\ttotal: 1m 17s\tremaining: 6m 31s\n",
      "83:\tlearn: 0.3638087\ttotal: 1m 18s\tremaining: 6m 29s\n",
      "84:\tlearn: 0.3626038\ttotal: 1m 19s\tremaining: 6m 28s\n",
      "85:\tlearn: 0.3618710\ttotal: 1m 20s\tremaining: 6m 29s\n",
      "86:\tlearn: 0.3611712\ttotal: 1m 21s\tremaining: 6m 28s\n",
      "87:\tlearn: 0.3603280\ttotal: 1m 22s\tremaining: 6m 27s\n",
      "88:\tlearn: 0.3595122\ttotal: 1m 23s\tremaining: 6m 26s\n",
      "89:\tlearn: 0.3586165\ttotal: 1m 24s\tremaining: 6m 25s\n",
      "90:\tlearn: 0.3576897\ttotal: 1m 25s\tremaining: 6m 23s\n",
      "91:\tlearn: 0.3551400\ttotal: 1m 26s\tremaining: 6m 22s\n",
      "92:\tlearn: 0.3538831\ttotal: 1m 27s\tremaining: 6m 21s\n",
      "93:\tlearn: 0.3529049\ttotal: 1m 27s\tremaining: 6m 19s\n",
      "94:\tlearn: 0.3518702\ttotal: 1m 28s\tremaining: 6m 18s\n",
      "95:\tlearn: 0.3509205\ttotal: 1m 29s\tremaining: 6m 17s\n",
      "96:\tlearn: 0.3500388\ttotal: 1m 30s\tremaining: 6m 16s\n",
      "97:\tlearn: 0.3490639\ttotal: 1m 31s\tremaining: 6m 14s\n",
      "98:\tlearn: 0.3481520\ttotal: 1m 32s\tremaining: 6m 13s\n",
      "99:\tlearn: 0.3473133\ttotal: 1m 33s\tremaining: 6m 12s\n",
      "100:\tlearn: 0.3464634\ttotal: 1m 33s\tremaining: 6m 10s\n",
      "101:\tlearn: 0.3454190\ttotal: 1m 34s\tremaining: 6m 9s\n",
      "102:\tlearn: 0.3431945\ttotal: 1m 35s\tremaining: 6m 8s\n",
      "103:\tlearn: 0.3424893\ttotal: 1m 36s\tremaining: 6m 8s\n",
      "104:\tlearn: 0.3416867\ttotal: 1m 37s\tremaining: 6m 7s\n",
      "105:\tlearn: 0.3408202\ttotal: 1m 39s\tremaining: 6m 8s\n",
      "106:\tlearn: 0.3398932\ttotal: 1m 40s\tremaining: 6m 9s\n",
      "107:\tlearn: 0.3388934\ttotal: 1m 41s\tremaining: 6m 9s\n",
      "108:\tlearn: 0.3381838\ttotal: 1m 43s\tremaining: 6m 10s\n",
      "109:\tlearn: 0.3371812\ttotal: 1m 44s\tremaining: 6m 8s\n",
      "110:\tlearn: 0.3361619\ttotal: 1m 44s\tremaining: 6m 7s\n",
      "111:\tlearn: 0.3354223\ttotal: 1m 45s\tremaining: 6m 6s\n",
      "112:\tlearn: 0.3346388\ttotal: 1m 46s\tremaining: 6m 5s\n",
      "113:\tlearn: 0.3339102\ttotal: 1m 47s\tremaining: 6m 4s\n",
      "114:\tlearn: 0.3331453\ttotal: 1m 48s\tremaining: 6m 3s\n",
      "115:\tlearn: 0.3323251\ttotal: 1m 49s\tremaining: 6m 2s\n",
      "116:\tlearn: 0.3313345\ttotal: 1m 50s\tremaining: 6m 1s\n",
      "117:\tlearn: 0.3306045\ttotal: 1m 51s\tremaining: 6m 1s\n",
      "118:\tlearn: 0.3290657\ttotal: 1m 52s\tremaining: 6m\n",
      "119:\tlearn: 0.3282961\ttotal: 1m 53s\tremaining: 5m 59s\n",
      "120:\tlearn: 0.3275512\ttotal: 1m 54s\tremaining: 5m 58s\n",
      "121:\tlearn: 0.3266054\ttotal: 1m 55s\tremaining: 5m 57s\n",
      "122:\tlearn: 0.3258280\ttotal: 1m 56s\tremaining: 5m 56s\n",
      "123:\tlearn: 0.3251889\ttotal: 1m 57s\tremaining: 5m 56s\n",
      "124:\tlearn: 0.3243244\ttotal: 1m 58s\tremaining: 5m 55s\n",
      "125:\tlearn: 0.3235919\ttotal: 1m 59s\tremaining: 5m 54s\n",
      "126:\tlearn: 0.3229100\ttotal: 2m\tremaining: 5m 53s\n",
      "127:\tlearn: 0.3219469\ttotal: 2m 1s\tremaining: 5m 52s\n",
      "128:\tlearn: 0.3213524\ttotal: 2m 2s\tremaining: 5m 51s\n",
      "129:\tlearn: 0.3208128\ttotal: 2m 3s\tremaining: 5m 50s\n",
      "130:\tlearn: 0.3202012\ttotal: 2m 4s\tremaining: 5m 49s\n",
      "131:\tlearn: 0.3195173\ttotal: 2m 4s\tremaining: 5m 48s\n",
      "132:\tlearn: 0.3185263\ttotal: 2m 5s\tremaining: 5m 46s\n",
      "133:\tlearn: 0.3179736\ttotal: 2m 6s\tremaining: 5m 46s\n",
      "134:\tlearn: 0.3173272\ttotal: 2m 7s\tremaining: 5m 45s\n",
      "135:\tlearn: 0.3165308\ttotal: 2m 8s\tremaining: 5m 44s\n",
      "136:\tlearn: 0.3153933\ttotal: 2m 9s\tremaining: 5m 42s\n",
      "137:\tlearn: 0.3148313\ttotal: 2m 10s\tremaining: 5m 41s\n",
      "138:\tlearn: 0.3135200\ttotal: 2m 11s\tremaining: 5m 40s\n",
      "139:\tlearn: 0.3127706\ttotal: 2m 12s\tremaining: 5m 39s\n",
      "140:\tlearn: 0.3122495\ttotal: 2m 12s\tremaining: 5m 38s\n",
      "141:\tlearn: 0.3114266\ttotal: 2m 14s\tremaining: 5m 38s\n",
      "142:\tlearn: 0.3108534\ttotal: 2m 14s\tremaining: 5m 36s\n",
      "143:\tlearn: 0.3100877\ttotal: 2m 15s\tremaining: 5m 35s\n",
      "144:\tlearn: 0.3095526\ttotal: 2m 16s\tremaining: 5m 35s\n",
      "145:\tlearn: 0.3090519\ttotal: 2m 17s\tremaining: 5m 34s\n",
      "146:\tlearn: 0.3081773\ttotal: 2m 18s\tremaining: 5m 33s\n",
      "147:\tlearn: 0.3076181\ttotal: 2m 19s\tremaining: 5m 31s\n",
      "148:\tlearn: 0.3071574\ttotal: 2m 20s\tremaining: 5m 30s\n",
      "149:\tlearn: 0.3065354\ttotal: 2m 21s\tremaining: 5m 29s\n",
      "150:\tlearn: 0.3057780\ttotal: 2m 22s\tremaining: 5m 28s\n",
      "151:\tlearn: 0.3050860\ttotal: 2m 23s\tremaining: 5m 27s\n",
      "152:\tlearn: 0.3045863\ttotal: 2m 24s\tremaining: 5m 26s\n",
      "153:\tlearn: 0.3040299\ttotal: 2m 24s\tremaining: 5m 25s\n",
      "154:\tlearn: 0.3034478\ttotal: 2m 25s\tremaining: 5m 24s\n",
      "155:\tlearn: 0.3029600\ttotal: 2m 26s\tremaining: 5m 23s\n",
      "156:\tlearn: 0.3023844\ttotal: 2m 27s\tremaining: 5m 22s\n",
      "157:\tlearn: 0.3017955\ttotal: 2m 28s\tremaining: 5m 22s\n",
      "158:\tlearn: 0.3011959\ttotal: 2m 29s\tremaining: 5m 21s\n",
      "159:\tlearn: 0.3006349\ttotal: 2m 30s\tremaining: 5m 20s\n",
      "160:\tlearn: 0.2999702\ttotal: 2m 31s\tremaining: 5m 19s\n",
      "161:\tlearn: 0.2994523\ttotal: 2m 32s\tremaining: 5m 18s\n",
      "162:\tlearn: 0.2990319\ttotal: 2m 33s\tremaining: 5m 17s\n",
      "163:\tlearn: 0.2984107\ttotal: 2m 34s\tremaining: 5m 16s\n",
      "164:\tlearn: 0.2979072\ttotal: 2m 35s\tremaining: 5m 15s\n",
      "165:\tlearn: 0.2975403\ttotal: 2m 36s\tremaining: 5m 14s\n",
      "166:\tlearn: 0.2970048\ttotal: 2m 37s\tremaining: 5m 13s\n",
      "167:\tlearn: 0.2962812\ttotal: 2m 38s\tremaining: 5m 12s\n",
      "168:\tlearn: 0.2957851\ttotal: 2m 39s\tremaining: 5m 11s\n",
      "169:\tlearn: 0.2951943\ttotal: 2m 39s\tremaining: 5m 10s\n",
      "170:\tlearn: 0.2947086\ttotal: 2m 40s\tremaining: 5m 9s\n",
      "171:\tlearn: 0.2942670\ttotal: 2m 41s\tremaining: 5m 8s\n",
      "172:\tlearn: 0.2938934\ttotal: 2m 42s\tremaining: 5m 7s\n",
      "173:\tlearn: 0.2934143\ttotal: 2m 43s\tremaining: 5m 5s\n",
      "174:\tlearn: 0.2928790\ttotal: 2m 44s\tremaining: 5m 4s\n",
      "175:\tlearn: 0.2924487\ttotal: 2m 44s\tremaining: 5m 3s\n",
      "176:\tlearn: 0.2919180\ttotal: 2m 45s\tremaining: 5m 2s\n",
      "177:\tlearn: 0.2914748\ttotal: 2m 46s\tremaining: 5m 1s\n",
      "178:\tlearn: 0.2910490\ttotal: 2m 47s\tremaining: 5m\n",
      "179:\tlearn: 0.2904638\ttotal: 2m 48s\tremaining: 4m 59s\n",
      "180:\tlearn: 0.2900206\ttotal: 2m 49s\tremaining: 4m 59s\n",
      "181:\tlearn: 0.2896521\ttotal: 2m 50s\tremaining: 4m 58s\n",
      "182:\tlearn: 0.2893442\ttotal: 2m 51s\tremaining: 4m 57s\n",
      "183:\tlearn: 0.2889826\ttotal: 2m 52s\tremaining: 4m 57s\n",
      "184:\tlearn: 0.2884591\ttotal: 2m 54s\tremaining: 4m 56s\n",
      "185:\tlearn: 0.2879268\ttotal: 2m 55s\tremaining: 4m 56s\n",
      "186:\tlearn: 0.2872706\ttotal: 2m 56s\tremaining: 4m 56s\n",
      "187:\tlearn: 0.2868762\ttotal: 2m 58s\tremaining: 4m 56s\n",
      "188:\tlearn: 0.2862647\ttotal: 2m 59s\tremaining: 4m 55s\n",
      "189:\tlearn: 0.2858259\ttotal: 3m 1s\tremaining: 4m 55s\n",
      "190:\tlearn: 0.2850803\ttotal: 3m 2s\tremaining: 4m 55s\n",
      "191:\tlearn: 0.2845271\ttotal: 3m 4s\tremaining: 4m 55s\n",
      "192:\tlearn: 0.2839901\ttotal: 3m 5s\tremaining: 4m 55s\n",
      "193:\tlearn: 0.2835895\ttotal: 3m 6s\tremaining: 4m 54s\n",
      "194:\tlearn: 0.2832294\ttotal: 3m 8s\tremaining: 4m 54s\n",
      "195:\tlearn: 0.2827288\ttotal: 3m 9s\tremaining: 4m 53s\n",
      "196:\tlearn: 0.2823047\ttotal: 3m 10s\tremaining: 4m 53s\n",
      "197:\tlearn: 0.2819153\ttotal: 3m 11s\tremaining: 4m 52s\n",
      "198:\tlearn: 0.2813031\ttotal: 3m 12s\tremaining: 4m 51s\n",
      "199:\tlearn: 0.2808782\ttotal: 3m 13s\tremaining: 4m 50s\n",
      "200:\tlearn: 0.2804968\ttotal: 3m 14s\tremaining: 4m 49s\n",
      "201:\tlearn: 0.2801812\ttotal: 3m 16s\tremaining: 4m 49s\n",
      "202:\tlearn: 0.2797923\ttotal: 3m 17s\tremaining: 4m 48s\n",
      "203:\tlearn: 0.2792914\ttotal: 3m 19s\tremaining: 4m 48s\n",
      "204:\tlearn: 0.2789520\ttotal: 3m 20s\tremaining: 4m 47s\n",
      "205:\tlearn: 0.2784663\ttotal: 3m 21s\tremaining: 4m 46s\n",
      "206:\tlearn: 0.2780797\ttotal: 3m 22s\tremaining: 4m 46s\n",
      "207:\tlearn: 0.2776341\ttotal: 3m 23s\tremaining: 4m 45s\n",
      "208:\tlearn: 0.2771815\ttotal: 3m 24s\tremaining: 4m 44s\n",
      "209:\tlearn: 0.2767250\ttotal: 3m 25s\tremaining: 4m 43s\n",
      "210:\tlearn: 0.2762703\ttotal: 3m 26s\tremaining: 4m 42s\n",
      "211:\tlearn: 0.2758918\ttotal: 3m 27s\tremaining: 4m 41s\n",
      "212:\tlearn: 0.2755258\ttotal: 3m 28s\tremaining: 4m 41s\n",
      "213:\tlearn: 0.2746906\ttotal: 3m 29s\tremaining: 4m 40s\n",
      "214:\tlearn: 0.2744293\ttotal: 3m 31s\tremaining: 4m 39s\n",
      "215:\tlearn: 0.2738795\ttotal: 3m 32s\tremaining: 4m 38s\n",
      "216:\tlearn: 0.2736006\ttotal: 3m 33s\tremaining: 4m 37s\n",
      "217:\tlearn: 0.2732032\ttotal: 3m 34s\tremaining: 4m 37s\n",
      "218:\tlearn: 0.2727865\ttotal: 3m 35s\tremaining: 4m 36s\n",
      "219:\tlearn: 0.2723431\ttotal: 3m 36s\tremaining: 4m 35s\n",
      "220:\tlearn: 0.2719138\ttotal: 3m 37s\tremaining: 4m 34s\n",
      "221:\tlearn: 0.2716375\ttotal: 3m 38s\tremaining: 4m 33s\n",
      "222:\tlearn: 0.2713941\ttotal: 3m 39s\tremaining: 4m 32s\n",
      "223:\tlearn: 0.2710027\ttotal: 3m 40s\tremaining: 4m 31s\n",
      "224:\tlearn: 0.2705426\ttotal: 3m 41s\tremaining: 4m 30s\n",
      "225:\tlearn: 0.2701354\ttotal: 3m 42s\tremaining: 4m 29s\n",
      "226:\tlearn: 0.2697411\ttotal: 3m 43s\tremaining: 4m 28s\n",
      "227:\tlearn: 0.2693938\ttotal: 3m 43s\tremaining: 4m 27s\n",
      "228:\tlearn: 0.2689817\ttotal: 3m 44s\tremaining: 4m 26s\n",
      "229:\tlearn: 0.2686244\ttotal: 3m 45s\tremaining: 4m 25s\n",
      "230:\tlearn: 0.2682235\ttotal: 3m 46s\tremaining: 4m 23s\n",
      "231:\tlearn: 0.2677711\ttotal: 3m 47s\tremaining: 4m 22s\n",
      "232:\tlearn: 0.2673500\ttotal: 3m 48s\tremaining: 4m 21s\n",
      "233:\tlearn: 0.2668757\ttotal: 3m 49s\tremaining: 4m 20s\n",
      "234:\tlearn: 0.2665725\ttotal: 3m 50s\tremaining: 4m 19s\n",
      "235:\tlearn: 0.2662999\ttotal: 3m 51s\tremaining: 4m 18s\n",
      "236:\tlearn: 0.2660769\ttotal: 3m 52s\tremaining: 4m 17s\n",
      "237:\tlearn: 0.2656104\ttotal: 3m 52s\tremaining: 4m 16s\n",
      "238:\tlearn: 0.2652739\ttotal: 3m 53s\tremaining: 4m 15s\n",
      "239:\tlearn: 0.2649459\ttotal: 3m 54s\tremaining: 4m 14s\n",
      "240:\tlearn: 0.2647146\ttotal: 3m 55s\tremaining: 4m 13s\n",
      "241:\tlearn: 0.2639879\ttotal: 3m 56s\tremaining: 4m 12s\n",
      "242:\tlearn: 0.2637838\ttotal: 3m 57s\tremaining: 4m 11s\n",
      "243:\tlearn: 0.2631858\ttotal: 3m 58s\tremaining: 4m 10s\n",
      "244:\tlearn: 0.2627805\ttotal: 3m 59s\tremaining: 4m 9s\n",
      "245:\tlearn: 0.2625739\ttotal: 4m\tremaining: 4m 7s\n",
      "246:\tlearn: 0.2622977\ttotal: 4m 1s\tremaining: 4m 6s\n",
      "247:\tlearn: 0.2619145\ttotal: 4m 2s\tremaining: 4m 5s\n",
      "248:\tlearn: 0.2616210\ttotal: 4m 3s\tremaining: 4m 5s\n",
      "249:\tlearn: 0.2612657\ttotal: 4m 4s\tremaining: 4m 4s\n",
      "250:\tlearn: 0.2610430\ttotal: 4m 4s\tremaining: 4m 2s\n",
      "251:\tlearn: 0.2606348\ttotal: 4m 5s\tremaining: 4m 1s\n",
      "252:\tlearn: 0.2602931\ttotal: 4m 6s\tremaining: 4m\n",
      "253:\tlearn: 0.2599402\ttotal: 4m 7s\tremaining: 3m 59s\n",
      "254:\tlearn: 0.2597079\ttotal: 4m 8s\tremaining: 3m 58s\n",
      "255:\tlearn: 0.2593816\ttotal: 4m 9s\tremaining: 3m 57s\n",
      "256:\tlearn: 0.2589696\ttotal: 4m 10s\tremaining: 3m 56s\n",
      "257:\tlearn: 0.2587810\ttotal: 4m 11s\tremaining: 3m 55s\n",
      "258:\tlearn: 0.2584292\ttotal: 4m 12s\tremaining: 3m 54s\n",
      "259:\tlearn: 0.2580802\ttotal: 4m 12s\tremaining: 3m 53s\n",
      "260:\tlearn: 0.2578103\ttotal: 4m 13s\tremaining: 3m 52s\n",
      "261:\tlearn: 0.2572223\ttotal: 4m 14s\tremaining: 3m 51s\n",
      "262:\tlearn: 0.2569497\ttotal: 4m 15s\tremaining: 3m 50s\n",
      "263:\tlearn: 0.2566066\ttotal: 4m 16s\tremaining: 3m 49s\n",
      "264:\tlearn: 0.2564054\ttotal: 4m 17s\tremaining: 3m 48s\n",
      "265:\tlearn: 0.2560371\ttotal: 4m 18s\tremaining: 3m 47s\n",
      "266:\tlearn: 0.2556846\ttotal: 4m 19s\tremaining: 3m 46s\n",
      "267:\tlearn: 0.2554029\ttotal: 4m 19s\tremaining: 3m 44s\n",
      "268:\tlearn: 0.2551167\ttotal: 4m 20s\tremaining: 3m 43s\n",
      "269:\tlearn: 0.2548004\ttotal: 4m 21s\tremaining: 3m 42s\n",
      "270:\tlearn: 0.2544936\ttotal: 4m 22s\tremaining: 3m 41s\n",
      "271:\tlearn: 0.2541718\ttotal: 4m 23s\tremaining: 3m 41s\n",
      "272:\tlearn: 0.2540006\ttotal: 4m 24s\tremaining: 3m 40s\n",
      "273:\tlearn: 0.2536303\ttotal: 4m 25s\tremaining: 3m 39s\n",
      "274:\tlearn: 0.2531898\ttotal: 4m 26s\tremaining: 3m 38s\n",
      "275:\tlearn: 0.2529500\ttotal: 4m 27s\tremaining: 3m 37s\n",
      "276:\tlearn: 0.2525736\ttotal: 4m 28s\tremaining: 3m 36s\n",
      "277:\tlearn: 0.2522457\ttotal: 4m 29s\tremaining: 3m 35s\n",
      "278:\tlearn: 0.2518682\ttotal: 4m 30s\tremaining: 3m 34s\n",
      "279:\tlearn: 0.2515184\ttotal: 4m 31s\tremaining: 3m 33s\n",
      "280:\tlearn: 0.2512109\ttotal: 4m 32s\tremaining: 3m 32s\n",
      "281:\tlearn: 0.2509482\ttotal: 4m 33s\tremaining: 3m 31s\n",
      "282:\tlearn: 0.2506087\ttotal: 4m 34s\tremaining: 3m 30s\n",
      "283:\tlearn: 0.2504507\ttotal: 4m 35s\tremaining: 3m 29s\n",
      "284:\tlearn: 0.2502675\ttotal: 4m 37s\tremaining: 3m 29s\n",
      "285:\tlearn: 0.2499525\ttotal: 4m 38s\tremaining: 3m 28s\n",
      "286:\tlearn: 0.2495388\ttotal: 4m 39s\tremaining: 3m 27s\n",
      "287:\tlearn: 0.2492208\ttotal: 4m 40s\tremaining: 3m 26s\n",
      "288:\tlearn: 0.2486270\ttotal: 4m 41s\tremaining: 3m 25s\n",
      "289:\tlearn: 0.2484201\ttotal: 4m 42s\tremaining: 3m 24s\n",
      "290:\tlearn: 0.2482382\ttotal: 4m 43s\tremaining: 3m 23s\n",
      "291:\tlearn: 0.2479890\ttotal: 4m 44s\tremaining: 3m 22s\n",
      "292:\tlearn: 0.2477815\ttotal: 4m 45s\tremaining: 3m 21s\n",
      "293:\tlearn: 0.2475085\ttotal: 4m 45s\tremaining: 3m 20s\n",
      "294:\tlearn: 0.2469394\ttotal: 4m 46s\tremaining: 3m 19s\n",
      "295:\tlearn: 0.2467286\ttotal: 4m 47s\tremaining: 3m 18s\n",
      "296:\tlearn: 0.2465732\ttotal: 4m 48s\tremaining: 3m 17s\n",
      "297:\tlearn: 0.2460603\ttotal: 4m 49s\tremaining: 3m 16s\n",
      "298:\tlearn: 0.2458804\ttotal: 4m 50s\tremaining: 3m 15s\n",
      "299:\tlearn: 0.2456111\ttotal: 4m 51s\tremaining: 3m 14s\n",
      "300:\tlearn: 0.2453055\ttotal: 4m 52s\tremaining: 3m 13s\n",
      "301:\tlearn: 0.2451052\ttotal: 4m 53s\tremaining: 3m 12s\n",
      "302:\tlearn: 0.2448399\ttotal: 4m 54s\tremaining: 3m 11s\n",
      "303:\tlearn: 0.2445568\ttotal: 4m 55s\tremaining: 3m 10s\n",
      "304:\tlearn: 0.2442860\ttotal: 4m 56s\tremaining: 3m 9s\n",
      "305:\tlearn: 0.2439951\ttotal: 4m 57s\tremaining: 3m 8s\n",
      "306:\tlearn: 0.2437939\ttotal: 4m 58s\tremaining: 3m 7s\n",
      "307:\tlearn: 0.2435525\ttotal: 4m 59s\tremaining: 3m 6s\n",
      "308:\tlearn: 0.2432335\ttotal: 5m\tremaining: 3m 5s\n",
      "309:\tlearn: 0.2428856\ttotal: 5m\tremaining: 3m 4s\n",
      "310:\tlearn: 0.2426788\ttotal: 5m 1s\tremaining: 3m 3s\n",
      "311:\tlearn: 0.2422925\ttotal: 5m 2s\tremaining: 3m 2s\n",
      "312:\tlearn: 0.2419856\ttotal: 5m 3s\tremaining: 3m 1s\n",
      "313:\tlearn: 0.2416979\ttotal: 5m 4s\tremaining: 3m\n",
      "314:\tlearn: 0.2415604\ttotal: 5m 5s\tremaining: 2m 59s\n",
      "315:\tlearn: 0.2413035\ttotal: 5m 5s\tremaining: 2m 58s\n",
      "316:\tlearn: 0.2410423\ttotal: 5m 6s\tremaining: 2m 57s\n",
      "317:\tlearn: 0.2408351\ttotal: 5m 7s\tremaining: 2m 56s\n",
      "318:\tlearn: 0.2405858\ttotal: 5m 8s\tremaining: 2m 55s\n",
      "319:\tlearn: 0.2402650\ttotal: 5m 9s\tremaining: 2m 54s\n",
      "320:\tlearn: 0.2400289\ttotal: 5m 10s\tremaining: 2m 53s\n",
      "321:\tlearn: 0.2396935\ttotal: 5m 11s\tremaining: 2m 52s\n",
      "322:\tlearn: 0.2394770\ttotal: 5m 12s\tremaining: 2m 51s\n",
      "323:\tlearn: 0.2391741\ttotal: 5m 12s\tremaining: 2m 50s\n",
      "324:\tlearn: 0.2388861\ttotal: 5m 13s\tremaining: 2m 48s\n",
      "325:\tlearn: 0.2386562\ttotal: 5m 14s\tremaining: 2m 47s\n",
      "326:\tlearn: 0.2383098\ttotal: 5m 15s\tremaining: 2m 46s\n",
      "327:\tlearn: 0.2381267\ttotal: 5m 16s\tremaining: 2m 45s\n",
      "328:\tlearn: 0.2379930\ttotal: 5m 17s\tremaining: 2m 44s\n",
      "329:\tlearn: 0.2376796\ttotal: 5m 18s\tremaining: 2m 43s\n",
      "330:\tlearn: 0.2373951\ttotal: 5m 18s\tremaining: 2m 42s\n",
      "331:\tlearn: 0.2371386\ttotal: 5m 19s\tremaining: 2m 41s\n",
      "332:\tlearn: 0.2368726\ttotal: 5m 20s\tremaining: 2m 40s\n",
      "333:\tlearn: 0.2366124\ttotal: 5m 21s\tremaining: 2m 39s\n",
      "334:\tlearn: 0.2363893\ttotal: 5m 22s\tremaining: 2m 38s\n",
      "335:\tlearn: 0.2361636\ttotal: 5m 23s\tremaining: 2m 37s\n",
      "336:\tlearn: 0.2358778\ttotal: 5m 24s\tremaining: 2m 36s\n",
      "337:\tlearn: 0.2355341\ttotal: 5m 25s\tremaining: 2m 35s\n",
      "338:\tlearn: 0.2353645\ttotal: 5m 26s\tremaining: 2m 34s\n",
      "339:\tlearn: 0.2351033\ttotal: 5m 26s\tremaining: 2m 33s\n",
      "340:\tlearn: 0.2348390\ttotal: 5m 27s\tremaining: 2m 32s\n",
      "341:\tlearn: 0.2346017\ttotal: 5m 28s\tremaining: 2m 31s\n",
      "342:\tlearn: 0.2343268\ttotal: 5m 29s\tremaining: 2m 30s\n",
      "343:\tlearn: 0.2341083\ttotal: 5m 30s\tremaining: 2m 29s\n",
      "344:\tlearn: 0.2339792\ttotal: 5m 31s\tremaining: 2m 28s\n",
      "345:\tlearn: 0.2333229\ttotal: 5m 32s\tremaining: 2m 27s\n",
      "346:\tlearn: 0.2330390\ttotal: 5m 33s\tremaining: 2m 26s\n",
      "347:\tlearn: 0.2328837\ttotal: 5m 34s\tremaining: 2m 25s\n",
      "348:\tlearn: 0.2326143\ttotal: 5m 34s\tremaining: 2m 24s\n",
      "349:\tlearn: 0.2324916\ttotal: 5m 35s\tremaining: 2m 23s\n",
      "350:\tlearn: 0.2322072\ttotal: 5m 36s\tremaining: 2m 22s\n",
      "351:\tlearn: 0.2320614\ttotal: 5m 37s\tremaining: 2m 21s\n",
      "352:\tlearn: 0.2317809\ttotal: 5m 38s\tremaining: 2m 20s\n",
      "353:\tlearn: 0.2315920\ttotal: 5m 39s\tremaining: 2m 20s\n",
      "354:\tlearn: 0.2313606\ttotal: 5m 40s\tremaining: 2m 19s\n",
      "355:\tlearn: 0.2311099\ttotal: 5m 41s\tremaining: 2m 18s\n",
      "356:\tlearn: 0.2308187\ttotal: 5m 42s\tremaining: 2m 17s\n",
      "357:\tlearn: 0.2306546\ttotal: 5m 43s\tremaining: 2m 16s\n",
      "358:\tlearn: 0.2303623\ttotal: 5m 43s\tremaining: 2m 15s\n",
      "359:\tlearn: 0.2300242\ttotal: 5m 44s\tremaining: 2m 14s\n",
      "360:\tlearn: 0.2299037\ttotal: 5m 45s\tremaining: 2m 13s\n",
      "361:\tlearn: 0.2295951\ttotal: 5m 46s\tremaining: 2m 12s\n",
      "362:\tlearn: 0.2294779\ttotal: 5m 47s\tremaining: 2m 11s\n",
      "363:\tlearn: 0.2292378\ttotal: 5m 48s\tremaining: 2m 10s\n",
      "364:\tlearn: 0.2289000\ttotal: 5m 49s\tremaining: 2m 9s\n",
      "365:\tlearn: 0.2287113\ttotal: 5m 49s\tremaining: 2m 8s\n",
      "366:\tlearn: 0.2284221\ttotal: 5m 50s\tremaining: 2m 7s\n",
      "367:\tlearn: 0.2281615\ttotal: 5m 51s\tremaining: 2m 6s\n",
      "368:\tlearn: 0.2280501\ttotal: 5m 52s\tremaining: 2m 5s\n",
      "369:\tlearn: 0.2275172\ttotal: 5m 53s\tremaining: 2m 4s\n",
      "370:\tlearn: 0.2273570\ttotal: 5m 54s\tremaining: 2m 3s\n",
      "371:\tlearn: 0.2271476\ttotal: 5m 55s\tremaining: 2m 2s\n",
      "372:\tlearn: 0.2269375\ttotal: 5m 55s\tremaining: 2m 1s\n",
      "373:\tlearn: 0.2266884\ttotal: 5m 56s\tremaining: 2m\n",
      "374:\tlearn: 0.2263971\ttotal: 5m 57s\tremaining: 1m 59s\n",
      "375:\tlearn: 0.2261717\ttotal: 5m 58s\tremaining: 1m 58s\n",
      "376:\tlearn: 0.2258508\ttotal: 5m 59s\tremaining: 1m 57s\n",
      "377:\tlearn: 0.2255858\ttotal: 6m\tremaining: 1m 56s\n",
      "378:\tlearn: 0.2254489\ttotal: 6m 1s\tremaining: 1m 55s\n",
      "379:\tlearn: 0.2250935\ttotal: 6m 2s\tremaining: 1m 54s\n",
      "380:\tlearn: 0.2249760\ttotal: 6m 2s\tremaining: 1m 53s\n",
      "381:\tlearn: 0.2247234\ttotal: 6m 3s\tremaining: 1m 52s\n",
      "382:\tlearn: 0.2244765\ttotal: 6m 4s\tremaining: 1m 51s\n",
      "383:\tlearn: 0.2242396\ttotal: 6m 5s\tremaining: 1m 50s\n",
      "384:\tlearn: 0.2240454\ttotal: 6m 6s\tremaining: 1m 49s\n",
      "385:\tlearn: 0.2237752\ttotal: 6m 7s\tremaining: 1m 48s\n",
      "386:\tlearn: 0.2235104\ttotal: 6m 8s\tremaining: 1m 47s\n",
      "387:\tlearn: 0.2233992\ttotal: 6m 9s\tremaining: 1m 46s\n",
      "388:\tlearn: 0.2231187\ttotal: 6m 10s\tremaining: 1m 45s\n",
      "389:\tlearn: 0.2229339\ttotal: 6m 11s\tremaining: 1m 44s\n",
      "390:\tlearn: 0.2226758\ttotal: 6m 12s\tremaining: 1m 43s\n",
      "391:\tlearn: 0.2225038\ttotal: 6m 13s\tremaining: 1m 42s\n",
      "392:\tlearn: 0.2223484\ttotal: 6m 14s\tremaining: 1m 41s\n",
      "393:\tlearn: 0.2222372\ttotal: 6m 15s\tremaining: 1m 41s\n",
      "394:\tlearn: 0.2219368\ttotal: 6m 16s\tremaining: 1m 40s\n",
      "395:\tlearn: 0.2218283\ttotal: 6m 17s\tremaining: 1m 39s\n",
      "396:\tlearn: 0.2215840\ttotal: 6m 18s\tremaining: 1m 38s\n",
      "397:\tlearn: 0.2213622\ttotal: 6m 20s\tremaining: 1m 37s\n",
      "398:\tlearn: 0.2211322\ttotal: 6m 21s\tremaining: 1m 36s\n",
      "399:\tlearn: 0.2209974\ttotal: 6m 22s\tremaining: 1m 35s\n",
      "400:\tlearn: 0.2208160\ttotal: 6m 23s\tremaining: 1m 34s\n",
      "401:\tlearn: 0.2206430\ttotal: 6m 24s\tremaining: 1m 33s\n",
      "402:\tlearn: 0.2203662\ttotal: 6m 24s\tremaining: 1m 32s\n",
      "403:\tlearn: 0.2201905\ttotal: 6m 25s\tremaining: 1m 31s\n",
      "404:\tlearn: 0.2199516\ttotal: 6m 26s\tremaining: 1m 30s\n",
      "405:\tlearn: 0.2198440\ttotal: 6m 27s\tremaining: 1m 29s\n",
      "406:\tlearn: 0.2195544\ttotal: 6m 28s\tremaining: 1m 28s\n",
      "407:\tlearn: 0.2193643\ttotal: 6m 29s\tremaining: 1m 27s\n",
      "408:\tlearn: 0.2189164\ttotal: 6m 30s\tremaining: 1m 26s\n",
      "409:\tlearn: 0.2187195\ttotal: 6m 31s\tremaining: 1m 25s\n",
      "410:\tlearn: 0.2184662\ttotal: 6m 31s\tremaining: 1m 24s\n",
      "411:\tlearn: 0.2181644\ttotal: 6m 32s\tremaining: 1m 23s\n",
      "412:\tlearn: 0.2180577\ttotal: 6m 33s\tremaining: 1m 22s\n",
      "413:\tlearn: 0.2178298\ttotal: 6m 34s\tremaining: 1m 21s\n",
      "414:\tlearn: 0.2176851\ttotal: 6m 35s\tremaining: 1m 20s\n",
      "415:\tlearn: 0.2175340\ttotal: 6m 36s\tremaining: 1m 20s\n",
      "416:\tlearn: 0.2173000\ttotal: 6m 37s\tremaining: 1m 19s\n",
      "417:\tlearn: 0.2170921\ttotal: 6m 38s\tremaining: 1m 18s\n",
      "418:\tlearn: 0.2169573\ttotal: 6m 38s\tremaining: 1m 17s\n",
      "419:\tlearn: 0.2167669\ttotal: 6m 39s\tremaining: 1m 16s\n",
      "420:\tlearn: 0.2166615\ttotal: 6m 40s\tremaining: 1m 15s\n",
      "421:\tlearn: 0.2165466\ttotal: 6m 41s\tremaining: 1m 14s\n",
      "422:\tlearn: 0.2163712\ttotal: 6m 42s\tremaining: 1m 13s\n",
      "423:\tlearn: 0.2162688\ttotal: 6m 43s\tremaining: 1m 12s\n",
      "424:\tlearn: 0.2161465\ttotal: 6m 44s\tremaining: 1m 11s\n",
      "425:\tlearn: 0.2159337\ttotal: 6m 45s\tremaining: 1m 10s\n",
      "426:\tlearn: 0.2156739\ttotal: 6m 46s\tremaining: 1m 9s\n",
      "427:\tlearn: 0.2155729\ttotal: 6m 47s\tremaining: 1m 8s\n",
      "428:\tlearn: 0.2152846\ttotal: 6m 48s\tremaining: 1m 7s\n",
      "429:\tlearn: 0.2150566\ttotal: 6m 49s\tremaining: 1m 6s\n",
      "430:\tlearn: 0.2149562\ttotal: 6m 50s\tremaining: 1m 5s\n",
      "431:\tlearn: 0.2148088\ttotal: 6m 51s\tremaining: 1m 4s\n",
      "432:\tlearn: 0.2146146\ttotal: 6m 52s\tremaining: 1m 3s\n",
      "433:\tlearn: 0.2143963\ttotal: 6m 53s\tremaining: 1m 2s\n",
      "434:\tlearn: 0.2141584\ttotal: 6m 54s\tremaining: 1m 1s\n",
      "435:\tlearn: 0.2140245\ttotal: 6m 55s\tremaining: 1m\n",
      "436:\tlearn: 0.2138282\ttotal: 6m 56s\tremaining: 1m\n",
      "437:\tlearn: 0.2135903\ttotal: 6m 57s\tremaining: 59.1s\n",
      "438:\tlearn: 0.2134196\ttotal: 6m 58s\tremaining: 58.2s\n",
      "439:\tlearn: 0.2131597\ttotal: 7m\tremaining: 57.3s\n",
      "440:\tlearn: 0.2130291\ttotal: 7m 2s\tremaining: 56.5s\n",
      "441:\tlearn: 0.2128040\ttotal: 7m 4s\tremaining: 55.7s\n",
      "442:\tlearn: 0.2124717\ttotal: 7m 5s\tremaining: 54.8s\n",
      "443:\tlearn: 0.2123745\ttotal: 7m 6s\tremaining: 53.8s\n",
      "444:\tlearn: 0.2121978\ttotal: 7m 7s\tremaining: 52.9s\n",
      "445:\tlearn: 0.2119368\ttotal: 7m 8s\tremaining: 51.9s\n",
      "446:\tlearn: 0.2117462\ttotal: 7m 9s\tremaining: 50.9s\n",
      "447:\tlearn: 0.2115247\ttotal: 7m 10s\tremaining: 50s\n",
      "448:\tlearn: 0.2114025\ttotal: 7m 11s\tremaining: 49s\n",
      "449:\tlearn: 0.2113085\ttotal: 7m 12s\tremaining: 48s\n",
      "450:\tlearn: 0.2111041\ttotal: 7m 13s\tremaining: 47.1s\n",
      "451:\tlearn: 0.2110087\ttotal: 7m 14s\tremaining: 46.2s\n",
      "452:\tlearn: 0.2106677\ttotal: 7m 16s\tremaining: 45.2s\n",
      "453:\tlearn: 0.2104809\ttotal: 7m 17s\tremaining: 44.3s\n",
      "454:\tlearn: 0.2103830\ttotal: 7m 18s\tremaining: 43.4s\n",
      "455:\tlearn: 0.2102274\ttotal: 7m 19s\tremaining: 42.4s\n",
      "456:\tlearn: 0.2100108\ttotal: 7m 21s\tremaining: 41.5s\n",
      "457:\tlearn: 0.2097973\ttotal: 7m 22s\tremaining: 40.6s\n",
      "458:\tlearn: 0.2096059\ttotal: 7m 23s\tremaining: 39.6s\n",
      "459:\tlearn: 0.2093769\ttotal: 7m 24s\tremaining: 38.6s\n",
      "460:\tlearn: 0.2092849\ttotal: 7m 24s\tremaining: 37.6s\n",
      "461:\tlearn: 0.2091897\ttotal: 7m 25s\tremaining: 36.7s\n",
      "462:\tlearn: 0.2090918\ttotal: 7m 26s\tremaining: 35.7s\n",
      "463:\tlearn: 0.2087804\ttotal: 7m 27s\tremaining: 34.7s\n",
      "464:\tlearn: 0.2085303\ttotal: 7m 28s\tremaining: 33.8s\n",
      "465:\tlearn: 0.2083790\ttotal: 7m 29s\tremaining: 32.8s\n",
      "466:\tlearn: 0.2081142\ttotal: 7m 31s\tremaining: 31.9s\n",
      "467:\tlearn: 0.2080163\ttotal: 7m 32s\tremaining: 30.9s\n",
      "468:\tlearn: 0.2079245\ttotal: 7m 33s\tremaining: 30s\n",
      "469:\tlearn: 0.2078268\ttotal: 7m 35s\tremaining: 29s\n",
      "470:\tlearn: 0.2076259\ttotal: 7m 36s\tremaining: 28.1s\n",
      "471:\tlearn: 0.2075283\ttotal: 7m 37s\tremaining: 27.1s\n",
      "472:\tlearn: 0.2074345\ttotal: 7m 38s\tremaining: 26.2s\n",
      "473:\tlearn: 0.2071496\ttotal: 7m 39s\tremaining: 25.2s\n",
      "474:\tlearn: 0.2070122\ttotal: 7m 40s\tremaining: 24.2s\n",
      "475:\tlearn: 0.2068032\ttotal: 7m 41s\tremaining: 23.3s\n",
      "476:\tlearn: 0.2067095\ttotal: 7m 42s\tremaining: 22.3s\n",
      "477:\tlearn: 0.2064424\ttotal: 7m 43s\tremaining: 21.3s\n",
      "478:\tlearn: 0.2062809\ttotal: 7m 44s\tremaining: 20.4s\n",
      "479:\tlearn: 0.2061875\ttotal: 7m 45s\tremaining: 19.4s\n",
      "480:\tlearn: 0.2059687\ttotal: 7m 47s\tremaining: 18.5s\n",
      "481:\tlearn: 0.2057825\ttotal: 7m 48s\tremaining: 17.5s\n",
      "482:\tlearn: 0.2056903\ttotal: 7m 49s\tremaining: 16.5s\n",
      "483:\tlearn: 0.2054858\ttotal: 7m 50s\tremaining: 15.6s\n",
      "484:\tlearn: 0.2053518\ttotal: 7m 51s\tremaining: 14.6s\n",
      "485:\tlearn: 0.2051162\ttotal: 7m 52s\tremaining: 13.6s\n",
      "486:\tlearn: 0.2049946\ttotal: 7m 54s\tremaining: 12.7s\n",
      "487:\tlearn: 0.2043768\ttotal: 7m 55s\tremaining: 11.7s\n",
      "488:\tlearn: 0.2041237\ttotal: 7m 56s\tremaining: 10.7s\n",
      "489:\tlearn: 0.2039681\ttotal: 7m 57s\tremaining: 9.75s\n",
      "490:\tlearn: 0.2038760\ttotal: 7m 58s\tremaining: 8.78s\n",
      "491:\tlearn: 0.2036803\ttotal: 7m 59s\tremaining: 7.8s\n",
      "492:\tlearn: 0.2034483\ttotal: 8m\tremaining: 6.83s\n",
      "493:\tlearn: 0.2033586\ttotal: 8m 2s\tremaining: 5.86s\n",
      "494:\tlearn: 0.2032218\ttotal: 8m 3s\tremaining: 4.89s\n",
      "495:\tlearn: 0.2031321\ttotal: 8m 4s\tremaining: 3.91s\n",
      "496:\tlearn: 0.2029545\ttotal: 8m 6s\tremaining: 2.93s\n",
      "497:\tlearn: 0.2028058\ttotal: 8m 7s\tremaining: 1.96s\n",
      "498:\tlearn: 0.2026340\ttotal: 8m 8s\tremaining: 978ms\n",
      "499:\tlearn: 0.2025107\ttotal: 8m 8s\tremaining: 0us\n",
      "[CV 5/5] END auto_class_weights=Balanced, iterations=500, random_state=12345;, score=0.750 total time= 8.3min\n",
      "Learning rate set to 0.13237\n",
      "0:\tlearn: 0.6330169\ttotal: 1.08s\tremaining: 8m 57s\n",
      "1:\tlearn: 0.5934682\ttotal: 2.22s\tremaining: 9m 12s\n",
      "2:\tlearn: 0.5673421\ttotal: 3.48s\tremaining: 9m 37s\n",
      "3:\tlearn: 0.5484144\ttotal: 4.64s\tremaining: 9m 36s\n",
      "4:\tlearn: 0.5399284\ttotal: 5.99s\tremaining: 9m 53s\n",
      "5:\tlearn: 0.5310612\ttotal: 7.22s\tremaining: 9m 54s\n",
      "6:\tlearn: 0.5223956\ttotal: 8.38s\tremaining: 9m 50s\n",
      "7:\tlearn: 0.5139889\ttotal: 9.52s\tremaining: 9m 45s\n",
      "8:\tlearn: 0.5076449\ttotal: 10.6s\tremaining: 9m 40s\n",
      "9:\tlearn: 0.5005815\ttotal: 12s\tremaining: 9m 46s\n",
      "10:\tlearn: 0.4961550\ttotal: 13.2s\tremaining: 9m 46s\n",
      "11:\tlearn: 0.4910737\ttotal: 14.5s\tremaining: 9m 49s\n",
      "12:\tlearn: 0.4835331\ttotal: 15.7s\tremaining: 9m 49s\n",
      "13:\tlearn: 0.4763022\ttotal: 17.2s\tremaining: 9m 55s\n",
      "14:\tlearn: 0.4715863\ttotal: 19.5s\tremaining: 10m 29s\n",
      "15:\tlearn: 0.4665143\ttotal: 20.8s\tremaining: 10m 30s\n",
      "16:\tlearn: 0.4625718\ttotal: 22s\tremaining: 10m 25s\n",
      "17:\tlearn: 0.4592881\ttotal: 23.2s\tremaining: 10m 21s\n",
      "18:\tlearn: 0.4566853\ttotal: 24.4s\tremaining: 10m 17s\n",
      "19:\tlearn: 0.4537130\ttotal: 25.6s\tremaining: 10m 15s\n",
      "20:\tlearn: 0.4497046\ttotal: 26.7s\tremaining: 10m 9s\n",
      "21:\tlearn: 0.4467962\ttotal: 27.8s\tremaining: 10m 3s\n",
      "22:\tlearn: 0.4440246\ttotal: 28.8s\tremaining: 9m 56s\n",
      "23:\tlearn: 0.4422439\ttotal: 30.1s\tremaining: 9m 56s\n",
      "24:\tlearn: 0.4385672\ttotal: 31.3s\tremaining: 9m 53s\n",
      "25:\tlearn: 0.4365560\ttotal: 32.4s\tremaining: 9m 50s\n",
      "26:\tlearn: 0.4344175\ttotal: 33.6s\tremaining: 9m 47s\n",
      "27:\tlearn: 0.4326385\ttotal: 34.7s\tremaining: 9m 44s\n",
      "28:\tlearn: 0.4308517\ttotal: 36s\tremaining: 9m 44s\n",
      "29:\tlearn: 0.4292682\ttotal: 37.1s\tremaining: 9m 42s\n",
      "30:\tlearn: 0.4266091\ttotal: 38.5s\tremaining: 9m 42s\n",
      "31:\tlearn: 0.4237946\ttotal: 39.6s\tremaining: 9m 39s\n",
      "32:\tlearn: 0.4219098\ttotal: 40.8s\tremaining: 9m 37s\n",
      "33:\tlearn: 0.4197278\ttotal: 42s\tremaining: 9m 35s\n",
      "34:\tlearn: 0.4177449\ttotal: 43.2s\tremaining: 9m 34s\n",
      "35:\tlearn: 0.4159537\ttotal: 44.4s\tremaining: 9m 32s\n",
      "36:\tlearn: 0.4140013\ttotal: 45.6s\tremaining: 9m 30s\n",
      "37:\tlearn: 0.4122850\ttotal: 46.6s\tremaining: 9m 26s\n",
      "38:\tlearn: 0.4099989\ttotal: 47.7s\tremaining: 9m 24s\n",
      "39:\tlearn: 0.4081073\ttotal: 48.7s\tremaining: 9m 20s\n",
      "40:\tlearn: 0.4055787\ttotal: 49.9s\tremaining: 9m 18s\n",
      "41:\tlearn: 0.4039049\ttotal: 51s\tremaining: 9m 15s\n",
      "42:\tlearn: 0.4020242\ttotal: 52s\tremaining: 9m 12s\n",
      "43:\tlearn: 0.4005729\ttotal: 53s\tremaining: 9m 9s\n",
      "44:\tlearn: 0.3994431\ttotal: 54s\tremaining: 9m 6s\n",
      "45:\tlearn: 0.3981039\ttotal: 55s\tremaining: 9m 2s\n",
      "46:\tlearn: 0.3969458\ttotal: 56s\tremaining: 8m 59s\n",
      "47:\tlearn: 0.3951385\ttotal: 57s\tremaining: 8m 56s\n",
      "48:\tlearn: 0.3934101\ttotal: 58s\tremaining: 8m 54s\n",
      "49:\tlearn: 0.3922890\ttotal: 59s\tremaining: 8m 51s\n",
      "50:\tlearn: 0.3911684\ttotal: 60s\tremaining: 8m 48s\n",
      "51:\tlearn: 0.3896324\ttotal: 1m\tremaining: 8m 45s\n",
      "52:\tlearn: 0.3885520\ttotal: 1m 2s\tremaining: 8m 42s\n",
      "53:\tlearn: 0.3868635\ttotal: 1m 2s\tremaining: 8m 40s\n",
      "54:\tlearn: 0.3858117\ttotal: 1m 3s\tremaining: 8m 37s\n",
      "55:\tlearn: 0.3843293\ttotal: 1m 4s\tremaining: 8m 34s\n",
      "56:\tlearn: 0.3828674\ttotal: 1m 5s\tremaining: 8m 32s\n",
      "57:\tlearn: 0.3818830\ttotal: 1m 6s\tremaining: 8m 30s\n",
      "58:\tlearn: 0.3807491\ttotal: 1m 7s\tremaining: 8m 27s\n",
      "59:\tlearn: 0.3799260\ttotal: 1m 8s\tremaining: 8m 25s\n",
      "60:\tlearn: 0.3780573\ttotal: 1m 9s\tremaining: 8m 23s\n",
      "61:\tlearn: 0.3770694\ttotal: 1m 10s\tremaining: 8m 20s\n",
      "62:\tlearn: 0.3760754\ttotal: 1m 11s\tremaining: 8m 18s\n",
      "63:\tlearn: 0.3751644\ttotal: 1m 12s\tremaining: 8m 16s\n",
      "64:\tlearn: 0.3737383\ttotal: 1m 13s\tremaining: 8m 14s\n",
      "65:\tlearn: 0.3721579\ttotal: 1m 14s\tremaining: 8m 12s\n",
      "66:\tlearn: 0.3711847\ttotal: 1m 15s\tremaining: 8m 9s\n",
      "67:\tlearn: 0.3704104\ttotal: 1m 16s\tremaining: 8m 7s\n",
      "68:\tlearn: 0.3696848\ttotal: 1m 17s\tremaining: 8m 5s\n",
      "69:\tlearn: 0.3689281\ttotal: 1m 18s\tremaining: 8m 3s\n",
      "70:\tlearn: 0.3673861\ttotal: 1m 19s\tremaining: 8m 1s\n",
      "71:\tlearn: 0.3659011\ttotal: 1m 20s\tremaining: 7m 59s\n",
      "72:\tlearn: 0.3644846\ttotal: 1m 21s\tremaining: 7m 57s\n",
      "73:\tlearn: 0.3631792\ttotal: 1m 22s\tremaining: 7m 55s\n",
      "74:\tlearn: 0.3622667\ttotal: 1m 23s\tremaining: 7m 53s\n",
      "75:\tlearn: 0.3614784\ttotal: 1m 24s\tremaining: 7m 51s\n",
      "76:\tlearn: 0.3604852\ttotal: 1m 25s\tremaining: 7m 50s\n",
      "77:\tlearn: 0.3593990\ttotal: 1m 27s\tremaining: 7m 50s\n",
      "78:\tlearn: 0.3585539\ttotal: 1m 28s\tremaining: 7m 49s\n",
      "79:\tlearn: 0.3568568\ttotal: 1m 29s\tremaining: 7m 50s\n",
      "80:\tlearn: 0.3559500\ttotal: 1m 31s\tremaining: 7m 52s\n",
      "81:\tlearn: 0.3550278\ttotal: 1m 32s\tremaining: 7m 50s\n",
      "82:\tlearn: 0.3542442\ttotal: 1m 33s\tremaining: 7m 50s\n",
      "83:\tlearn: 0.3532267\ttotal: 1m 34s\tremaining: 7m 49s\n",
      "84:\tlearn: 0.3518069\ttotal: 1m 36s\tremaining: 7m 48s\n",
      "85:\tlearn: 0.3507838\ttotal: 1m 37s\tremaining: 7m 47s\n",
      "86:\tlearn: 0.3499796\ttotal: 1m 38s\tremaining: 7m 47s\n",
      "87:\tlearn: 0.3492324\ttotal: 1m 39s\tremaining: 7m 45s\n",
      "88:\tlearn: 0.3485027\ttotal: 1m 40s\tremaining: 7m 44s\n",
      "89:\tlearn: 0.3474245\ttotal: 1m 41s\tremaining: 7m 42s\n",
      "90:\tlearn: 0.3463577\ttotal: 1m 42s\tremaining: 7m 42s\n",
      "91:\tlearn: 0.3454110\ttotal: 1m 44s\tremaining: 7m 41s\n",
      "92:\tlearn: 0.3443842\ttotal: 1m 45s\tremaining: 7m 40s\n",
      "93:\tlearn: 0.3432781\ttotal: 1m 46s\tremaining: 7m 41s\n",
      "94:\tlearn: 0.3425233\ttotal: 1m 47s\tremaining: 7m 40s\n",
      "95:\tlearn: 0.3416230\ttotal: 1m 48s\tremaining: 7m 38s\n",
      "96:\tlearn: 0.3408529\ttotal: 1m 49s\tremaining: 7m 36s\n",
      "97:\tlearn: 0.3399718\ttotal: 1m 51s\tremaining: 7m 36s\n",
      "98:\tlearn: 0.3391312\ttotal: 1m 52s\tremaining: 7m 34s\n",
      "99:\tlearn: 0.3385028\ttotal: 1m 53s\tremaining: 7m 33s\n",
      "100:\tlearn: 0.3376212\ttotal: 1m 54s\tremaining: 7m 32s\n",
      "101:\tlearn: 0.3357882\ttotal: 1m 55s\tremaining: 7m 32s\n",
      "102:\tlearn: 0.3345150\ttotal: 1m 57s\tremaining: 7m 30s\n",
      "103:\tlearn: 0.3337094\ttotal: 1m 58s\tremaining: 7m 29s\n",
      "104:\tlearn: 0.3328768\ttotal: 1m 59s\tremaining: 7m 28s\n",
      "105:\tlearn: 0.3320474\ttotal: 2m\tremaining: 7m 27s\n",
      "106:\tlearn: 0.3311969\ttotal: 2m 1s\tremaining: 7m 25s\n",
      "107:\tlearn: 0.3303672\ttotal: 2m 2s\tremaining: 7m 24s\n",
      "108:\tlearn: 0.3294898\ttotal: 2m 3s\tremaining: 7m 22s\n",
      "109:\tlearn: 0.3288568\ttotal: 2m 4s\tremaining: 7m 20s\n",
      "110:\tlearn: 0.3281118\ttotal: 2m 5s\tremaining: 7m 19s\n",
      "111:\tlearn: 0.3272924\ttotal: 2m 6s\tremaining: 7m 17s\n",
      "112:\tlearn: 0.3266075\ttotal: 2m 7s\tremaining: 7m 15s\n",
      "113:\tlearn: 0.3260131\ttotal: 2m 8s\tremaining: 7m 14s\n",
      "114:\tlearn: 0.3253656\ttotal: 2m 9s\tremaining: 7m 12s\n",
      "115:\tlearn: 0.3245994\ttotal: 2m 10s\tremaining: 7m 10s\n",
      "116:\tlearn: 0.3233349\ttotal: 2m 11s\tremaining: 7m 9s\n",
      "117:\tlearn: 0.3226831\ttotal: 2m 12s\tremaining: 7m 7s\n",
      "118:\tlearn: 0.3220676\ttotal: 2m 13s\tremaining: 7m 6s\n",
      "119:\tlearn: 0.3213266\ttotal: 2m 14s\tremaining: 7m 5s\n",
      "120:\tlearn: 0.3206346\ttotal: 2m 15s\tremaining: 7m 4s\n",
      "121:\tlearn: 0.3192291\ttotal: 2m 16s\tremaining: 7m 3s\n",
      "122:\tlearn: 0.3185731\ttotal: 2m 17s\tremaining: 7m 2s\n",
      "123:\tlearn: 0.3180093\ttotal: 2m 18s\tremaining: 7m 1s\n",
      "124:\tlearn: 0.3171292\ttotal: 2m 19s\tremaining: 6m 59s\n",
      "125:\tlearn: 0.3163955\ttotal: 2m 21s\tremaining: 6m 59s\n",
      "126:\tlearn: 0.3156649\ttotal: 2m 22s\tremaining: 6m 58s\n",
      "127:\tlearn: 0.3150510\ttotal: 2m 23s\tremaining: 6m 56s\n",
      "128:\tlearn: 0.3144141\ttotal: 2m 24s\tremaining: 6m 55s\n",
      "129:\tlearn: 0.3135084\ttotal: 2m 25s\tremaining: 6m 53s\n",
      "130:\tlearn: 0.3129327\ttotal: 2m 26s\tremaining: 6m 52s\n",
      "131:\tlearn: 0.3123635\ttotal: 2m 27s\tremaining: 6m 50s\n",
      "132:\tlearn: 0.3117660\ttotal: 2m 28s\tremaining: 6m 49s\n",
      "133:\tlearn: 0.3111569\ttotal: 2m 29s\tremaining: 6m 48s\n",
      "134:\tlearn: 0.3106191\ttotal: 2m 30s\tremaining: 6m 47s\n",
      "135:\tlearn: 0.3100662\ttotal: 2m 31s\tremaining: 6m 45s\n",
      "136:\tlearn: 0.3092957\ttotal: 2m 32s\tremaining: 6m 44s\n",
      "137:\tlearn: 0.3086038\ttotal: 2m 33s\tremaining: 6m 43s\n",
      "138:\tlearn: 0.3080282\ttotal: 2m 34s\tremaining: 6m 42s\n",
      "139:\tlearn: 0.3074747\ttotal: 2m 36s\tremaining: 6m 41s\n",
      "140:\tlearn: 0.3068431\ttotal: 2m 37s\tremaining: 6m 40s\n",
      "141:\tlearn: 0.3061297\ttotal: 2m 38s\tremaining: 6m 39s\n",
      "142:\tlearn: 0.3055943\ttotal: 2m 39s\tremaining: 6m 37s\n",
      "143:\tlearn: 0.3049931\ttotal: 2m 40s\tremaining: 6m 36s\n",
      "144:\tlearn: 0.3044041\ttotal: 2m 41s\tremaining: 6m 36s\n",
      "145:\tlearn: 0.3039136\ttotal: 2m 42s\tremaining: 6m 35s\n",
      "146:\tlearn: 0.3033603\ttotal: 2m 44s\tremaining: 6m 34s\n",
      "147:\tlearn: 0.3025193\ttotal: 2m 45s\tremaining: 6m 33s\n",
      "148:\tlearn: 0.3021048\ttotal: 2m 46s\tremaining: 6m 32s\n",
      "149:\tlearn: 0.3015875\ttotal: 2m 47s\tremaining: 6m 30s\n",
      "150:\tlearn: 0.3010354\ttotal: 2m 48s\tremaining: 6m 29s\n",
      "151:\tlearn: 0.3004954\ttotal: 2m 49s\tremaining: 6m 28s\n",
      "152:\tlearn: 0.2998649\ttotal: 2m 50s\tremaining: 6m 26s\n",
      "153:\tlearn: 0.2993055\ttotal: 2m 51s\tremaining: 6m 25s\n",
      "154:\tlearn: 0.2986557\ttotal: 2m 52s\tremaining: 6m 24s\n",
      "155:\tlearn: 0.2982516\ttotal: 2m 53s\tremaining: 6m 23s\n",
      "156:\tlearn: 0.2978634\ttotal: 2m 54s\tremaining: 6m 22s\n",
      "157:\tlearn: 0.2974138\ttotal: 2m 55s\tremaining: 6m 20s\n",
      "158:\tlearn: 0.2968958\ttotal: 2m 57s\tremaining: 6m 19s\n",
      "159:\tlearn: 0.2963343\ttotal: 2m 58s\tremaining: 6m 18s\n",
      "160:\tlearn: 0.2958553\ttotal: 2m 59s\tremaining: 6m 17s\n",
      "161:\tlearn: 0.2953551\ttotal: 3m\tremaining: 6m 15s\n",
      "162:\tlearn: 0.2949296\ttotal: 3m 1s\tremaining: 6m 14s\n",
      "163:\tlearn: 0.2942928\ttotal: 3m 2s\tremaining: 6m 13s\n",
      "164:\tlearn: 0.2937987\ttotal: 3m 3s\tremaining: 6m 11s\n",
      "165:\tlearn: 0.2932818\ttotal: 3m 4s\tremaining: 6m 10s\n",
      "166:\tlearn: 0.2928950\ttotal: 3m 5s\tremaining: 6m 10s\n",
      "167:\tlearn: 0.2920077\ttotal: 3m 6s\tremaining: 6m 8s\n",
      "168:\tlearn: 0.2915060\ttotal: 3m 7s\tremaining: 6m 7s\n",
      "169:\tlearn: 0.2911021\ttotal: 3m 8s\tremaining: 6m 6s\n",
      "170:\tlearn: 0.2905864\ttotal: 3m 10s\tremaining: 6m 5s\n",
      "171:\tlearn: 0.2900141\ttotal: 3m 11s\tremaining: 6m 4s\n",
      "172:\tlearn: 0.2895513\ttotal: 3m 12s\tremaining: 6m 3s\n",
      "173:\tlearn: 0.2890284\ttotal: 3m 13s\tremaining: 6m 2s\n",
      "174:\tlearn: 0.2885276\ttotal: 3m 14s\tremaining: 6m 1s\n",
      "175:\tlearn: 0.2880817\ttotal: 3m 15s\tremaining: 5m 59s\n",
      "176:\tlearn: 0.2875879\ttotal: 3m 16s\tremaining: 5m 58s\n",
      "177:\tlearn: 0.2871075\ttotal: 3m 17s\tremaining: 5m 57s\n",
      "178:\tlearn: 0.2865683\ttotal: 3m 18s\tremaining: 5m 56s\n",
      "179:\tlearn: 0.2859836\ttotal: 3m 19s\tremaining: 5m 54s\n",
      "180:\tlearn: 0.2855255\ttotal: 3m 20s\tremaining: 5m 53s\n",
      "181:\tlearn: 0.2849365\ttotal: 3m 21s\tremaining: 5m 52s\n",
      "182:\tlearn: 0.2845971\ttotal: 3m 22s\tremaining: 5m 51s\n",
      "183:\tlearn: 0.2841576\ttotal: 3m 24s\tremaining: 5m 50s\n",
      "184:\tlearn: 0.2837592\ttotal: 3m 25s\tremaining: 5m 49s\n",
      "185:\tlearn: 0.2832824\ttotal: 3m 26s\tremaining: 5m 48s\n",
      "186:\tlearn: 0.2829456\ttotal: 3m 27s\tremaining: 5m 46s\n",
      "187:\tlearn: 0.2823525\ttotal: 3m 28s\tremaining: 5m 45s\n",
      "188:\tlearn: 0.2814329\ttotal: 3m 29s\tremaining: 5m 44s\n",
      "189:\tlearn: 0.2810196\ttotal: 3m 30s\tremaining: 5m 43s\n",
      "190:\tlearn: 0.2805712\ttotal: 3m 31s\tremaining: 5m 41s\n",
      "191:\tlearn: 0.2802232\ttotal: 3m 32s\tremaining: 5m 40s\n",
      "192:\tlearn: 0.2798986\ttotal: 3m 33s\tremaining: 5m 39s\n",
      "193:\tlearn: 0.2794895\ttotal: 3m 34s\tremaining: 5m 38s\n",
      "194:\tlearn: 0.2791160\ttotal: 3m 35s\tremaining: 5m 37s\n",
      "195:\tlearn: 0.2787244\ttotal: 3m 36s\tremaining: 5m 36s\n",
      "196:\tlearn: 0.2784457\ttotal: 3m 37s\tremaining: 5m 34s\n",
      "197:\tlearn: 0.2778900\ttotal: 3m 38s\tremaining: 5m 33s\n",
      "198:\tlearn: 0.2775700\ttotal: 3m 39s\tremaining: 5m 32s\n",
      "199:\tlearn: 0.2762537\ttotal: 3m 41s\tremaining: 5m 31s\n",
      "200:\tlearn: 0.2757742\ttotal: 3m 42s\tremaining: 5m 30s\n",
      "201:\tlearn: 0.2753750\ttotal: 3m 43s\tremaining: 5m 29s\n",
      "202:\tlearn: 0.2749767\ttotal: 3m 44s\tremaining: 5m 27s\n",
      "203:\tlearn: 0.2746265\ttotal: 3m 45s\tremaining: 5m 26s\n",
      "204:\tlearn: 0.2743403\ttotal: 3m 46s\tremaining: 5m 25s\n",
      "205:\tlearn: 0.2740721\ttotal: 3m 47s\tremaining: 5m 24s\n",
      "206:\tlearn: 0.2737189\ttotal: 3m 48s\tremaining: 5m 23s\n",
      "207:\tlearn: 0.2733476\ttotal: 3m 49s\tremaining: 5m 21s\n",
      "208:\tlearn: 0.2730426\ttotal: 3m 50s\tremaining: 5m 20s\n",
      "209:\tlearn: 0.2725665\ttotal: 3m 51s\tremaining: 5m 19s\n",
      "210:\tlearn: 0.2717650\ttotal: 3m 52s\tremaining: 5m 18s\n",
      "211:\tlearn: 0.2715085\ttotal: 3m 53s\tremaining: 5m 17s\n",
      "212:\tlearn: 0.2712433\ttotal: 3m 54s\tremaining: 5m 15s\n",
      "213:\tlearn: 0.2708950\ttotal: 3m 55s\tremaining: 5m 14s\n",
      "214:\tlearn: 0.2704710\ttotal: 3m 56s\tremaining: 5m 13s\n",
      "215:\tlearn: 0.2701754\ttotal: 3m 57s\tremaining: 5m 12s\n",
      "216:\tlearn: 0.2698235\ttotal: 3m 58s\tremaining: 5m 11s\n",
      "217:\tlearn: 0.2694007\ttotal: 3m 59s\tremaining: 5m 9s\n",
      "218:\tlearn: 0.2689265\ttotal: 4m\tremaining: 5m 8s\n",
      "219:\tlearn: 0.2683064\ttotal: 4m 1s\tremaining: 5m 7s\n",
      "220:\tlearn: 0.2679832\ttotal: 4m 2s\tremaining: 5m 6s\n",
      "221:\tlearn: 0.2676704\ttotal: 4m 4s\tremaining: 5m 5s\n",
      "222:\tlearn: 0.2672800\ttotal: 4m 5s\tremaining: 5m 4s\n",
      "223:\tlearn: 0.2669549\ttotal: 4m 6s\tremaining: 5m 3s\n",
      "224:\tlearn: 0.2666847\ttotal: 4m 7s\tremaining: 5m 2s\n",
      "225:\tlearn: 0.2664312\ttotal: 4m 8s\tremaining: 5m 1s\n",
      "226:\tlearn: 0.2661020\ttotal: 4m 10s\tremaining: 5m 1s\n",
      "227:\tlearn: 0.2657348\ttotal: 4m 11s\tremaining: 5m\n",
      "228:\tlearn: 0.2654530\ttotal: 4m 13s\tremaining: 4m 59s\n",
      "229:\tlearn: 0.2652058\ttotal: 4m 14s\tremaining: 4m 58s\n",
      "230:\tlearn: 0.2648790\ttotal: 4m 15s\tremaining: 4m 57s\n",
      "231:\tlearn: 0.2644777\ttotal: 4m 16s\tremaining: 4m 56s\n",
      "232:\tlearn: 0.2641131\ttotal: 4m 17s\tremaining: 4m 55s\n",
      "233:\tlearn: 0.2637219\ttotal: 4m 18s\tremaining: 4m 53s\n",
      "234:\tlearn: 0.2634565\ttotal: 4m 19s\tremaining: 4m 52s\n",
      "235:\tlearn: 0.2631986\ttotal: 4m 20s\tremaining: 4m 51s\n",
      "236:\tlearn: 0.2628431\ttotal: 4m 21s\tremaining: 4m 50s\n",
      "237:\tlearn: 0.2624686\ttotal: 4m 23s\tremaining: 4m 50s\n",
      "238:\tlearn: 0.2621622\ttotal: 4m 25s\tremaining: 4m 49s\n",
      "239:\tlearn: 0.2619190\ttotal: 4m 26s\tremaining: 4m 48s\n",
      "240:\tlearn: 0.2615074\ttotal: 4m 27s\tremaining: 4m 47s\n",
      "241:\tlearn: 0.2612567\ttotal: 4m 29s\tremaining: 4m 47s\n",
      "242:\tlearn: 0.2608525\ttotal: 4m 30s\tremaining: 4m 46s\n",
      "243:\tlearn: 0.2604473\ttotal: 4m 32s\tremaining: 4m 45s\n",
      "244:\tlearn: 0.2602140\ttotal: 4m 33s\tremaining: 4m 44s\n",
      "245:\tlearn: 0.2598399\ttotal: 4m 34s\tremaining: 4m 43s\n",
      "246:\tlearn: 0.2595300\ttotal: 4m 36s\tremaining: 4m 42s\n",
      "247:\tlearn: 0.2591293\ttotal: 4m 37s\tremaining: 4m 42s\n",
      "248:\tlearn: 0.2588577\ttotal: 4m 38s\tremaining: 4m 41s\n",
      "249:\tlearn: 0.2585027\ttotal: 4m 40s\tremaining: 4m 40s\n",
      "250:\tlearn: 0.2582202\ttotal: 4m 42s\tremaining: 4m 39s\n",
      "251:\tlearn: 0.2579910\ttotal: 4m 43s\tremaining: 4m 39s\n",
      "252:\tlearn: 0.2577944\ttotal: 4m 44s\tremaining: 4m 37s\n",
      "253:\tlearn: 0.2574617\ttotal: 4m 45s\tremaining: 4m 36s\n",
      "254:\tlearn: 0.2571496\ttotal: 4m 46s\tremaining: 4m 35s\n",
      "255:\tlearn: 0.2567853\ttotal: 4m 47s\tremaining: 4m 34s\n",
      "256:\tlearn: 0.2564756\ttotal: 4m 48s\tremaining: 4m 33s\n",
      "257:\tlearn: 0.2561820\ttotal: 4m 49s\tremaining: 4m 31s\n",
      "258:\tlearn: 0.2559723\ttotal: 4m 50s\tremaining: 4m 30s\n",
      "259:\tlearn: 0.2556060\ttotal: 4m 52s\tremaining: 4m 29s\n",
      "260:\tlearn: 0.2552453\ttotal: 4m 53s\tremaining: 4m 28s\n",
      "261:\tlearn: 0.2549850\ttotal: 4m 54s\tremaining: 4m 27s\n",
      "262:\tlearn: 0.2546507\ttotal: 4m 55s\tremaining: 4m 25s\n",
      "263:\tlearn: 0.2543773\ttotal: 4m 56s\tremaining: 4m 24s\n",
      "264:\tlearn: 0.2539148\ttotal: 4m 57s\tremaining: 4m 23s\n",
      "265:\tlearn: 0.2536917\ttotal: 4m 58s\tremaining: 4m 22s\n",
      "266:\tlearn: 0.2532674\ttotal: 4m 59s\tremaining: 4m 21s\n",
      "267:\tlearn: 0.2531010\ttotal: 5m\tremaining: 4m 19s\n",
      "268:\tlearn: 0.2526839\ttotal: 5m 1s\tremaining: 4m 18s\n",
      "269:\tlearn: 0.2522983\ttotal: 5m 2s\tremaining: 4m 17s\n",
      "270:\tlearn: 0.2520000\ttotal: 5m 3s\tremaining: 4m 16s\n",
      "271:\tlearn: 0.2517681\ttotal: 5m 4s\tremaining: 4m 15s\n",
      "272:\tlearn: 0.2515288\ttotal: 5m 5s\tremaining: 4m 14s\n",
      "273:\tlearn: 0.2513155\ttotal: 5m 7s\tremaining: 4m 13s\n",
      "274:\tlearn: 0.2509951\ttotal: 5m 8s\tremaining: 4m 12s\n",
      "275:\tlearn: 0.2506034\ttotal: 5m 9s\tremaining: 4m 10s\n",
      "276:\tlearn: 0.2501718\ttotal: 5m 10s\tremaining: 4m 9s\n",
      "277:\tlearn: 0.2498458\ttotal: 5m 11s\tremaining: 4m 8s\n",
      "278:\tlearn: 0.2496027\ttotal: 5m 12s\tremaining: 4m 7s\n",
      "279:\tlearn: 0.2491765\ttotal: 5m 13s\tremaining: 4m 6s\n",
      "280:\tlearn: 0.2490206\ttotal: 5m 14s\tremaining: 4m 5s\n",
      "281:\tlearn: 0.2488217\ttotal: 5m 15s\tremaining: 4m 4s\n",
      "282:\tlearn: 0.2484835\ttotal: 5m 16s\tremaining: 4m 2s\n",
      "283:\tlearn: 0.2481617\ttotal: 5m 17s\tremaining: 4m 1s\n",
      "284:\tlearn: 0.2479361\ttotal: 5m 18s\tremaining: 4m\n",
      "285:\tlearn: 0.2476135\ttotal: 5m 20s\tremaining: 3m 59s\n",
      "286:\tlearn: 0.2474368\ttotal: 5m 20s\tremaining: 3m 58s\n",
      "287:\tlearn: 0.2471579\ttotal: 5m 21s\tremaining: 3m 56s\n",
      "288:\tlearn: 0.2469022\ttotal: 5m 22s\tremaining: 3m 55s\n",
      "289:\tlearn: 0.2465957\ttotal: 5m 23s\tremaining: 3m 54s\n",
      "290:\tlearn: 0.2462495\ttotal: 5m 24s\tremaining: 3m 53s\n",
      "291:\tlearn: 0.2459290\ttotal: 5m 25s\tremaining: 3m 52s\n",
      "292:\tlearn: 0.2455887\ttotal: 5m 26s\tremaining: 3m 50s\n",
      "293:\tlearn: 0.2453859\ttotal: 5m 27s\tremaining: 3m 49s\n",
      "294:\tlearn: 0.2451099\ttotal: 5m 28s\tremaining: 3m 48s\n",
      "295:\tlearn: 0.2449067\ttotal: 5m 29s\tremaining: 3m 47s\n",
      "296:\tlearn: 0.2445579\ttotal: 5m 31s\tremaining: 3m 46s\n",
      "297:\tlearn: 0.2442951\ttotal: 5m 32s\tremaining: 3m 45s\n",
      "298:\tlearn: 0.2439588\ttotal: 5m 33s\tremaining: 3m 44s\n",
      "299:\tlearn: 0.2438169\ttotal: 5m 34s\tremaining: 3m 43s\n",
      "300:\tlearn: 0.2435589\ttotal: 5m 35s\tremaining: 3m 41s\n",
      "301:\tlearn: 0.2432301\ttotal: 5m 36s\tremaining: 3m 40s\n",
      "302:\tlearn: 0.2429465\ttotal: 5m 37s\tremaining: 3m 39s\n",
      "303:\tlearn: 0.2427564\ttotal: 5m 38s\tremaining: 3m 38s\n",
      "304:\tlearn: 0.2426284\ttotal: 5m 39s\tremaining: 3m 37s\n",
      "305:\tlearn: 0.2423892\ttotal: 5m 41s\tremaining: 3m 36s\n",
      "306:\tlearn: 0.2421338\ttotal: 5m 42s\tremaining: 3m 35s\n",
      "307:\tlearn: 0.2417997\ttotal: 5m 44s\tremaining: 3m 34s\n",
      "308:\tlearn: 0.2415097\ttotal: 5m 45s\tremaining: 3m 33s\n",
      "309:\tlearn: 0.2413336\ttotal: 5m 47s\tremaining: 3m 32s\n",
      "310:\tlearn: 0.2409982\ttotal: 5m 49s\tremaining: 3m 32s\n",
      "311:\tlearn: 0.2406466\ttotal: 5m 50s\tremaining: 3m 31s\n",
      "312:\tlearn: 0.2404084\ttotal: 5m 51s\tremaining: 3m 30s\n",
      "313:\tlearn: 0.2401738\ttotal: 5m 53s\tremaining: 3m 29s\n",
      "314:\tlearn: 0.2398511\ttotal: 5m 54s\tremaining: 3m 28s\n",
      "315:\tlearn: 0.2396232\ttotal: 5m 56s\tremaining: 3m 27s\n",
      "316:\tlearn: 0.2393701\ttotal: 5m 57s\tremaining: 3m 26s\n",
      "317:\tlearn: 0.2391886\ttotal: 5m 58s\tremaining: 3m 25s\n",
      "318:\tlearn: 0.2387218\ttotal: 5m 59s\tremaining: 3m 24s\n",
      "319:\tlearn: 0.2384440\ttotal: 6m 1s\tremaining: 3m 23s\n",
      "320:\tlearn: 0.2382504\ttotal: 6m 2s\tremaining: 3m 22s\n",
      "321:\tlearn: 0.2379369\ttotal: 6m 3s\tremaining: 3m 21s\n",
      "322:\tlearn: 0.2377874\ttotal: 6m 5s\tremaining: 3m 20s\n",
      "323:\tlearn: 0.2376607\ttotal: 6m 6s\tremaining: 3m 19s\n",
      "324:\tlearn: 0.2373797\ttotal: 6m 7s\tremaining: 3m 17s\n",
      "325:\tlearn: 0.2371605\ttotal: 6m 8s\tremaining: 3m 16s\n",
      "326:\tlearn: 0.2369120\ttotal: 6m 9s\tremaining: 3m 15s\n",
      "327:\tlearn: 0.2366994\ttotal: 6m 10s\tremaining: 3m 14s\n",
      "328:\tlearn: 0.2364543\ttotal: 6m 11s\tremaining: 3m 13s\n",
      "329:\tlearn: 0.2362140\ttotal: 6m 12s\tremaining: 3m 12s\n",
      "330:\tlearn: 0.2359392\ttotal: 6m 13s\tremaining: 3m 10s\n",
      "331:\tlearn: 0.2356750\ttotal: 6m 14s\tremaining: 3m 9s\n",
      "332:\tlearn: 0.2355509\ttotal: 6m 15s\tremaining: 3m 8s\n",
      "333:\tlearn: 0.2352630\ttotal: 6m 16s\tremaining: 3m 7s\n",
      "334:\tlearn: 0.2349899\ttotal: 6m 17s\tremaining: 3m 6s\n",
      "335:\tlearn: 0.2344887\ttotal: 6m 18s\tremaining: 3m 4s\n",
      "336:\tlearn: 0.2336237\ttotal: 6m 19s\tremaining: 3m 3s\n",
      "337:\tlearn: 0.2334537\ttotal: 6m 20s\tremaining: 3m 2s\n",
      "338:\tlearn: 0.2331899\ttotal: 6m 21s\tremaining: 3m 1s\n",
      "339:\tlearn: 0.2330221\ttotal: 6m 22s\tremaining: 3m\n",
      "340:\tlearn: 0.2326113\ttotal: 6m 23s\tremaining: 2m 59s\n",
      "341:\tlearn: 0.2323239\ttotal: 6m 25s\tremaining: 2m 57s\n",
      "342:\tlearn: 0.2320756\ttotal: 6m 26s\tremaining: 2m 56s\n",
      "343:\tlearn: 0.2318489\ttotal: 6m 27s\tremaining: 2m 55s\n",
      "344:\tlearn: 0.2316054\ttotal: 6m 28s\tremaining: 2m 54s\n",
      "345:\tlearn: 0.2313214\ttotal: 6m 29s\tremaining: 2m 53s\n",
      "346:\tlearn: 0.2311725\ttotal: 6m 30s\tremaining: 2m 52s\n",
      "347:\tlearn: 0.2308680\ttotal: 6m 31s\tremaining: 2m 51s\n",
      "348:\tlearn: 0.2307124\ttotal: 6m 33s\tremaining: 2m 50s\n",
      "349:\tlearn: 0.2304775\ttotal: 6m 34s\tremaining: 2m 48s\n",
      "350:\tlearn: 0.2303578\ttotal: 6m 35s\tremaining: 2m 47s\n",
      "351:\tlearn: 0.2301934\ttotal: 6m 36s\tremaining: 2m 46s\n",
      "352:\tlearn: 0.2300161\ttotal: 6m 37s\tremaining: 2m 45s\n",
      "353:\tlearn: 0.2297307\ttotal: 6m 38s\tremaining: 2m 44s\n",
      "354:\tlearn: 0.2295409\ttotal: 6m 39s\tremaining: 2m 43s\n",
      "355:\tlearn: 0.2292392\ttotal: 6m 40s\tremaining: 2m 41s\n",
      "356:\tlearn: 0.2291217\ttotal: 6m 41s\tremaining: 2m 40s\n",
      "357:\tlearn: 0.2289470\ttotal: 6m 42s\tremaining: 2m 39s\n",
      "358:\tlearn: 0.2284185\ttotal: 6m 43s\tremaining: 2m 38s\n",
      "359:\tlearn: 0.2281927\ttotal: 6m 45s\tremaining: 2m 37s\n",
      "360:\tlearn: 0.2278151\ttotal: 6m 46s\tremaining: 2m 36s\n",
      "361:\tlearn: 0.2275913\ttotal: 6m 47s\tremaining: 2m 35s\n",
      "362:\tlearn: 0.2273538\ttotal: 6m 48s\tremaining: 2m 34s\n",
      "363:\tlearn: 0.2271008\ttotal: 6m 49s\tremaining: 2m 33s\n",
      "364:\tlearn: 0.2268050\ttotal: 6m 51s\tremaining: 2m 32s\n",
      "365:\tlearn: 0.2266646\ttotal: 6m 52s\tremaining: 2m 30s\n",
      "366:\tlearn: 0.2265512\ttotal: 6m 53s\tremaining: 2m 29s\n",
      "367:\tlearn: 0.2263978\ttotal: 6m 54s\tremaining: 2m 28s\n",
      "368:\tlearn: 0.2262655\ttotal: 6m 55s\tremaining: 2m 27s\n",
      "369:\tlearn: 0.2260741\ttotal: 6m 57s\tremaining: 2m 26s\n",
      "370:\tlearn: 0.2258638\ttotal: 6m 58s\tremaining: 2m 25s\n",
      "371:\tlearn: 0.2256227\ttotal: 6m 59s\tremaining: 2m 24s\n",
      "372:\tlearn: 0.2254272\ttotal: 7m\tremaining: 2m 23s\n",
      "373:\tlearn: 0.2252212\ttotal: 7m 2s\tremaining: 2m 22s\n",
      "374:\tlearn: 0.2250916\ttotal: 7m 3s\tremaining: 2m 21s\n",
      "375:\tlearn: 0.2248724\ttotal: 7m 5s\tremaining: 2m 20s\n",
      "376:\tlearn: 0.2247659\ttotal: 7m 6s\tremaining: 2m 19s\n",
      "377:\tlearn: 0.2244963\ttotal: 7m 8s\tremaining: 2m 18s\n",
      "378:\tlearn: 0.2243395\ttotal: 7m 9s\tremaining: 2m 17s\n",
      "379:\tlearn: 0.2241140\ttotal: 7m 10s\tremaining: 2m 16s\n",
      "380:\tlearn: 0.2240073\ttotal: 7m 12s\tremaining: 2m 14s\n",
      "381:\tlearn: 0.2238049\ttotal: 7m 13s\tremaining: 2m 13s\n",
      "382:\tlearn: 0.2235931\ttotal: 7m 14s\tremaining: 2m 12s\n",
      "383:\tlearn: 0.2233073\ttotal: 7m 15s\tremaining: 2m 11s\n",
      "384:\tlearn: 0.2232017\ttotal: 7m 16s\tremaining: 2m 10s\n",
      "385:\tlearn: 0.2228682\ttotal: 7m 17s\tremaining: 2m 9s\n",
      "386:\tlearn: 0.2227477\ttotal: 7m 18s\tremaining: 2m 8s\n",
      "387:\tlearn: 0.2225109\ttotal: 7m 19s\tremaining: 2m 6s\n",
      "388:\tlearn: 0.2223920\ttotal: 7m 20s\tremaining: 2m 5s\n",
      "389:\tlearn: 0.2221795\ttotal: 7m 22s\tremaining: 2m 4s\n",
      "390:\tlearn: 0.2219099\ttotal: 7m 23s\tremaining: 2m 3s\n",
      "391:\tlearn: 0.2217137\ttotal: 7m 24s\tremaining: 2m 2s\n",
      "392:\tlearn: 0.2216103\ttotal: 7m 25s\tremaining: 2m 1s\n",
      "393:\tlearn: 0.2213571\ttotal: 7m 27s\tremaining: 2m\n",
      "394:\tlearn: 0.2211431\ttotal: 7m 28s\tremaining: 1m 59s\n",
      "395:\tlearn: 0.2209395\ttotal: 7m 29s\tremaining: 1m 58s\n",
      "396:\tlearn: 0.2207379\ttotal: 7m 30s\tremaining: 1m 57s\n",
      "397:\tlearn: 0.2205945\ttotal: 7m 31s\tremaining: 1m 55s\n",
      "398:\tlearn: 0.2203645\ttotal: 7m 33s\tremaining: 1m 54s\n",
      "399:\tlearn: 0.2201487\ttotal: 7m 34s\tremaining: 1m 53s\n",
      "400:\tlearn: 0.2200469\ttotal: 7m 35s\tremaining: 1m 52s\n",
      "401:\tlearn: 0.2198020\ttotal: 7m 36s\tremaining: 1m 51s\n",
      "402:\tlearn: 0.2195382\ttotal: 7m 37s\tremaining: 1m 50s\n",
      "403:\tlearn: 0.2192771\ttotal: 7m 38s\tremaining: 1m 48s\n",
      "404:\tlearn: 0.2190815\ttotal: 7m 39s\tremaining: 1m 47s\n",
      "405:\tlearn: 0.2189839\ttotal: 7m 39s\tremaining: 1m 46s\n",
      "406:\tlearn: 0.2188409\ttotal: 7m 40s\tremaining: 1m 45s\n",
      "407:\tlearn: 0.2186726\ttotal: 7m 41s\tremaining: 1m 44s\n",
      "408:\tlearn: 0.2184734\ttotal: 7m 42s\tremaining: 1m 43s\n",
      "409:\tlearn: 0.2182212\ttotal: 7m 43s\tremaining: 1m 41s\n",
      "410:\tlearn: 0.2180895\ttotal: 7m 44s\tremaining: 1m 40s\n",
      "411:\tlearn: 0.2178239\ttotal: 7m 45s\tremaining: 1m 39s\n",
      "412:\tlearn: 0.2175614\ttotal: 7m 46s\tremaining: 1m 38s\n",
      "413:\tlearn: 0.2174631\ttotal: 7m 47s\tremaining: 1m 37s\n",
      "414:\tlearn: 0.2172893\ttotal: 7m 48s\tremaining: 1m 35s\n",
      "415:\tlearn: 0.2170367\ttotal: 7m 49s\tremaining: 1m 34s\n",
      "416:\tlearn: 0.2169413\ttotal: 7m 50s\tremaining: 1m 33s\n",
      "417:\tlearn: 0.2167653\ttotal: 7m 51s\tremaining: 1m 32s\n",
      "418:\tlearn: 0.2164794\ttotal: 7m 52s\tremaining: 1m 31s\n",
      "419:\tlearn: 0.2163299\ttotal: 7m 53s\tremaining: 1m 30s\n",
      "420:\tlearn: 0.2161278\ttotal: 7m 54s\tremaining: 1m 29s\n",
      "421:\tlearn: 0.2158802\ttotal: 7m 55s\tremaining: 1m 27s\n",
      "422:\tlearn: 0.2156301\ttotal: 7m 56s\tremaining: 1m 26s\n",
      "423:\tlearn: 0.2154219\ttotal: 7m 57s\tremaining: 1m 25s\n",
      "424:\tlearn: 0.2151952\ttotal: 7m 58s\tremaining: 1m 24s\n",
      "425:\tlearn: 0.2149340\ttotal: 7m 59s\tremaining: 1m 23s\n",
      "426:\tlearn: 0.2147360\ttotal: 8m\tremaining: 1m 22s\n",
      "427:\tlearn: 0.2145246\ttotal: 8m 1s\tremaining: 1m 21s\n",
      "428:\tlearn: 0.2144283\ttotal: 8m 2s\tremaining: 1m 19s\n",
      "429:\tlearn: 0.2142590\ttotal: 8m 3s\tremaining: 1m 18s\n",
      "430:\tlearn: 0.2141351\ttotal: 8m 4s\tremaining: 1m 17s\n",
      "431:\tlearn: 0.2139463\ttotal: 8m 5s\tremaining: 1m 16s\n",
      "432:\tlearn: 0.2136235\ttotal: 8m 6s\tremaining: 1m 15s\n",
      "433:\tlearn: 0.2134210\ttotal: 8m 7s\tremaining: 1m 14s\n",
      "434:\tlearn: 0.2132334\ttotal: 8m 8s\tremaining: 1m 13s\n",
      "435:\tlearn: 0.2130549\ttotal: 8m 9s\tremaining: 1m 11s\n",
      "436:\tlearn: 0.2128603\ttotal: 8m 10s\tremaining: 1m 10s\n",
      "437:\tlearn: 0.2127504\ttotal: 8m 11s\tremaining: 1m 9s\n",
      "438:\tlearn: 0.2126555\ttotal: 8m 12s\tremaining: 1m 8s\n",
      "439:\tlearn: 0.2125633\ttotal: 8m 13s\tremaining: 1m 7s\n",
      "440:\tlearn: 0.2123778\ttotal: 8m 14s\tremaining: 1m 6s\n",
      "441:\tlearn: 0.2122168\ttotal: 8m 15s\tremaining: 1m 5s\n",
      "442:\tlearn: 0.2120676\ttotal: 8m 16s\tremaining: 1m 3s\n",
      "443:\tlearn: 0.2118515\ttotal: 8m 17s\tremaining: 1m 2s\n",
      "444:\tlearn: 0.2117135\ttotal: 8m 18s\tremaining: 1m 1s\n",
      "445:\tlearn: 0.2115075\ttotal: 8m 19s\tremaining: 1m\n",
      "446:\tlearn: 0.2112626\ttotal: 8m 20s\tremaining: 59.4s\n",
      "447:\tlearn: 0.2110906\ttotal: 8m 21s\tremaining: 58.3s\n",
      "448:\tlearn: 0.2109969\ttotal: 8m 23s\tremaining: 57.1s\n",
      "449:\tlearn: 0.2109050\ttotal: 8m 24s\tremaining: 56s\n",
      "450:\tlearn: 0.2107180\ttotal: 8m 25s\tremaining: 54.9s\n",
      "451:\tlearn: 0.2105456\ttotal: 8m 26s\tremaining: 53.7s\n",
      "452:\tlearn: 0.2103006\ttotal: 8m 27s\tremaining: 52.6s\n",
      "453:\tlearn: 0.2100895\ttotal: 8m 28s\tremaining: 51.5s\n",
      "454:\tlearn: 0.2099552\ttotal: 8m 29s\tremaining: 50.3s\n",
      "455:\tlearn: 0.2098653\ttotal: 8m 30s\tremaining: 49.2s\n",
      "456:\tlearn: 0.2097068\ttotal: 8m 30s\tremaining: 48.1s\n",
      "457:\tlearn: 0.2095542\ttotal: 8m 31s\tremaining: 46.9s\n",
      "458:\tlearn: 0.2093766\ttotal: 8m 32s\tremaining: 45.8s\n",
      "459:\tlearn: 0.2092893\ttotal: 8m 33s\tremaining: 44.7s\n",
      "460:\tlearn: 0.2090514\ttotal: 8m 34s\tremaining: 43.6s\n",
      "461:\tlearn: 0.2089652\ttotal: 8m 35s\tremaining: 42.4s\n",
      "462:\tlearn: 0.2087450\ttotal: 8m 37s\tremaining: 41.3s\n",
      "463:\tlearn: 0.2084968\ttotal: 8m 38s\tremaining: 40.2s\n",
      "464:\tlearn: 0.2083740\ttotal: 8m 39s\tremaining: 39.1s\n",
      "465:\tlearn: 0.2082852\ttotal: 8m 40s\tremaining: 38s\n",
      "466:\tlearn: 0.2081785\ttotal: 8m 41s\tremaining: 36.8s\n",
      "467:\tlearn: 0.2080286\ttotal: 8m 42s\tremaining: 35.7s\n",
      "468:\tlearn: 0.2078708\ttotal: 8m 43s\tremaining: 34.6s\n",
      "469:\tlearn: 0.2077837\ttotal: 8m 44s\tremaining: 33.5s\n",
      "470:\tlearn: 0.2075107\ttotal: 8m 45s\tremaining: 32.3s\n",
      "471:\tlearn: 0.2073367\ttotal: 8m 46s\tremaining: 31.2s\n",
      "472:\tlearn: 0.2072521\ttotal: 8m 47s\tremaining: 30.1s\n",
      "473:\tlearn: 0.2070407\ttotal: 8m 48s\tremaining: 29s\n",
      "474:\tlearn: 0.2069369\ttotal: 8m 49s\tremaining: 27.9s\n",
      "475:\tlearn: 0.2068505\ttotal: 8m 50s\tremaining: 26.8s\n",
      "476:\tlearn: 0.2066560\ttotal: 8m 51s\tremaining: 25.6s\n",
      "477:\tlearn: 0.2065724\ttotal: 8m 52s\tremaining: 24.5s\n",
      "478:\tlearn: 0.2064854\ttotal: 8m 53s\tremaining: 23.4s\n",
      "479:\tlearn: 0.2063709\ttotal: 8m 54s\tremaining: 22.3s\n",
      "480:\tlearn: 0.2062841\ttotal: 8m 55s\tremaining: 21.2s\n",
      "481:\tlearn: 0.2062003\ttotal: 8m 56s\tremaining: 20s\n",
      "482:\tlearn: 0.2060631\ttotal: 8m 57s\tremaining: 18.9s\n",
      "483:\tlearn: 0.2059754\ttotal: 8m 58s\tremaining: 17.8s\n",
      "484:\tlearn: 0.2058895\ttotal: 8m 59s\tremaining: 16.7s\n",
      "485:\tlearn: 0.2058021\ttotal: 9m\tremaining: 15.6s\n",
      "486:\tlearn: 0.2056002\ttotal: 9m 1s\tremaining: 14.5s\n",
      "487:\tlearn: 0.2055166\ttotal: 9m 2s\tremaining: 13.3s\n",
      "488:\tlearn: 0.2053261\ttotal: 9m 3s\tremaining: 12.2s\n",
      "489:\tlearn: 0.2052396\ttotal: 9m 4s\tremaining: 11.1s\n",
      "490:\tlearn: 0.2050440\ttotal: 9m 5s\tremaining: 10s\n",
      "491:\tlearn: 0.2049093\ttotal: 9m 6s\tremaining: 8.89s\n",
      "492:\tlearn: 0.2046984\ttotal: 9m 7s\tremaining: 7.78s\n",
      "493:\tlearn: 0.2046141\ttotal: 9m 8s\tremaining: 6.66s\n",
      "494:\tlearn: 0.2044352\ttotal: 9m 9s\tremaining: 5.55s\n",
      "495:\tlearn: 0.2043512\ttotal: 9m 10s\tremaining: 4.44s\n",
      "496:\tlearn: 0.2042243\ttotal: 9m 11s\tremaining: 3.33s\n",
      "497:\tlearn: 0.2039826\ttotal: 9m 12s\tremaining: 2.22s\n",
      "498:\tlearn: 0.2038656\ttotal: 9m 13s\tremaining: 1.11s\n",
      "499:\tlearn: 0.2037001\ttotal: 9m 14s\tremaining: 0us\n",
      "Лучшие параметры модели CatBoostClassifier: {'auto_class_weights': 'Balanced', 'iterations': 500, 'random_state': 12345}\n",
      "Лучший показатель RMSE для CatBoostClassifier: 0.7471575270987483\n",
      "CPU times: total: 2h 10min 44s\n",
      "Wall time: 48min 20s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "parametrs_cbc = {'random_state': [RANDOM_STATE]\n",
    "                   , 'auto_class_weights': ['Balanced']\n",
    "                   , 'iterations': [500]\n",
    "                }\n",
    "\n",
    "best_model_cbc = cv_model(CatBoostClassifier()\n",
    "                          , parametrs_cbc\n",
    "                          , X_train\n",
    "                          , y_train)\n",
    "\n",
    "print(f'Лучшие параметры модели CatBoostClassifier: {best_model_cbc.best_params_}')\n",
    "print(f'Лучший показатель RMSE для CatBoostClassifier: {best_model_cbc.best_score_}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Сведем полученные показатели по моделям в одну таблицу и выведем"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Hyperparameters</th>\n",
       "      <th>F1 score in training</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>{'class_weight': 'balanced', 'max_iter': 700, 'penalty': 'l2', 'random_state': 12345, 'solver': 'liblinear'}</td>\n",
       "      <td>0.744787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SGDClassifier</td>\n",
       "      <td>{'class_weight': 'balanced', 'loss': 'modified_huber', 'max_iter': 700, 'penalty': 'l2', 'random_state': 12345}</td>\n",
       "      <td>0.748787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LinearSVC</td>\n",
       "      <td>{'C': 0.5, 'class_weight': 'balanced', 'loss': 'squared_hinge', 'max_iter': 700, 'penalty': 'l2', 'random_state': 12345}</td>\n",
       "      <td>0.755813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>{'class_weight': 'balanced', 'max_depth': 200, 'random_state': 12345}</td>\n",
       "      <td>0.651080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>{'class_weight': 'balanced', 'max_depth': 200, 'n_estimators': 10, 'random_state': 12345}</td>\n",
       "      <td>0.564845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LightGBMClassifier</td>\n",
       "      <td>{'class_weight': 'balanced', 'max_depth': 20, 'n_estimators': 250, 'random_state': 12345}</td>\n",
       "      <td>0.751451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>CatBoostClassifier</td>\n",
       "      <td>{'auto_class_weights': 'Balanced', 'iterations': 500, 'random_state': 12345}</td>\n",
       "      <td>0.747158</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Model  \\\n",
       "0      LogisticRegression   \n",
       "1           SGDClassifier   \n",
       "2               LinearSVC   \n",
       "3  DecisionTreeClassifier   \n",
       "4  RandomForestClassifier   \n",
       "5      LightGBMClassifier   \n",
       "6      CatBoostClassifier   \n",
       "\n",
       "                                                                                                            Hyperparameters  \\\n",
       "0              {'class_weight': 'balanced', 'max_iter': 700, 'penalty': 'l2', 'random_state': 12345, 'solver': 'liblinear'}   \n",
       "1           {'class_weight': 'balanced', 'loss': 'modified_huber', 'max_iter': 700, 'penalty': 'l2', 'random_state': 12345}   \n",
       "2  {'C': 0.5, 'class_weight': 'balanced', 'loss': 'squared_hinge', 'max_iter': 700, 'penalty': 'l2', 'random_state': 12345}   \n",
       "3                                                     {'class_weight': 'balanced', 'max_depth': 200, 'random_state': 12345}   \n",
       "4                                 {'class_weight': 'balanced', 'max_depth': 200, 'n_estimators': 10, 'random_state': 12345}   \n",
       "5                                 {'class_weight': 'balanced', 'max_depth': 20, 'n_estimators': 250, 'random_state': 12345}   \n",
       "6                                              {'auto_class_weights': 'Balanced', 'iterations': 500, 'random_state': 12345}   \n",
       "\n",
       "   F1 score in training  \n",
       "0              0.744787  \n",
       "1              0.748787  \n",
       "2              0.755813  \n",
       "3              0.651080  \n",
       "4              0.564845  \n",
       "5              0.751451  \n",
       "6              0.747158  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = ['LogisticRegression'\n",
    "         , 'SGDClassifier'\n",
    "         , 'LinearSVC'\n",
    "         , 'DecisionTreeClassifier'\n",
    "         , 'RandomForestClassifier'\n",
    "         , 'LightGBMClassifier'\n",
    "         , 'CatBoostClassifier']\n",
    "\n",
    "params = [best_model_lr.best_params_\n",
    "          , best_model_sgdc.best_params_\n",
    "          , best_model_lsvc.best_params_\n",
    "          , best_model_dtc.best_params_\n",
    "          , best_model_rfc.best_params_\n",
    "          , best_model_lgbmc.best_params_\n",
    "          , best_model_cbc.best_params_]\n",
    "\n",
    "f1_score_train = [best_model_lr.best_score_\n",
    "                  , best_model_sgdc.best_score_\n",
    "                  , best_model_lsvc.best_score_\n",
    "                  , best_model_dtc.best_score_\n",
    "                  , best_model_rfc.best_score_\n",
    "                  , best_model_lgbmc.best_score_\n",
    "                  , best_model_cbc.best_score_]\n",
    "\n",
    "result = {'Model': model, 'Hyperparameters': params, 'F1 score in training': f1_score_train}\n",
    "\n",
    "display(pd.DataFrame(result))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Из всех рассмотренных моделей самыми лучшими оказались модели LinearSVC с параметрами {'C': 0.5, 'class_weight': 'balanced', 'loss': 'squared_hinge', 'max_iter': 700, 'penalty': 'l2', 'random_state': 12345} и LightGBMClassifier с параметрами {'class_weight': 'balanced', 'max_depth': 20, 'n_estimators': 250, 'random_state': 12345} и показателем f1_score равным 0,756 и 0,751 соответственно.\n",
    "\n",
    "Проведем предсказание по модели LinearSVC на тестовой выборке."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Тестирование"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Показатель метрики f1_score на тестовой выборке по лучшей модели составляет: 0.751\n",
      "CPU times: total: 1.3 s\n",
      "Wall time: 1.34 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model_test = LinearSVC(C = 0.5\n",
    "                       , class_weight = 'balanced'\n",
    "                       , loss = 'squared_hinge'\n",
    "                       , max_iter = 700\n",
    "                       , penalty = 'l2'\n",
    "                       , random_state = RANDOM_STATE)\n",
    "model_test.fit(X_train, y_train)\n",
    "predictions_test = model_test.predict(X_test)\n",
    "print(f'Показатель метрики f1_score на тестовой выборке по лучшей модели составляет: {f1_score(y_test, predictions_test).round(3)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Выводы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Открыли и ознакомились с данными.\n",
    "\n",
    "Для решения данной задачи NLP нужен только текст, для этого обработали данные, привели тексты к нижнему регистру, произвели очистку данных от всех возможных знаков и символов, удалили стоп-слова.\n",
    "\n",
    "Обучили разные модели и подобрали оптимальны параметры модели. \n",
    "\n",
    "Произвели предсказание на тестовой выборке. \n",
    "\n",
    "Из всех рассмотренных моделей самыми лучшими оказались модели LinearSVC с параметрами {'C': 0.5, 'class_weight': 'balanced', 'loss': 'squared_hinge', 'max_iter': 700, 'penalty': 'l2', 'random_state': 12345} и показателем f1_score равным 0,756. Чуть хуже себя показала модель LightGBMClassifier с параметрами {'class_weight': 'balanced', 'max_depth': 20, 'n_estimators': 250, 'random_state': 12345} и показателем f1_score равным 0,751.\n",
    "\n",
    "Из всех рассмотренных моделей была выбрана модель LinearSVC и на тестовой выборке показатель F1 score составляет 0.751."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Содержание",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "302.391px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
